---
title: "《PostgreSQL指南》记录"
date: 2024-12-22
aliases: ["/Daily Dev"]
tags: ["PostgreSQL"]
categories: ["Daily Dev"]
author: "Kurong"
showToc: true
TocOpen: true
draft: false
hidemeta: false
comments: false
description: ""
disableHLJS: false # to disable highlightjs
disableShare: true
disableHLJS: false
hideSummary: false
searchHidden: true
ShowBreadCrumbs: true
ShowPostNavLinks: true
ShowRssButtonInSectionTermList: true
UseHugoToc: true
---

# 《PostgreSQL指南》记录

## Why choose PostgreSQL, or not MySQL ?

- SQL 标准支持更好：PostgreSQL 对 SQL 标准的支持更加全面，而 MySQL 在某些情况下依赖非标准实现（如分组函数的行为）。
- 高级功能更强：
  - JOSNB 的性能更优：PostgreSQL 的 JSONB 数据类型支持更高效的索引和操作，而 MySQL 的 JSON 功能较为有限。
  - 复杂查询：支持递归查询、窗口函数等复杂功能，而 MySQL 在这些方面功能较弱或支持有限。
  - 并行查询：PostgreSQL 提供原生的并行查询能力，能够充分利用多核 CPU，而 MySQL 直到 8.0 版本才有一定程度的改进。
- 扩展性更好：
  - PostgreSQL 支持自定义数据类型、函数和插件，更适合需要扩展或复杂业务逻辑的项目。
  - PostGIS 插件使其在地理信息领域表现出色，而 MySQL 的 GIS 功能相对简单。
- 更高的性能和灵活性：
  - 支持多种索引类型（如 GIN、GiST、BRIN 等），适合高性能全文搜索、地理查询等场景。
  - 支持更复杂的查询优化器策略，适合复杂查询和数据分析。
- 更可靠的数据一致性：
  - PostgreSQL 的 MVCC 机制更成熟，避免了常见的锁争用问题。
  - MySQL 的 MVCC 在某些情况下（如高并发）性能欠佳，容易导致死锁。

PostgreSQL 适用于有复杂数据分析需求、地理信息系统、高并发和大数据量等应用场景，相比于 MySQL 的应用场景更复杂。



## 数据库集簇、数据库和数据表

### 数据库集簇的逻辑结构

数据库集簇是一组数据库的集合，由一个 PostgreSQL 服务器管理。而数据库是数据对象的集合，数据库对象用于存储或引用数据的数据结构。

在 PosgreSQL 中，所有的数据库对象都通过相应的对象标识符（oid）进行管理，这些标识都是无符号 4 字节整型。

### 数据库集簇的物理结构

数据库集簇就是一个文件目录。对于 PostgreSQL，base 子目录中的每个子目录都是一个数据库，数据库中的每个表和索引都至少在相应子目录下存储为一个文件，且该子目录的名称与相应数据库的 oid 相同。

每个小于 1GB 的表或索引都在相应的数据库目录中存储为单个文件，这些文件通过 oid 进行管理。大小超过 1GB 时，会创建并使用一个名为 relfilenode.1 的新文件，如果也填满了就会创建 relfilenode.2 ，以此类推。文件的最大大小是可以通过配置文件更改的。

PostgreSQL 的表空间是基础目录之外的附加数据区域，表空间就像一个仓库，用来存放数据库文件。每个仓库可以放在不同的物理位置（比如不同的磁盘或路径）。默认情况下，PostgreSQL 有一个主仓库，叫 pg_default，所有的数据库和表默认都存放在这里。

### 堆表文件的内部布局

数据文件内部被划分成固定长度的区块，大小默认为 8KB，从 0 开始按顺序编号。如果文件已满，就在最后加一个新的区块。     

区块包含三种类型的数据：

- 堆元组：数据记录本身，从区块地步开始依序堆叠；
- 行指针：指向堆元组的指针；
- 首部数据：包含关于区块的元数据，大小为 24B。

为了识别表中的元组，数据库使用元组标识符（TID），它由区块号、指向元组的行指针的偏移号组成。

### 读写元组的方式

这里只讲述最基本的读写过程，其余细节留待后续章节描述。

写堆元组：

- PostgreSQL 在堆表的存储文件中找到有空闲空间的区块；
- 数据作为一条元组插入到这个区块的空闲空间中。

读堆元组：

- PostgreSQL 首先通过表的存储文件和区块号找到目标区块；
- 使用共享缓冲区，把目标区块加载到内存；
- PostgreSQL 遍历页面中的所有堆元组，检查每个元组是否满足查询条件。



## 进程和内存架构

### 进程架构

postgres 服务器进程是所有进程的父进程，它会在内存中分配共享内存区域，启动各种后台进程，并等待来自客户端的连接请求。每当接收到来自客户端的连接请求时，它都会启动一个后端进程，然后由启动的后端进程处理该客户端发出的所有查询。

每个后端进程由 postgres 服务器进程启动，并处理连接另一侧的客户端发出的查询。它通过单条 TCP 连接与客户端通信。PostgreSQL 没有原生的连接池功能，客户端与服务器频繁地建立断开连接会导致开销变大，可以通过池化中间件解决。

后台进程有很多种类，它们依赖于 PostgreSQL 的内部机制和特定的独立特性。

除了这三类进程外，还有复制相关进程、后台工作进程。

### 内存架构

PostgreSQL 的内存架构可以分为：

- 本地内存区域：由每个后端进程分配，自己使用。
- 共享内存区域：由所有进程使用。

​     

## 查询处理

### 概览

每个后端进程由以下 5 个子系统构成：

- 解析器：根据 SQL 语句生成一棵语法解析树；
- 分析器：对语法解析树进行语义分析，生成一棵查询树；
- 重写器：按照规则系统中的规则对查询树进行改写；
- 计划器：基于查询树生成一棵执行效率最高的计划树；
- 执行器：按照计划树中的顺序访问表和索引，执行相应查询。

解析器只会检查 SQL 语法，并不会检查语义是否正确。解析器不检查语义，如查询中有一个不存在的表名，解析器不会报错，该部分由分析器负责。

分析器中，解析和分析过程会吧所有语句转换为一颗查询树，查询树包含对应查询的元数据、特定子句相应的数据，供之后的步骤进行进一步的处理。

PostgreSQL 的规则系统基于重写器实现，重写器会根据存储在 pg_rules 中的规则对查询树进行转换。PostgreSQL 的视图是基于规则系统实现的，当使用 CREATE VIEW 命令定义一个视图时，PostgreSQL就会创建相应的规则，并存储到系统目录中。当执行一个包含该视图的查询，解析器会创建一棵语法解析树，重写器会根据 pg_rules 中存储的视图规则将部分节点重写为一棵查询子树，与子查询相对应。

计划器从重写器获取一棵查询树，基于查询树生成一棵能够被执行器高效执行的计划树。计划器是完全基于代价估计的，而不是基于规则的优化和提示。

> 计划器非常复杂，也是极其重要的内容，在后面章节会详细说明。

计划树由计划节点组成，计划节点包含执行器进行处理所必需的信息，在单表查询的场景中，执行器会按照从终端节点往根节点的顺序依次处理这些节点。

### 单表查询的代价估计

在 PostgreSQL 中有三种代价：

- 启动代价：在读取到第一条元组前花费的代价，比如索引扫描节点的启动代价就是读取目标表的索引页，取到第一个元组的代价；
- 运行代价：获取全部元组的代价；
- 总代价：前两者之和。

下面分为三种方式去计算代价估计：顺序扫描、索引扫描、排序。

#### 顺序扫描

顺序扫描会逐页扫描整个表，因此其代价与表的大小有关。计算公式如下：
$$
{Cost}_{seqscan} = {Cost}_{startup} + {Pages} \times SeqPageCost + {Tuples} \times CpuTupleCost
$$
解释：

- cost_startup：初始化代价，通常为零或很小。
- pages：表占用的磁盘页数（关系到表的大小）。
- seq_page_cost：每个磁盘页的顺序访问代价，默认值是 1.0。
- tuples：表中的行数。
- cpu_tuple_cost：处理每行数据的 CPU 代价，默认值是 0.01。

优化点：当表很大时，顺序扫描的代价较高，适合全表扫描场景。

#### 索引扫描

索引扫描会首先通过索引定位到目标记录，再访问对应的表行，因此代价包括两部分：索引扫描代价和表扫描代价。公式如下：
$$
{Cost}_{indexscan} = {Cost}_{startup} + {IndexPages} \times {RandomPageCost} + {Tuples} \times ({CpuTupleCost} + {CpuIndexTupleCost})
$$
解释：

- cost_startup：索引初始化代价。
- index_pages：访问的索引页数量。
- random_page_cost：随机访问磁盘页的代价，默认值是 4.0。
- tuples：满足条件的行数。
- cpu_tuple_cost：处理每行数据的 CPU 代价。
- cpu_index_tuple_cost：处理索引元组的 CPU 代价，默认值是 0.005。

特点：

- 当条件过滤比例较低（即匹配的行数很少）时，索引扫描的代价较低。

- 如果表较大且符合条件的记录较多，索引扫描代价可能会超过顺序扫描。

#### 排序

排序的代价主要受需要排序的行数、排序的字段数量以及排序的内存/磁盘使用影响。内存足够用快排，不足用归并。公式如下：
$$
{Cost}_{sort} = {Cost}_{startup} + {Tuples} \times \log_2({Tuples}) \times {CpuOperatorCost} + {DiskCost}
$$
解释：

- cost_startup：排序初始化代价。
- tuples：需要排序的行数。
- cpu_operator_cost：每次比较操作的代价，默认值是 0.0025。
- disk_cost：当排序超出内存时，需要进行磁盘操作，其代价由随机和顺序磁盘访问的混合代价计算。

特点：

 - 如果排序数据量较小，代价较低且可能完全在内存中完成。
 - 如果排序数据量较大，可能需要多次磁盘读写，导致代价显著增加。

### 创建单表查询的计划树

计划树的创建会经过计划器的三个步骤：

1. 执行预处理；
2. 找到代价最小的访问路径；
3. 按照代价最小的访问路径，创建计划树。

访问路径是估算代价时的处理单元；比如，顺序扫描，索引扫描，排序以及各种连接操作都有其对应的路径。访问路径只在计划器创建查询计划树的时候使用。

#### 预处理

在生成计划树前，优化器需要对查询进行预处理。预处理的主要目的是简化和规范查询，为后续的优化和执行计划生成做好准备。

预处理的具体内容：

- 解析查询：将 SQL 查询解析为语法解析树。

- 语义检查：

  - 验证表和列是否存在。

  - 检查数据类型是否匹配。

  - 验证用户权限是否足够执行该查询。

- 规则重写：

  - 如果查询涉及视图，展开视图为对应的基表查询。

  - 如果触发规则存在（如 INSTEAD OF 触发器），根据规则替换查询。

- 生成查询树：

  - 根据语法解析树和重写规则生成逻辑查询计划。
  - 查询树是一种规范化的结构，描述了查询的逻辑步骤，但尚未包含执行方式。

#### 找到代价最小的访问路径

优化器为查询中的每个表选择访问路径，并评估每种路径的代价。目标是找到总代价最低的访问路径。

评估访问路径的方式：

- 顺序扫描：逐页扫描整个表，代价与表的大小（页数）和行数成正比。
- 索引扫描：利用索引定位到满足条件的记录，代价与索引大小、符合条件的记录数成正比。
- 索引仅扫描：如果查询所需的列全部包含在索引中，无需访问表。
- 位图索引扫描：当多个索引条件（布尔表达式）结合时，使用位图来合并索引结果，适合中等数量的结果集。

代价与其计算方式见《单表查询的代价估计》这一小节。

#### 按照代价最小的访问路径，创建计划树

根据评估出的代价最小路径，生成具体的计划树。计划树描述了查询的实际执行步骤和顺序，供执行引擎使用。

创建流程：

- 创建计划节点：
  - 为每个操作创建一个计划节点。
  - 每个节点包含该操作的代价、输入来源和操作类型。
- 构建计划树结构：
  - 将各个计划节点组织成一棵树，根节点表示查询的最终输出，子节点是该输出的输入来源。
  - 子节点之间的关系体现了操作的顺序。
- 优化计划树：
  - 管道化操作：避免中间结果的浪费，如将过滤和排序合并为流水线操作。
  - 并行化：如果系统支持并行查询，评估是否可以并行执行操作。

### 执行器的工作流程

1. 接收执行计划：从优化器获取执行计划树，明确执行顺序和操作方式；
2. 初始化执行环境：准备所需资源，加载表、索引等元数据；
3. 遍历执行计划树：按计划树的结构自顶向下逐节点执行操作，每个节点处理完成后，将结果传递给父节点；
4. 流式处理返回结果：顶层节点汇总所有数据，并逐步返回给客户端。采用按需获取机制，减少中间结果的物化。

### 连接操作 Join

在 PostgreSQL 中有三种连接操作：

- 嵌套循环连接：对每个外表中的记录，逐一扫描内表，寻找匹配的记录。这种连接操作适用于外表数据较小，而内表有索引，能够快速定位匹配记录的场景。时间复杂度为 $O(m \times n)$ 。
- 归并连接：要求参与连接的表已经按连接条件的列排序（通常是索引列），同时遍历两表的排序结果，逐步匹配记录。适用场景为两个表都按连接列排序，或可以通过索引快速排序，两表数据量大且有序时效果最佳。时间复杂度为 $O(m + n)$ 。
- 散列连接：将较小的表（称为内表）加载到内存中并构建哈希表，使用连接列作为哈希键。遍历较大的表（称为外表），通过哈希表快速定位匹配记录。适用场景为外表或内表数据分布均匀，且内表较小时性能较优。时间复杂度为 $O(m + n)$ 。



## 并发控制

在 PostgreSQL 中，选择的并发控制机制是多版本并发控制（MVCC）的变体快照隔离（SI）。

PostgreSQL 中的事务隔离级别：

| 隔离等级 | 脏读 | 不可重复读 | 幻读                      | 串行化异常 |
| -------- | ---- | ---------- | ------------------------- | ---------- |
| 读已提交 | No   | Yes        | Yes                       | Yes        |
| 可重复读 | No   | No         | PG 中 No，ANSI SQL 中 Yes | Yes        |
| 串行化   | No   | No         | No                        | No         |

### 事务标识

每当事务开始时，事务管理器就会为其分配一个称为事务标识（transaction id, txid）的唯一标识符。 PostgreSQL 的 txid 是一个32位无符号整数，总取值约42亿。

### 提交日志 clog

PostgreSQL 在提交日志（Commit Log, clog）中保存事务的状态。clog 分配于共享内存中，并用于事务处理过程的全过程。

PostgreSQL 定义了四种事务状态，即：IN_PROGRESS，COMMITTED，ABORTED 和 SUB_COMMITTED。前三种很明显，SUB_COMMITTED 用于子事务。

clog 在逻辑上是一个数组，由共享内存中一系列页面组成。数组的序号索引对应相应事务的标识，内容就是事务的状态。txid 不断前进，当 clog 空间耗尽无法存储新的事务状态时，就会追加分配一个新的页面。当需要获取事务的状态时，PostgreSQL 将调用相应内部函数读取clog，并返回所请求事务的状态。

当 PostgreSQL 关机或执行存档过程时，clog 数据会写入至 pg_clog 子目录下的文件中（注意在10版本中，pg_clog 被重命名 pg_xact）。当PostgreSQL启动时会加载存储在 pg_clog（pg_xact）中的文件，用其数据初始化 clog。clog 的大小会不断增长，因为只要 clog 一填满就会追加新的页面。但并非所有数据都是必需的，PostgreSQL 会定期进行清除。

### 事务快照



### 可见性检查规则

### 可见性检查

### 防止丢失更新

### 可串行化快照隔离

### 需要的维护进程

