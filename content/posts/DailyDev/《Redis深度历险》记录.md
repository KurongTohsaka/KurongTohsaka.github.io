---
title: "《Redis深度历险》记录"
date: 2025-04-29
aliases: ["/Daily Dev"]
tags: ["Redis"]
categories: ["Daily Dev"]
author: "Kurong"
showToc: true
TocOpen: true
draft: false
hidemeta: false
comments: false
description: ""
disableHLJS: false # to disable highlightjs
disableShare: true
disableHLJS: false
hideSummary: false
searchHidden: false
ShowBreadCrumbs: true
ShowPostNavLinks: true
ShowRssButtonInSectionTermList: true
UseHugoToc: true
---

# 《Redis深度历险》记录

## 基础与应用

### 分布式锁

分布式锁用于高并发或分布式事务中保护临界资源。

最常见的实现方式是使用 SET 命令的 NX (不存在时设置)和 PX (设置过期时间)选项：

```bash
SET lock_name my_random_value NX PX 30000
```

- `lock_name` : 锁的名称。
- `my_random_value` : 唯一标识(通常使用 UUID)。
- `NX` : 只有键不存在时才设置。
- `PX 30000` : 设置 30 秒的过期时间。

释放分布式锁时需要验证唯一标识是否匹配，防止误删其他客户端的锁。

#### 超时问题

超时问题有三类：

- 锁过期，可以通过锁续约机制，即获取锁后启动一个守护线程，定期检查锁是否仍由自己持有，如果是则延长锁的过期时间。
- 客户端获取锁后崩溃，没有主动释放锁，锁就只能等待超时后才能被其他客户端获取。所以要设置合理的锁超时时间。
- Redis 服务器和客户端之间的时钟不同步，可能导致锁提前或延后过期。尽量确保服务器和客户端时钟同步(NTP)，同时适当增加锁的超时时间作为缓冲。

分布式锁的实现有 Redlock 算法、go-redis 中的简易 `mutex` 分布式锁。

### 延时队列

通过 List 来作为简易的消息队列使用。

通过 `rpush` , `lpush` 控制入队，`rpop` , `lpop` 控制出队。

使用 List 实现延时队列会出现一个问题，假设 List 为空，那么之后的 `pop` 操作就是死循环。此时可以使用阻塞读来避免这种情况，即使用 `blpop`, `brpop` 两个命令代替之前的出队命令。阻塞读在队列没有数据的时候，会立即进入休眠状态。

同时需要注意，List 长时间为空，Redis 客户端连接可能会因为空闲而被回收。所以需要加入重试机制。

结合之间的分布式锁内容，假设有一个操作加锁失败，那么可以怎么做：

1. 抛出异常，通知用户稍后重试。
2. sleep，等待锁释放。
3. 操作扔进延时队列，异步处理。

对于上面的做法 3 ，取出来又失败了怎么办？解决方法有以下几种：

- 有限重试 + 指数退避：简单而有效。
- 再维持一个死信队列，超过最大次数后转入死信队列。
- 动态优先级：类似第一种，但是复杂度会高一些，因为涉及到业务的优先级判定。

#### zset 实现，更优的选择

对于 zset 的两个值，Score 为任务执行时间戳，Member 为序列化的任务数据。

1. 添加任务：`ZADD delay_queue <执行时间戳> <任务数据>` 。
2. 获取到期任务：`ZRANGEBYSCORE delay_queue 0 <当前时间戳>` 。
3. 移除已处理任务：`ZREM delay_queue <任务数据> `。

以下是对比。

|    特性    |         ZSet实现         |      List实现      |
| :--------: | :----------------------: | :----------------: |
|  定时精度  |        精确到秒级        | 依赖消费者轮询间隔 |
|  任务排序  |      自动按时间排序      |  需要额外排序逻辑  |
|  批量获取  |  一次性获取所有到期任务  |    只能逐个获取    |
|  内存效率  | 较高(自动清理已执行任务) |  较低(需手动删除)  |
| 实现复杂度 |           中等           |        简单        |
|  适合场景  |       精确延时任务       | 简单延时/普通队列  |

### 位图

位图就是 `[]byte` ，即字符数组。

位图的操作如下：

```bash
# 设置指定位的值
SETBIT key offset value  # value 只能是 0 或 1

# 获取指定位的值
GETBIT key offset

# 统计值为 1 的位数
BITCOUNT key [start end]

# 查找第一个设置为 0/1 的位
BITPOS key bit [start] [end]
```

同时位图还支持位运算（AND 等逻辑运算）。

位图的应用场景：

- 典型的就是用户签到系统，可以快速查询定位用户签到情况。
- 可以通过 `BITCOUNT` 与位运算实现活跃用户统计。
- 实现布隆过滤器（后面会说明）。
- RBAC ，快速检查用户权限。

#### 大位图与稀疏位图

对于大位图，可以采取以下操作进行优化：

- 分片。
- 使用 `BITFIELD` 批量操作。
- 定期合并碎片。

对于稀疏位图，Redis 做了以下优化：

- 用 RLE 编码压缩：连续相同值的位会被压缩。
- 分块存储：只存储非零的块。

### HyperLogLog

HyperLogLog 是 Redis 提供的一种概率数据结构，用于高效地估计集合的基数（cardinality，即集合中不重复元素的数量）。它的核心原理基于以下特点：

1. 概率算法：HyperLogLog 使用概率统计方法来估计基数，不是精确计算。
2. 固定内存占用：每个 HyperLogLog 结构只需要 12KB 内存。
3. 误差率低：标准误差率约为 0.81%，可以配置更低的误差率。
4. 哈希函数：使用哈希函数将输入元素映射到二进制串。

它有以下几个基本操作：

- `PFADD key element [element ...]`：添加元素到 HyperLogLog 。
- `PFCOUNT key [key ...]`：返回 HyperLogLog 的基数估计值。
- `PFMERGE destkey sourcekey [sourcekey ...]`：合并多个 HyperLogLog 。

HyperLogLog 比较适合以下场景：

- 网站的 UV 统计：统计每天/每周/每月的独立访客数，相比使用集合存储每个用户 ID，HyperLogLog 节省大量内存。
- 其他大规模数据的去重场景。

### 布隆过滤器（Bloom Filter）

布隆过滤器是一种空间高效的概率型数据结构，用于判断一个元素是否存在于集合中。它的核心特点是：

1. 可能误判但不会漏判：如果布隆过滤器说某个元素不存在，则一定不存在；如果说存在，则可能存在（有一定误判率）。
2. 空间效率极高：相比存储完整数据集，布隆过滤器使用的内存极少。
3. 查询效率高：查询时间与集合大小无关，始终是 $O(k)$ ，$k$ 是哈希函数数量。

Redis 4.0+ 通过 `BF` 命令组支持布隆过滤器，基本命令：

- `BF.RESERVE key error_rate capacity`：创建布隆过滤器。
- `BF.ADD key item`：添加元素。
- `BF.MADD key item1 item2 ...`：批量添加。
- `BF.EXISTS key item`：检查元素是否存在。
- `BF.MEXISTS key item1 item2 ...`：批量检查。

Redis 的布隆过滤器会自动扩容。

它的应用场景有这些：

- 缓存穿透防护：在查询缓存前先检查布隆过滤器，避免对数据库的无效查询。
- 垃圾邮件过滤、爬虫 URL 去重等。

#### 原理

1. 初始化：创建一个长度为 m 的位数组(bit array)，所有位初始化为 0 。
2. 添加元素：
   - 使用 k 个不同的哈希函数对元素进行计算，得到 k 个哈希值。
   - 将这些哈希值对 m 取模，得到 k 个数组位置。
   - 将这些位置的值设为 1 。
3. 查询元素：
   - 同样使用 k 个哈希函数计算元素的位置。
   - 如果所有对应位置的值都为 1，则返回"可能存在"。
   - 如果有任何一个位置为 0，则确定"不存在"。

可以看到布隆过滤器有三个参数，这些参数决定了误判率：

- m：位数组大小（位数）。
- k：哈希函数数量。
- n：预期要插入的元素数量。

无论是在 Redis 中的 `BF` 指令组中，还是在相关库中，布隆过滤器的使用只会用到两个参数：误判率和预期插入元素数量，而位数组、哈希函数数量两个参数会自动计算。

### 限流算法

#### 固定窗口计数器

固定窗口计数器算法是最简单的限流算法，它将时间划分为固定大小的窗口（如1秒、1分钟），每个窗口内维护一个请求计数器。

- 时间分割：将时间线划分为固定长度的连续时间段（窗口）。
- 计数机制：每个窗口独立计数，请求到达时当前窗口计数器加1 。
- 限流判断：当窗口内计数超过预设阈值时，拒绝后续请求。
- 窗口重置：时间进入下一个窗口时，计数器清零重新开始计数。

#### 滑动窗口计数器

滑动窗口算法是对固定窗口算法的改进，通过更细粒度的时间记录来模拟滑动窗口效果。

- 时间记录：不再使用固定窗口，而是记录每个请求的时间戳。
- 滑动窗口：定义一个时间范围（如1分钟），只统计这个滑动窗口内的请求。
- 过期清理：持续清理滑动窗口之前的旧请求记录。
- 动态计数：实时计算当前滑动窗口内的请求总数。

#### 漏斗限流

漏斗算法模拟了一个漏水的桶的物理过程：

- 漏斗容器：想象一个容量固定的漏斗。
- 进水过程：请求像水一样流入漏斗。
- 漏水过程：漏斗以恒定速率"漏水"（处理请求）。
- 限流判断：当漏斗中的水（待处理请求）超过容量时，拒绝新请求。

工作流程：

1. 每个新请求到达时，计算自上次请求以来的漏水量。
2. 更新当前漏斗中的水量（上次水量 - 漏水量）。
3. 判断当前水量 + 1（新请求）是否超过容量。
4. 不超过则接受请求，更新水量；否则拒绝。

#### 令牌桶

令牌桶算法与漏斗算法相似但理念相反：

- 令牌桶：想象一个装令牌的桶，容量固定。
- 令牌生成：系统以固定速率向桶中添加令牌。
- 请求消耗：每个请求需要获取一个令牌才能被处理。
- 限流判断：当桶中没有令牌时，拒绝新请求。

工作流程：

1. 计算自上次请求以来应该新增的令牌数（基于时间间隔和生成速率）。
2. 更新当前令牌数（不超过桶容量）。
3. 判断是否有足够令牌（至少1个）。
4. 有则取走一个令牌接受请求，否则拒绝。

|       特性       |  固定窗口计数器  | 滑动窗口计数器 |      漏斗限流      |       令牌桶限流       |
| :--------------: | :--------------: | :------------: | :----------------: | :--------------------: |
|  **限流精确度**  | 低（有边界问题） |       中       |         高         |           高           |
| **突发流量处理** | 允许窗口边界突发 |  允许部分突发  |      严格限制      |   允许桶容量内的突发   |
|   **内存消耗**   |       很小       |      较大      |        中等        |          中等          |
|  **实现复杂度**  |     非常简单     |      中等      |       较复杂       |         较复杂         |
| **典型应用场景** |   简单限流需求   |  一般API限流   | 严格速率控制的系统 | 需要弹性处理突发的系统 |

### SCAN 命令与大 Key 问题

SCAN 是 Redis 提供的渐进式遍历键空间的命令，解决了 KEYS 命令可能阻塞 Redis 的问题。

这是 SCAN 的基本用法：`SCAN cursor [MATCH pattern] [COUNT count] [TYPE type]` 。

SCAN 命令有以下特点：

1. 非阻塞式：不会像 KEYS 命令那样长时间阻塞服务器。
2. 渐进式遍历：分批返回结果，避免一次性处理大量数据。
3. 游标机制：使用游标(cursor)记录遍历位置。
4. 可重复遍历：保证完整遍历所有键(但不保证不重复)。

#### 大 Key 问题

大 Key 是指存储在 Redis 中具有较大体积的单个键值对，通常表现为以下几种形式：

- Value 过大：单个 String 类型的值超过 10KB 。
- 元素过多：Hash、List、Set、ZSet 等集合类型元素数量超过 5000 个。
- 复合结构过大：复杂数据结构（如嵌套 Hash）占用内存过大。

大 Key 的危害：

- 操作耗时增加，阻塞 Redis 单线程，降低持久化速度。
- 内存使用不均，集群环境下数据分片不均。
- 传输大 Key 消耗带宽，客户端处理耗时增加。

可以用 `redis-cli` 命令检测大 Key ：

```bash
# 扫描大Key
redis-cli --bigkeys

# 内存分析
redis-cli --memkeys
```

可以使用 SCAN 命令：

```bash
# 自定义扫描大Key
redis-cli --scan --pattern '*' --count 1000 | while read key; do echo "$key: $(redis-cli memory usage $key)"; done | sort -n -k2 -t: | tail -n 20
```

也可以使用 MEMORY USAGE 命令：

```bash
MEMORY USAGE key_name
```

大 Key 有几种解决方法：

- 拆分大 Key。
- 压缩。
- 调整数据结构。
- 设置合理的过期时间。
- 渐进式删除：通过 `UNLINK large_key` 删除大 Key 。



## 原理

### 线程 IO 模型

### 持久化

 ### 管道

### 事务

### 小对象压缩



## 集群

### 主从同步

### Sentinel

### Cluster



## 拓展

### Stream

### 集群下的分布式锁

### LRU

### 惰式删除

