<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>EMNLP | KurongBlog</title>
<meta name=keywords content><meta name=description content="记录日常"><meta name=author content="Kurong"><link rel=canonical href=http://localhost:1313/tags/emnlp/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=http://localhost:1313/tags/emnlp/index.xml><link rel=alternate hreflang=en href=http://localhost:1313/tags/emnlp/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],throwOnError:!1})})</script><meta property="og:title" content="EMNLP"><meta property="og:description" content="记录日常"><meta property="og:type" content="website"><meta property="og:url" content="http://localhost:1313/tags/emnlp/"><meta property="og:image" content="http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="og:site_name" content="KurongBlog"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="EMNLP"><meta name=twitter:description content="记录日常"></head><body class="list dark" id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Home (Alt + H)"><img src=http://localhost:1313/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/categories/ title=categories><span>categories</span></a></li><li><a href=http://localhost:1313/tags/ title=tags><span>tags</span></a></li><li><a href=http://localhost:1313/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a>&nbsp;»&nbsp;<a href=http://localhost:1313/tags/>Tags</a></div><h1>EMNLP</h1></header><article class="post-entry tag-entry"><figure class=entry-cover><img loading=lazy src=http://localhost:1313/cover/Summarization_as_Indirect_Supervision_for_Relation_Extraction.png alt></figure><header class=entry-header><h2 class=entry-hint-parent>《Summarization as Indirect Supervision for Relation Extraction》笔记</h2></header><div class=entry-content><p>Link [2205.09837v2] Summarization as Indirect Supervision for Relation Extraction (arxiv.org)
Accepted EMNLP 2022.
Intro 关系抽取（RE）旨在从文本中提取实体之间的关系。例如，给定句子“Steve Jobs 是 Apple 的创始人”，RE 模型会识别出“创立”这一关系。RE 是自然语言理解的重要任务，也是构建知识库的关键步骤。先进的 RE 模型对于对话系统、叙事预测和问答等知识驱动的下游任务至关重要。
现有的 RE 模型通常依赖于带有昂贵注释的训练数据，这限制了它们的应用。为了应对这一问题，本文提出了一种新的方法——SURE（Summarization as Relation Extraction），将 RE 转化为摘要任务，通过间接监督来提高 RE 的精度和资源效率。
图1展示了 SURE 的结构。具体来说，SURE 通过关系和句子转换技术将 RE 转化为摘要任务，并应用约束推理进行关系预测。我们采用实体信息口语化技术，突出包含实体信息的句子上下文，并将关系口语化为模板式的简短摘要。这样，转换后的RE输入和输出自然适合摘要模型。然后，我们通过在转换后的RE数据上进行微调，将摘要模型适配于RE任务。在推理过程中，设计了一种 Trie 评分技术来推断关系。通过这种方式，SURE 充分利用了摘要的间接监督，即使在资源匮乏的情况下也能获得精确的RE模型。
这项工作的贡献有两个方面。首先，据我们所知，这是首次研究利用摘要的间接监督进行RE。由于摘要的目标与 RE 自然对齐，它允许在不完全依赖直接任务注释的情况下训练出精确的 RE 模型，并在资源匮乏的情况下表现出色。其次，我们研究了有效桥接摘要和 RE 任务形式的输入转换技术，以及进一步增强基于摘要的RE推理的约束技术。我们的贡献通过在三个广泛使用的句子级 RE 数据集 TACRED、TACREV 和 SemEval 以及 TACRED 的三个低资源设置上的实验得到验证。我们观察到，SURE 在低资源设置下（使用10%的 TACRED 训练数据）优于各种基线。SURE 还在 TACRED 和 TACREV上 分别以75.1%和83.5%的 micro-F1 得分达到了SOTA 性能。我们还进行了全面的消融研究，展示了摘要的间接监督的有效性以及 SURE 输入转换的最佳选项。
...</p></div><footer class=entry-footer><span title='2024-09-29 00:00:00 +0000 UTC'>September 29, 2024</span>&nbsp;·&nbsp;Kurong</footer><a class=entry-link aria-label="post link to 《Summarization as Indirect Supervision for Relation Extraction》笔记" href=http://localhost:1313/posts/papernotes/summarization_as_indirect_supervision_for_relation_extraction/></a></article><article class="post-entry tag-entry"><figure class=entry-cover><img loading=lazy src=http://localhost:1313/cover/Modular_Self-Supervision_for_Document-Level_Relation_Extraction.png alt></figure><header class=entry-header><h2 class=entry-hint-parent>《Modular Self-Supervision for Document-Level Relation Extraction》笔记</h2></header><div class=entry-content><p>Link [2109.05362] Modular Self-Supervision for Document-Level Relation Extraction (arxiv.org)
Accepted at EMNLP 2021
Intro 信息抽取的先前工作通常集中在句子内的二元关系。然而，实际应用往往需要跨大段文本提取复杂关系。这在生物医学等高价值领域尤为重要，因为获取最新发现的高召回率至关重要。例如，图1显示了一个三元（药物、基因、突变）关系，表明具有 MAP2K1 突变 K57T 的肿瘤对 cobimetinib 敏感，但这些实体从未在同一段落中同时出现。
先前的工作都将文档级关系抽取视为一个单一的整体问题，这在推理和学习上都带来了重大挑战。尽管最近取得了一些进展，但在使用最先进的神经架构（如LSTM 和 transformer）建模长文本范围时仍存在显著挑战。此外，直接监督稀缺，任务特定的自监督（如距离监督）在应用于短文本范围之外时变得极其嘈杂。
在本文中，我们通过将文档级关系抽取分解为局部关系检测和全局推理来探索一种替代范式。具体来说，我们使用 Davidsonian 语义表示 $n$ 元关系，并结合段落级关系分类和使用全局推理规则（例如，参数解析的传递性）的篇章级参数解析。每个组件问题都存在于短文本范围内，其相应的自监督错误率要低得多。我们的方法借鉴了模块化神经网络和神经逻辑编程的灵感，将复杂任务分解为局部神经学习和全局结构化集成。然而，我们不是从端到端的直接监督中学习，而是承认组件问题的模块化自监督（Modular Self-Supervision），这更容易获得。
这种模块化方法不仅使我们能够处理长文本，还能扩展到所有先前方法无法覆盖的跨段落关系。我们在精准肿瘤学的生物医学机器阅读中进行了全面评估，其中跨段落关系尤为普遍。我们的方法在最具挑战性的关系中表现尤为突出，这些关系的参数从未在段落中同时出现，其F1分数比之前的最先进方法（如多尺度学习（和图神经网络高出20多个百分点。
Document-Level Relation Extraction 设 $E,R,D$ 分别代表实体、关系、文档，那在图2中的 $R$ 为精准癌症药物反应，实体 $E_1,E_2,E_3$​ 分别药物 cobimetinib、基因 MAP2K1 和突变 K57T。这个关系跨越多个段落和几十个句子。
用新戴维森语义表示 n 元关系抽取： $$ R_D(E_1, \cdots, E_n) \equiv \exists T \in D \exists r. [R_T(r) \land A_1(r, E_1) \land \cdots \land A_n(r, E_n)] $$ 其中，$T$ 为文档 $D$ 中的片段，$r$ 为引入的事件变量以表示 $R$​ 。
...</p></div><footer class=entry-footer><span title='2024-09-28 00:00:00 +0000 UTC'>September 28, 2024</span>&nbsp;·&nbsp;Kurong</footer><a class=entry-link aria-label="post link to 《Modular Self-Supervision for Document-Level Relation Extraction》笔记" href=http://localhost:1313/posts/papernotes/modular_self-supervision_for_document-level_relation_extraction/></a></article><article class="post-entry tag-entry"><figure class=entry-cover><img loading=lazy src=http://localhost:1313/cover/Separating_Retention_from_Extraction.png alt></figure><header class=entry-header><h2 class=entry-hint-parent>《Separating Retention from Extraction in the Evaluation of End-to-end Relation Extraction》笔记</h2></header><div class=entry-content><p>Link [2109.12008v1] Separating Retention from Extraction in the Evaluation of End-to-end Relation Extraction (arxiv.org)
Accepted at EMNLP 2021
Intro 信息抽取（Information Extraction, IE）旨在将文本中表达的信息转换为预定义的结构化知识格式。这个总体目标被分解为更容易自动执行和评估的子任务。因此，命名实体识别（Named Entity Recognition, NER）和关系抽取（Relation Extraction, RE）是两个关键的 IE 任务。传统上，这些任务是通过流水线方式执行的。也可以采用联合方式处理，以建模它们的相互依赖性，减少错误传播并获得更现实的评估设置。
随着 NLP 领域的总体趋势，最近在实体和关系抽取基准测试中报告的定量改进至少部分归因于使用了越来越大的预训练语言模型（Language Models, LMs），如 BERT 来获得上下文词表示。同时，人们意识到需要新的评估协议，以更好地理解所获得的神经网络模型的优缺点，而不仅仅是对一个保留测试集上的单一整体指标。
特别是，对未见数据的泛化是评估深度神经网络的关键因素。在涉及提取提及的IE任务中，这一点尤为重要：小范围的词语可能会同时出现在评估和训练数据集中。已证明这种词汇重叠与NER中神经网络的性能相关。对于流水线 RE，神经模型过度依赖候选参数的类型或其上下文中存在的特定触发词。
在端到端关系抽取中，我们可以预期这些 NER 和 RE 会结合在一起。在这项工作中，我们认为当前的评估基准不仅衡量了从文本中提取信息的能力，还衡量了模型在训练期间简单保留标记的（头、谓词、尾）三元组的能力。当模型在训练期间看到的句子上进行评估时，很难区分这两种行为中的哪一种占主导地位。
然而，我们可以假设模型可以简单地检索先前看到的信息，像一个被压缩的知识库一样，通过相关查询进行探测。因此，在包含过多已见三元组的示例上进行测试可能会高估模型的泛化能力。
即使没有标记数据，LMs也能够学习一些单词之间的关系，可以通过填空句子进行探测，其中一个参数被掩盖。
Datasets and Models 数据集选用了 CoNLL04、ACE05、SciERC。
模型选用了三个模型：
PURE：Pipeline 模型 SpERT：Joint 模型 Two are better than one（TABTO）：Joint 模型 Partitioning by Lexical Overlap（基于词汇重叠的划分） 我们根据与训练集的词汇重叠情况对测试集中的实体提及进行划分。我们区分了已见和未见的提及，并将这种划分扩展到关系上。
我们实现了一个简单的保留启发式方法（Retention Heuristic，启发式方法），将训练集中确切存在的实体提及或关系标记为其多数标签。我们在表1中报告了 NER 和 RE 的 Micro-avg. 精度、召回率和 F1 分数。
...</p></div><footer class=entry-footer><span title='2024-09-27 00:00:00 +0000 UTC'>September 27, 2024</span>&nbsp;·&nbsp;Kurong</footer><a class=entry-link aria-label="post link to 《Separating Retention from Extraction in the Evaluation of End-to-end Relation Extraction》笔记" href=http://localhost:1313/posts/papernotes/separating_retention_from_extraction/></a></article><article class="post-entry tag-entry"><figure class=entry-cover><img loading=lazy src=http://localhost:1313/cover/Better_Few-Shot_Relation_Extraction_with_Label_Prompt_Dropout.png alt></figure><header class=entry-header><h2 class=entry-hint-parent>《Better Few-Shot Relation Extraction with Label Prompt Dropout》笔记</h2></header><div class=entry-content><p>Link [2210.13733] Better Few-Shot Relation Extraction with Label Prompt Dropout (arxiv.org)
Accepted EMNLP 2022.
Intro 在这项工作中，我们提出了一种称为标签提示丢弃（Label Prompt Dropout, LPD）的新方法。我们直接将文本标签和上下文句子连接在一起，并将它们一起输入到 Transformer Encoder 中。文本标签作为标签提示，通过自注意力机制引导和规范 Transformer Encoder 输出标签感知的关系表示。在训练过程中，我们随机丢弃提示标记，使模型必须学会在有和没有关系描述的情况下工作。实验表明，我们的方法在两个标准的FSRE数据集上取得了显著的改进。我们进行了广泛的消融研究，以证明我们方法的有效性。此外，我们强调了先前研究工作评估设置中的一个潜在问题，即预训练数据中包含的关系类型实际上与测试集中的关系类型重叠。我们认为这对于少样本学习来说可能不是一个理想的设置，并表明现有工作的性能提升可能部分归因于这种“知识泄漏”问题。我们建议过滤掉预训练数据中所有重叠的关系类型，并进行更严格的少样本评估。总之，我们做出了以下贡献：
我们提出了 LPD，一种新的标签提示丢弃方法，使 FSRE 中的文本标签得到了更好的利用。这种简单的设计显著优于以前使用复杂网络结构将文本标签和上下文句子融合的方法。 我们识别了文献中先前实验设置的局限性，并提出了一个更严格的FSRE评估设置。对于这两种设置，我们都显示出比以前的最先进方法更强的改进。 Related Work Few-Shot Relation Extraction Prompt-Based Fine-Tuning 基于提示的模型在小样本和零样本学习中表现出色。这一研究方向的模型尝试将下游微调任务与预训练的掩码语言建模目标对齐，以更好地利用预训练语言模型的潜在知识。
然而，与许多其他自然语言处理任务（如二元情感分析中的“正面/负面”）的标签语义直观不同，关系抽取中的关系类型可能非常复杂，通常需要较长的句子来描述。例如，FewRel 中的关系 P2094 被描述为“由监管机构进行的官方分类，主体（事件、团队、参与者或设备）符合纳入标准”。基于提示的模型在这种情况下会遇到困难，因为它们需要固定的模板（例如，提示模板中的 [MASK] 令牌数量必须固定）。以前的方法不得不依赖手动设计的提示模板，并使用关系名称而不是关系描述。
为了解决这个问题，我们提出直接使用整个关系描述作为提示，而不使用任何掩码令牌。在传统的基于提示的模型中，提示用于创建自然描述，以便模型可以在 [MASK] 位置进行更好的预测，而本研究中使用的标签提示通过自然描述来帮助规范模型输出更好的类别表示。
Approach Training with Label Prompt Dropout 对于每个支持实例，我们直接将关系描述和上下文句子用“:”连接起来。例如，句子“北京举办了2022年冬季奥运会”将变成“事件地点: 北京举办了2022年冬季奥运会。” 这个想法是创建一个自然的实例，其中定义首先给出，然后是例子。关系描述和冒号作为标签提示，引导 Transformer Encoder 输出一个标签感知的关系表示。为了防止模型完全依赖标签提示而忽略上下文句子，标签提示会以 $α_{train}$ 的概率随机丢弃。例如，上图中的支持实例“十进制数最早在印度发展起来”保持其初始形式，因为其标签提示被丢弃了。对于查询实例，我们直接输入句子而不带任何标签提示。这是因为查询集本质上与测试集相同，我们不应假设可以访问真实知识。随后，使用特殊实体标记来标记头部和尾部，并在句子的前后添加特殊的分类和分隔标记，例如“[CLS] 事件地点: [E1] 北京 [/E1] 举办了 [E2] 2022年冬季奥运会 [/E2]。” 解析后的句子然后被送入Transformer Encoder。
...</p></div><footer class=entry-footer><span title='2024-09-22 00:00:00 +0000 UTC'>September 22, 2024</span>&nbsp;·&nbsp;Kurong</footer><a class=entry-link aria-label="post link to 《Better Few-Shot Relation Extraction with Label Prompt Dropout》笔记" href=http://localhost:1313/posts/papernotes/better_few-shot_relation_extraction_with_label_prompt_dropout/></a></article><article class="post-entry tag-entry"><figure class=entry-cover><img loading=lazy src=http://localhost:1313/cover/RAPL.png alt></figure><header class=entry-header><h2 class=entry-hint-parent>RAPL: A Relation-Aware Prototype Learning Approach for Few-Shot Document-Level Relation Extraction</h2></header><div class=entry-content><p>Link [2310.15743] RAPL: A Relation-Aware Prototype Learning Approach for Few-Shot Document-Level Relation Extraction (arxiv.org)
Accepted EMNLP 2023.
EMNLP：CCF B
Related Works 这一部分内容本来是在论文的最后面，但是考虑到这篇论文也算是打开了新世界的大门，所以把这个放在最前面。
关系抽取（Relation Extraction，RE）大致可以分为三种：
语句级 RE（Sentence-Level RE）：早期的研究主要集中在预测单个句子内两个实体之间的关系。各种基于模式和神经网络的方法在句子级关系抽取上取得了令人满意的结果。然而，句子级关系抽取在抽取范围和规模上有显著的局限性。
可以说是早期的 RE 大多是这一类别。
文档级 RE （Document-Level RE，DocRE）：现有的大多数文档级关系抽取研究都基于数据驱动的监督场景，通常分为基于图和基于序列的方法。基于图的方法通常通过图结构抽象文档，并使用图神经网络进行推理。基于序列的方法则使用仅包含变压器的架构来编码长距离的上下文依赖关系。这两类方法在文档级关系抽取中都取得了令人印象深刻的结果。然而，这些方法对大规模标注文档的依赖使得它们难以适应低资源场景。
小样本文档级 RE （Few-Shot Document-Level RE，FSDLRE）：为了应对现实世界文档级关系抽取场景中普遍存在的数据稀缺问题，Popovic等将文档级关系抽取任务形式化为小样本学习任务。为了完成这一任务，他们提出了多种基于度量的模型，这些模型建立在最先进的监督文档级关系抽取方法和少样本句子级关系抽取方法的基础上，旨在解决不同任务设置的问题。有效的基于度量的少样本文档级关系抽取方法的每个类别的原型应该准确捕捉相应的关系语义。然而，由于现有方法的粗粒度关系原型学习策略和”一刀切”的 NOTA 原型学习策略，这对现有方法来说是一个挑战。
术语解释：
原型学习（Prototype-Based Learning）是一种通过存储一组代表性样本（原型）来进行分类、回归或聚类的学习方法。原型学习的主要步骤包括：
选择原型：从训练数据中选择一组代表性的样本作为原型。 计算距离：使用距离度量（如欧氏距离、曼哈顿距离等）来确定测试样本与原型之间的相似性。 分类或聚类：将测试样本分配给最接近的原型，从而确定其所属的类别或簇。 NOTA Prototype 在本文中指的是 “None-Of-The-Above” 原型，用于处理那些不属于任何目标关系类型的实体对。以下是其主要特点：
任务特定：每个任务生成特定的 NOTA 原型，以更好地捕捉该任务中的 NOTA 语义。
基础原型：引入一组可学习的基础 NOTA 原型，这些原型需要在每个任务中进一步修正。
支持实例选择：从支持文档中选择 NOTA 实例，并将其与基础NOTA原型融合，生成最终的任务特定NOTA 原型。
语义捕捉：通过这种方法，NOTA 原型不仅包含了元学习的通用知识，还能捕捉每个任务中的特定NOTA 语义。
Intro FSDLRE 任务的简单描述：
...</p></div><footer class=entry-footer><span title='2024-09-17 00:00:00 +0000 UTC'>September 17, 2024</span>&nbsp;·&nbsp;Kurong</footer><a class=entry-link aria-label="post link to RAPL: A Relation-Aware Prototype Learning Approach for Few-Shot Document-Level Relation Extraction" href=http://localhost:1313/posts/papernotes/rapl/></a></article></main><footer class=footer><span>&copy; 2025 <a href=http://localhost:1313/>KurongBlog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>