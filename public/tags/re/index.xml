<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>RE on KurongBlog</title>
    <link>http://localhost:1313/tags/re/</link>
    <description>Recent content in RE on KurongBlog</description>
    <image>
      <title>KurongBlog</title>
      <url>http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- 0.135.0</generator>
    <language>en</language>
    <lastBuildDate>Sat, 05 Oct 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/re/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>《Distantly-Supervised Joint Extraction with Noise-Robust Learning》笔记</title>
      <link>http://localhost:1313/posts/papernotes/distantly-supervised_joint_extraction_with_noise-robust_learning/</link>
      <pubDate>Sat, 05 Oct 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/papernotes/distantly-supervised_joint_extraction_with_noise-robust_learning/</guid>
      <description>&lt;h2 id=&#34;link&#34;&gt;Link&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2310.04994#:~:text=We%20propose%20DENRL,%20a%20generalizable%20framework%20that%201&#34;&gt;https://arxiv.org/abs/2310.04994#:~:text=We%20propose%20DENRL,%20a%20generalizable%20framework%20that%201&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Accepted by ACL 2024.&lt;/p&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;联合抽取&lt;/strong&gt;旨在使用单一模型检测实体及其关系，这是自动知识库构建中的关键步骤。为了廉价地获取大量标注的联合训练数据，提出了&lt;strong&gt;远程监督（Distantly Supervise，DS）&lt;/strong&gt;，通过将知识库（Knowledge Base，KB）与未标注的语料库对齐，自动生成训练数据。假设如果一个实体对在 KB 中有关系，则包含该对的所有句子都表达相应的关系。&lt;/p&gt;
&lt;p&gt;然而，DS 带来了大量的&lt;strong&gt;噪声标签&lt;/strong&gt;，显著降低了联合抽取模型的性能。此外，由于开放域 KB 中实体的模糊性和覆盖范围有限，DS 还会生成噪声和不完整的实体标签。在某些情况下，DS 可能导致 KB 中包含超过30%的噪声实例，使得学习有用特征变得不可能。&lt;/p&gt;
&lt;p&gt;处理这些噪声标签的先前研究要么考虑弱标注的实体，即远程监督的命名实体识别（NER），要么考虑噪声关系标签，即远程监督的关系抽取（RE），它们专注于设计新颖的手工制作关系特征、神经架构和标注方案以提高关系抽取性能。此外，使用大型语言模型（LLMs）的上下文学习（ICL）也很流行。然而，它们资源需求高，对提示设计敏感，可能在处理复杂任务时表现不佳。&lt;/p&gt;
&lt;p&gt;为了廉价地减轻两种噪声源，我们提出了 &lt;strong&gt;DENRL&lt;/strong&gt; （&lt;strong&gt;D&lt;/strong&gt;istantly-supervised joint &lt;strong&gt;E&lt;/strong&gt;xtraction with &lt;strong&gt;N&lt;/strong&gt;oise-&lt;strong&gt;R&lt;/strong&gt;obust &lt;strong&gt;L&lt;/strong&gt;earning）。DENRL 假设&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可靠的关系标签，其关系模式显著表明实体对之间的关系，应该由模型解释；&lt;/li&gt;
&lt;li&gt;可靠的关系标签也隐含地表明相应实体对的可靠实体标签。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;具体来说，DENRL应用词袋正则化（BR）引导模型关注解释正确关系标签的显著关系模式，并使用基于本体的逻辑融合（OLF）通过概率软逻辑（PSL）教授底层实体关系依赖性。这两种信息源被整合形成噪声鲁棒损失，正则化标注模型从具有正确实体和关系标签的实例中学习。接下来，如果学习到的模型能够清晰地定位关系模式并理解候选实例的实体关系逻辑，它们将被选择用于后续的自适应学习。我们进一步采样包含已识别模式中对应头实体或尾实体的负实例以减少实体噪声。我们迭代学习一个可解释的模型并选择高质量实例。这两个步骤相互强化——更可解释的模型有助于选择更高质量的子集，反之亦然。&lt;/p&gt;
&lt;h2 id=&#34;joint-extraction-architecture&#34;&gt;Joint Extraction Architecture&lt;/h2&gt;
&lt;h3 id=&#34;tagging-scheme&#34;&gt;Tagging Scheme&lt;/h3&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/PaperNotes/Distantly-Supervised_Joint_Extraction_with_Noise-Robust_Learning/img1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/PaperNotes/Distantly-Supervised_Joint_Extraction_with_Noise-Robust_Learning/img2.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;为了同时抽取实体（提及和类型）和关系，我们为每个起始位置 $p$ 标注四元组 ${e_1, tag_1, e_2, r_e}$，并定义 “BIO” 标记来编码位置。对于一个 $T$ 个 token 的句子，我们根据不同的起始位置标注 $T$ 个不同的标记序列。&lt;/p&gt;
&lt;p&gt;对于每个标记序列，如果 $p$ 是一个实体的起始位置（该序列是一个实例），则在 $p$ 处标注实体类型，并用关系类型标注与 $p$ 处实体有关系的其他实体。其余的令牌标注为 “O”（Outside），表示它们不对应头实体。这样，每个标记序列将生成一个关系四元组。&lt;/p&gt;
&lt;p&gt;我们将包含至少一个关系的实例定义为正实例，没有关系的实例定义为负实例。“BIO”（Begin, Inside, Outside）标记用于指示每个实体中令牌的位置信息，以便同时提取多词实体和关系类型。注意，我们不需要尾实体类型，因为每个实体都会被查询，我们可以从 T 标记序列中获得所有实体类型及其关系。&lt;/p&gt;</description>
    </item>
    <item>
      <title>《Summarization as Indirect Supervision for Relation Extraction》笔记</title>
      <link>http://localhost:1313/posts/papernotes/summarization_as_indirect_supervision_for_relation_extraction/</link>
      <pubDate>Sun, 29 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/papernotes/summarization_as_indirect_supervision_for_relation_extraction/</guid>
      <description>&lt;h2 id=&#34;link&#34;&gt;Link&lt;/h2&gt;
&lt;p&gt;[&lt;a href=&#34;https://arxiv.org/abs/2205.09837v2&#34;&gt;2205.09837v2] Summarization as Indirect Supervision for Relation Extraction (arxiv.org)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Accepted EMNLP 2022.&lt;/p&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;
&lt;p&gt;关系抽取（RE）旨在从文本中提取实体之间的关系。例如，给定句子“Steve Jobs 是 Apple 的创始人”，RE 模型会识别出“创立”这一关系。RE 是自然语言理解的重要任务，也是构建知识库的关键步骤。先进的 RE 模型对于对话系统、叙事预测和问答等知识驱动的下游任务至关重要。&lt;/p&gt;
&lt;p&gt;现有的 RE 模型通常依赖于带有昂贵注释的训练数据，这限制了它们的应用。为了应对这一问题，本文提出了一种新的方法——&lt;strong&gt;SURE（Summarization as Relation Extraction）&lt;/strong&gt;，将 RE 转化为摘要任务，通过间接监督来提高 RE 的精度和资源效率。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/PaperNotes/Summarization_as_Indirect_Supervision_for_Relation_Extraction/img1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;图1展示了 SURE 的结构。具体来说，SURE 通过关系和句子转换技术将 RE 转化为摘要任务，并应用约束推理进行关系预测。我们采用实体信息口语化技术，突出包含实体信息的句子上下文，并将关系口语化为模板式的简短摘要。这样，转换后的RE输入和输出自然适合摘要模型。然后，我们通过在转换后的RE数据上进行微调，将摘要模型适配于RE任务。在推理过程中，设计了一种 Trie 评分技术来推断关系。通过这种方式，SURE 充分利用了摘要的间接监督，即使在资源匮乏的情况下也能获得精确的RE模型。&lt;/p&gt;
&lt;p&gt;这项工作的贡献有两个方面。首先，据我们所知，这是首次研究利用摘要的间接监督进行RE。由于摘要的目标与 RE 自然对齐，它允许在不完全依赖直接任务注释的情况下训练出精确的 RE 模型，并在资源匮乏的情况下表现出色。其次，我们研究了有效桥接摘要和 RE 任务形式的输入转换技术，以及进一步增强基于摘要的RE推理的约束技术。我们的贡献通过在三个广泛使用的句子级 RE 数据集 TACRED、TACREV 和 SemEval 以及 TACRED 的三个低资源设置上的实验得到验证。我们观察到，SURE 在低资源设置下（使用10%的 TACRED 训练数据）优于各种基线。SURE 还在 TACRED 和 TACREV上 分别以75.1%和83.5%的 micro-F1 得分达到了SOTA 性能。我们还进行了全面的消融研究，展示了摘要的间接监督的有效性以及 SURE 输入转换的最佳选项。&lt;/p&gt;</description>
    </item>
    <item>
      <title>《Modular Self-Supervision for Document-Level Relation Extraction》笔记</title>
      <link>http://localhost:1313/posts/papernotes/modular_self-supervision_for_document-level_relation_extraction/</link>
      <pubDate>Sat, 28 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/papernotes/modular_self-supervision_for_document-level_relation_extraction/</guid>
      <description>&lt;h2 id=&#34;link&#34;&gt;Link&lt;/h2&gt;
&lt;p&gt;[&lt;a href=&#34;https://arxiv.org/abs/2109.05362&#34;&gt;2109.05362] Modular Self-Supervision for Document-Level Relation Extraction (arxiv.org)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Accepted at EMNLP 2021&lt;/p&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;
&lt;p&gt;信息抽取的先前工作通常集中在句子内的二元关系。然而，实际应用往往需要跨大段文本提取复杂关系。这在生物医学等高价值领域尤为重要，因为获取最新发现的高召回率至关重要。例如，图1显示了一个三元（药物、基因、突变）关系，表明具有 MAP2K1 突变 K57T 的肿瘤对 cobimetinib 敏感，但这些实体从未在同一段落中同时出现。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/PaperNotes/Modular_Self-Supervision_for_Document-Level_Relation_Extraction/img1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;先前的工作都将文档级关系抽取视为一个单一的整体问题，这在推理和学习上都带来了重大挑战。尽管最近取得了一些进展，但在使用最先进的神经架构（如LSTM 和 transformer）建模长文本范围时仍存在显著挑战。此外，直接监督稀缺，任务特定的自监督（如距离监督）在应用于短文本范围之外时变得极其嘈杂。&lt;/p&gt;
&lt;p&gt;在本文中，我们通过将文档级关系抽取分解为局部关系检测和全局推理来探索一种替代范式。具体来说，我们使用 Davidsonian 语义表示 $n$ 元关系，并结合段落级关系分类和使用全局推理规则（例如，参数解析的传递性）的篇章级参数解析。每个组件问题都存在于短文本范围内，其相应的自监督错误率要低得多。我们的方法借鉴了模块化神经网络和神经逻辑编程的灵感，将复杂任务分解为局部神经学习和全局结构化集成。然而，我们不是从端到端的直接监督中学习，而是承认组件问题的模块化自监督（Modular Self-Supervision），这更容易获得。&lt;/p&gt;
&lt;p&gt;这种模块化方法不仅使我们能够处理长文本，还能扩展到所有先前方法无法覆盖的跨段落关系。我们在精准肿瘤学的生物医学机器阅读中进行了全面评估，其中跨段落关系尤为普遍。我们的方法在最具挑战性的关系中表现尤为突出，这些关系的参数从未在段落中同时出现，其F1分数比之前的最先进方法（如多尺度学习（和图神经网络高出20多个百分点。&lt;/p&gt;
&lt;h2 id=&#34;document-level-relation-extraction&#34;&gt;Document-Level Relation Extraction&lt;/h2&gt;
&lt;p&gt;设 $E,R,D$ 分别代表实体、关系、文档，那在图2中的 $R$ 为精准癌症药物反应，实体 $E_1,E_2,E_3$​ 分别药物 cobimetinib、基因 MAP2K1 和突变 K57T。这个关系跨越多个段落和几十个句子。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/PaperNotes/Modular_Self-Supervision_for_Document-Level_Relation_Extraction/img2.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;用新戴维森语义表示 n 元关系抽取：
&lt;/p&gt;
$$
R_D(E_1, \cdots, E_n) \equiv \exists T \in D \exists r. [R_T(r) \land A_1(r, E_1) \land \cdots \land A_n(r, E_n)]
$$&lt;p&gt;
其中，$T$ 为文档 $D$ 中的片段，$r$ 为引入的事件变量以表示 $R$​ 。&lt;/p&gt;</description>
    </item>
    <item>
      <title>《Separating Retention from Extraction in the Evaluation of End-to-end Relation Extraction》笔记</title>
      <link>http://localhost:1313/posts/papernotes/separating_retention_from_extraction/</link>
      <pubDate>Fri, 27 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/papernotes/separating_retention_from_extraction/</guid>
      <description>&lt;h2 id=&#34;link&#34;&gt;Link&lt;/h2&gt;
&lt;p&gt;[&lt;a href=&#34;https://arxiv.org/abs/2109.12008v1&#34;&gt;2109.12008v1] Separating Retention from Extraction in the Evaluation of End-to-end Relation Extraction (arxiv.org)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Accepted at EMNLP 2021&lt;/p&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;
&lt;p&gt;信息抽取（Information Extraction, IE）旨在将文本中表达的信息转换为预定义的结构化知识格式。这个总体目标被分解为更容易自动执行和评估的子任务。因此，命名实体识别（Named Entity Recognition, NER）和关系抽取（Relation Extraction, RE）是两个关键的 IE 任务。传统上，这些任务是通过流水线方式执行的。也可以采用联合方式处理，以建模它们的相互依赖性，减少错误传播并获得更现实的评估设置。&lt;/p&gt;
&lt;p&gt;随着 NLP 领域的总体趋势，最近在实体和关系抽取基准测试中报告的定量改进至少部分归因于使用了越来越大的预训练语言模型（Language Models, LMs），如 BERT 来获得上下文词表示。同时，人们意识到需要新的评估协议，以更好地理解所获得的神经网络模型的优缺点，而不仅仅是对一个保留测试集上的单一整体指标。&lt;/p&gt;
&lt;p&gt;特别是，对未见数据的泛化是评估深度神经网络的关键因素。在涉及提取提及的IE任务中，这一点尤为重要：小范围的词语可能会同时出现在评估和训练数据集中。已证明这种词汇重叠与NER中神经网络的性能相关。对于流水线 RE，神经模型过度依赖候选参数的类型或其上下文中存在的特定触发词。&lt;/p&gt;
&lt;p&gt;在端到端关系抽取中，我们可以预期这些 NER 和 RE 会结合在一起。在这项工作中，我们认为当前的评估基准不仅衡量了从文本中提取信息的能力，还衡量了模型在训练期间简单保留标记的（头、谓词、尾）三元组的能力。当模型在训练期间看到的句子上进行评估时，很难区分这两种行为中的哪一种占主导地位。&lt;/p&gt;
&lt;p&gt;然而，我们可以假设模型可以简单地检索先前看到的信息，像一个被压缩的知识库一样，通过相关查询进行探测。因此，在包含过多已见三元组的示例上进行测试可能会高估模型的泛化能力。&lt;/p&gt;
&lt;p&gt;即使没有标记数据，LMs也能够学习一些单词之间的关系，可以通过填空句子进行探测，其中一个参数被掩盖。&lt;/p&gt;
&lt;h2 id=&#34;datasets-and-models&#34;&gt;Datasets and Models&lt;/h2&gt;
&lt;p&gt;数据集选用了 CoNLL04、ACE05、SciERC。&lt;/p&gt;
&lt;p&gt;模型选用了三个模型：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PURE：Pipeline 模型&lt;/li&gt;
&lt;li&gt;SpERT：Joint 模型&lt;/li&gt;
&lt;li&gt;Two are better than one（TABTO）：Joint 模型&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;partitioning-by-lexical-overlap基于词汇重叠的划分&#34;&gt;Partitioning by Lexical Overlap（基于词汇重叠的划分）&lt;/h2&gt;
&lt;p&gt;我们根据与训练集的词汇重叠情况对测试集中的实体提及进行划分。我们区分了已见和未见的提及，并将这种划分扩展到关系上。&lt;/p&gt;
&lt;p&gt;我们实现了一个简单的保留启发式方法（Retention Heuristic，启发式方法），将训练集中确切存在的实体提及或关系标记为其多数标签。我们在表1中报告了 NER 和 RE 的 Micro-avg. 精度、召回率和 F1 分数。&lt;/p&gt;</description>
    </item>
    <item>
      <title>《Better Few-Shot Relation Extraction with Label Prompt Dropout》笔记</title>
      <link>http://localhost:1313/posts/papernotes/better_few-shot_relation_extraction_with_label_prompt_dropout/</link>
      <pubDate>Sun, 22 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/papernotes/better_few-shot_relation_extraction_with_label_prompt_dropout/</guid>
      <description>&lt;h2 id=&#34;link&#34;&gt;Link&lt;/h2&gt;
&lt;p&gt;[&lt;a href=&#34;https://arxiv.org/abs/2210.13733&#34;&gt;2210.13733] Better Few-Shot Relation Extraction with Label Prompt Dropout (arxiv.org)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Accepted EMNLP 2022.&lt;/p&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;
&lt;p&gt;在这项工作中，我们提出了一种称为标签提示丢弃（&lt;strong&gt;L&lt;/strong&gt;abel &lt;strong&gt;P&lt;/strong&gt;rompt &lt;strong&gt;D&lt;/strong&gt;ropout, LPD）的新方法。我们直接将文本标签和上下文句子连接在一起，并将它们一起输入到 Transformer Encoder 中。文本标签作为标签提示，通过自注意力机制引导和规范 Transformer Encoder 输出标签感知的关系表示。在训练过程中，我们随机丢弃提示标记，使模型必须学会在有和没有关系描述的情况下工作。实验表明，我们的方法在两个标准的FSRE数据集上取得了显著的改进。我们进行了广泛的消融研究，以证明我们方法的有效性。此外，我们强调了先前研究工作评估设置中的一个潜在问题，即预训练数据中包含的关系类型实际上与测试集中的关系类型重叠。我们认为这对于少样本学习来说可能不是一个理想的设置，并表明现有工作的性能提升可能部分归因于这种“知识泄漏”问题。我们建议过滤掉预训练数据中所有重叠的关系类型，并进行更严格的少样本评估。总之，我们做出了以下贡献：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;我们提出了 LPD，一种新的标签提示丢弃方法，使 FSRE 中的文本标签得到了更好的利用。这种简单的设计显著优于以前使用复杂网络结构将文本标签和上下文句子融合的方法。&lt;/li&gt;
&lt;li&gt;我们识别了文献中先前实验设置的局限性，并提出了一个更严格的FSRE评估设置。对于这两种设置，我们都显示出比以前的最先进方法更强的改进。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;related-work&#34;&gt;Related Work&lt;/h2&gt;
&lt;h3 id=&#34;few-shot-relation-extraction&#34;&gt;Few-Shot Relation Extraction&lt;/h3&gt;
&lt;h3 id=&#34;prompt-based-fine-tuning&#34;&gt;Prompt-Based Fine-Tuning&lt;/h3&gt;
&lt;p&gt;基于提示的模型在小样本和零样本学习中表现出色。这一研究方向的模型尝试将下游微调任务与预训练的掩码语言建模目标对齐，以更好地利用预训练语言模型的潜在知识。&lt;/p&gt;
&lt;p&gt;然而，与许多其他自然语言处理任务（如二元情感分析中的“正面/负面”）的标签语义直观不同，关系抽取中的关系类型可能非常复杂，通常需要较长的句子来描述。例如，FewRel 中的关系 P2094 被描述为“由监管机构进行的官方分类，主体（事件、团队、参与者或设备）符合纳入标准”。基于提示的模型在这种情况下会遇到困难，因为它们需要固定的模板（例如，提示模板中的 [MASK] 令牌数量必须固定）。以前的方法不得不依赖手动设计的提示模板，并使用关系名称而不是关系描述。&lt;/p&gt;
&lt;p&gt;为了解决这个问题，我们提出直接使用整个关系描述作为提示，而不使用任何掩码令牌。在传统的基于提示的模型中，提示用于创建自然描述，以便模型可以在 [MASK] 位置进行更好的预测，而本研究中使用的标签提示通过自然描述来帮助规范模型输出更好的类别表示。&lt;/p&gt;
&lt;h2 id=&#34;approach&#34;&gt;Approach&lt;/h2&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/PaperNotes/Better_Few-Shot_Relation_Extraction_with_Label_Prompt_Dropout/img1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;h3 id=&#34;training-with-label-prompt-dropout&#34;&gt;Training with Label Prompt Dropout&lt;/h3&gt;
&lt;p&gt;对于每个支持实例，我们直接将关系描述和上下文句子用“:”连接起来。例如，句子“北京举办了2022年冬季奥运会”将变成“事件地点: 北京举办了2022年冬季奥运会。” 这个想法是创建一个自然的实例，其中定义首先给出，然后是例子。关系描述和冒号作为标签提示，引导 Transformer Encoder 输出一个标签感知的关系表示。为了防止模型完全依赖标签提示而忽略上下文句子，标签提示会以 $α_{train}$ 的概率随机丢弃。例如，上图中的支持实例“十进制数最早在印度发展起来”保持其初始形式，因为其标签提示被丢弃了。对于查询实例，我们直接输入句子而不带任何标签提示。这是因为查询集本质上与测试集相同，我们不应假设可以访问真实知识。随后，使用特殊实体标记来标记头部和尾部，并在句子的前后添加特殊的分类和分隔标记，例如“[CLS] 事件地点: [E1] 北京 [/E1] 举办了 [E2] 2022年冬季奥运会 [/E2]。” 解析后的句子然后被送入Transformer Encoder。&lt;/p&gt;</description>
    </item>
    <item>
      <title>《Making Pre-trained Language Models Better Continual Few-Shot Relation Extractors》笔记</title>
      <link>http://localhost:1313/posts/papernotes/making_pre-trained_language_models_better_continual_few-shot_relation_extractors/</link>
      <pubDate>Fri, 20 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/papernotes/making_pre-trained_language_models_better_continual_few-shot_relation_extractors/</guid>
      <description>&lt;h2 id=&#34;link&#34;&gt;Link&lt;/h2&gt;
&lt;p&gt;[&lt;a href=&#34;https://arxiv.org/abs/2402.15713&#34;&gt;2402.15713] Making Pre-trained Language Models Better Continual Few-Shot Relation Extractors (arxiv.org)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Accepted COLING 2024&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;COLING: CCF B&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;
&lt;p&gt;关系抽取是自然语言处理领域中的一个基本且重要的任务，旨在从句子或文档中提取实体之间的潜在关系。传统的 RE 方法在大量标注样本上训练模型，然后在具有相同标签空间的数据上进行测试。然而，在现实生活中，新关系不断涌现，这些模型在适应新关系时可能会出现显著的性能下降。此外，这些模型严重依赖于大量标注数据，这需要大量时间和精力来收集。&lt;/p&gt;
&lt;p&gt;因此，提出了&lt;strong&gt;持续少样本关系抽取（Continual Few-shot Relation Extraction, CFRE）&lt;/strong&gt;，其目标是在有限的标注数据约束下，持续学习新关系的同时保留先前学习的关系知识。这一实际任务带来了两个重大挑战：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;灾难性遗忘&lt;/strong&gt;：模型在学习新任务时突然忘记从前任务中获得的知识。最新研究指出，即使在大型语言模型中也存在灾难性遗忘问题，这使得这一问题值得研究。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;过拟合&lt;/strong&gt;：模型在训练数据上表现异常好，但由于拟合噪声或无关模式，无法有效泛化到未见数据，这在训练数据稀少的低资源场景中更为明显。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;总结一下，我们的主要贡献包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;我们利用提示学习来探索预训练语言模型（PLM）的隐含能力，并提出了 &lt;strong&gt;C&lt;/strong&gt;ontrastive &lt;strong&gt;P&lt;/strong&gt;rompt &lt;strong&gt;L&lt;/strong&gt;earning framework (CPL) 框架，将其与一种新的基于边际的对比学习目标（CFRL）结合起来，同时缓解灾难性遗忘和过拟合问题。&lt;/li&gt;
&lt;li&gt;我们通过利用大型语言模型（LLM）的力量引入了一种记忆增强策略，以提升较小的 PLM。这种策略使用精心设计的提示来指导 ChatGPT 生成样本，从而更好地对抗过拟合。&lt;/li&gt;
&lt;li&gt;在两个 RE 基准上的大量实验表明，我们的方法优于最先进的模型，证明了缓解灾难性遗忘和过拟合的有效性。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;related-work&#34;&gt;Related Work&lt;/h2&gt;
&lt;h3 id=&#34;continual-learning&#34;&gt;Continual Learning&lt;/h3&gt;
&lt;p&gt;持续学习（Continual Learning, CL）旨在从一系列任务中不断学习新知识，同时避免遗忘旧知识。CL的主要挑战是灾难性遗忘。&lt;/p&gt;
&lt;p&gt;现有的CL方法分为三类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;正则化方法&lt;/strong&gt;：使用额外的约束来限制参数更新，使模型能够记住更多旧知识。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;动态架构方法&lt;/strong&gt;：动态扩展模型架构，以在任务序列不断出现时存储新知识。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;基于记忆的方法&lt;/strong&gt;：存储当前任务的一些典型样本，并在学习任务序列后重放记忆以复习旧知识。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在这些方法中，基于记忆的方法在自然语言处理（NLP）任务中最为有效。然而，新任务的数据并不总是充足的，而且获取高质量数据往往既昂贵又耗时。我们也采用基于记忆的策略，但我们更注重如何更好地利用预训练语言模型（PLMs）来解决 CFRE。&lt;/p&gt;
&lt;h3 id=&#34;prompt-learning&#34;&gt;Prompt Learning&lt;/h3&gt;
&lt;p&gt;提示学习随着GPT-3系列的诞生而出现，并在自然语言处理任务中取得了显著的性能，尤其是在小样本场景中。它通过添加提示词将下游任务重新表述为预训练任务，并引导预训练语言模型（PLMs）理解各种任务。之前的提示学习方法可以分为三类：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;硬提示&lt;/strong&gt;：在句子中添加手工制作的提示词，并将其转换为掩码语言建模问题。尽管有效，但它需要针对不同任务的复杂专家知识，这既繁琐又耗时。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;软提示&lt;/strong&gt;：在句子中添加可连续训练的向量，这些向量可以被模型自动学习。然而，在没有任何先验专家知识的情况下，模型并不总能学到合适的提示，尤其是在低资源场景中。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;混合提示&lt;/strong&gt;：结合不可调的硬提示和可调的软提示，使模型能够在少量人工干预下轻松学习合适的模板。它被验证为最有效的方法。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;我们专注于少样本设置，并采用混合提示来帮助预训练语言模型（PLMs）缓解灾难性遗忘和过拟合问题。&lt;/p&gt;
&lt;h2 id=&#34;method&#34;&gt;Method&lt;/h2&gt;
&lt;h3 id=&#34;framework-overview&#34;&gt;Framework Overview&lt;/h3&gt;
&lt;p&gt;整个 CPL 框架有三个模块：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Prompt Representation，Contrastive Learning，Memory Augmentation&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/PaperNotes/Making_Pre-trained_Language_Models_Better_Continual_Few-Shot_Relation_Extractors/img1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;</description>
    </item>
    <item>
      <title>《Efficient Information Extraction in Few-Shot Relation Classification through Contrastive Representation Learning》笔记</title>
      <link>http://localhost:1313/posts/papernotes/efficient_information_extraction_in_few-shot_relation_classification_through_contrastive_representation_learning/</link>
      <pubDate>Thu, 19 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/papernotes/efficient_information_extraction_in_few-shot_relation_classification_through_contrastive_representation_learning/</guid>
      <description>&lt;h2 id=&#34;link&#34;&gt;Link&lt;/h2&gt;
&lt;p&gt;[&lt;a href=&#34;https://arxiv.org/abs/2403.16543&#34;&gt;2403.16543] Efficient Information Extraction in Few-Shot Relation Classification through Contrastive Representation Learning (arxiv.org)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Accepted NAACL 2024.&lt;/p&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;
&lt;p&gt;关系分类（Relation Classification, RC）是关系抽取中的一个重要子任务，主要关注在给定文本上下文中识别实体对之间的关系类型。为了实现这一目标，RC 模型必须从句子中提取丰富的信息，包括上下文线索、实体属性和关系特征。虽然语言模型在提取文本表示方面重要，但它们在句子表示中的向量空间使用并不理想。为了改进这一点，最近的研究通过各种技术增强了句子表示。&lt;/p&gt;
&lt;p&gt;关系抽取在许多关系类型上面临数据有限的挑战，并且数据获取成本不成比例。为了解决这一挑战，通过小样本 RC 训练模型以快速适应新关系类型，仅使用少量标记示例。&lt;/p&gt;
&lt;p&gt;由于区分各种关系类型的内在复杂性，RC 应用通常将实体标记令牌的表示作为句子表示。最近的工作在少样本 RC 中使用对比学习以获得更具辨别力的表示。此外，研究表明，通过提示使用 [MASK] 令牌表示句子可以改善句子表示。&lt;/p&gt;
&lt;p&gt;本文贡献如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;新方法&lt;/strong&gt;：我们引入了一种使用对比学习对齐多重表示的方法，用于小样本关系分类。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;适应性&lt;/strong&gt;：我们的方法能够适应各种资源限制，并扩展到包括关系描述在内的额外信息源。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;资源效率&lt;/strong&gt;：我们强调了该方法的资源效率，提升了在低资源环境下的性能。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;实体标记：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;实体标记技术通过在输入句子中添加标记来指示文本中的实体。例如，句子“他在2006年世界杯上为墨西哥效力”可以被标记为“他在[E1S]2006年世界杯[E1E]上为[E2S]墨西哥[E2E]效力”。&lt;/li&gt;
&lt;li&gt;在 BERT 编码器中，句子的表示是通过连接实体开始标记的表示来构建的。这种方法增强了模型对实体及其关系的理解。&lt;/li&gt;
&lt;li&gt;这种技术有助于模型更好地捕捉句子中的上下文线索、实体属性和关系特征，从而提高关系分类的准确性。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;对比学习：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对比学习是一种用于增强模型表示能力的方法，特别是在少样本关系分类任务中。&lt;/li&gt;
&lt;li&gt;对比学习的主要目标是使相似的样本在表示空间中更接近，而使不相似的样本更远离。&lt;/li&gt;
&lt;li&gt;在训练过程中，对比学习会创建正样本对（相似样本）和负样本对（不相似样本），并通过优化模型使正样本对的表示更接近，负样本对的表示更远。而表现在损失函数中，对比学习的损失函数旨在最大化同一输入句子不同表示之间的相似性，同时最小化不同输入句子表示之间的相似性。&lt;/li&gt;
&lt;li&gt;在少样本关系分类中，对比学习通过对齐多个句子表示（如[CLS]标记、[MASK]标记和实体标记）来提取补充的判别信息，从而提高模型在低资源环境中的表现。&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;approach&#34;&gt;Approach&lt;/h2&gt;
&lt;p&gt;方法一览：&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/PaperNotes/Efficient_Information_Extraction_in_Few-Shot_Relation_Classification_through_Contrastive_Representation_Learning/img1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;h3 id=&#34;sentence-representations&#34;&gt;Sentence Representations&lt;/h3&gt;
&lt;p&gt;使用了&lt;strong&gt;平均池化&lt;/strong&gt;从BERT编码器生成各种句子表示。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通过平均 token 表示来计算句子表示。同时，BERT-Base 编码器预训练期间使用 [CLS] 标记作为句子表示，捕捉整个输入序列的信息。实体标记技术通过在文本中标记实体来增强输入句子。这将输入增强为 $x = [x_0, …, [E1S], x_i, [E1E], …, x_n]$ 。句子表示通过连接实体开始标记表示 [E1S] 和 [E2S] 构建。&lt;/li&gt;
&lt;li&gt;在 Prompt 方法中，RC 任务被重新表述为掩码语言建模问题。使用模板 T，每个输入被转换为包含至少一个 [MASK] 标记的 $x_{prompt} = T(x)$ 。这个掩码标记表示关系标签，并从上下文中预测，例如 $\hat x = [MASK]: x$​ 。&lt;/li&gt;
&lt;li&gt;使用 dropout 掩码生成增强句子表示的方法。由于实体标记表示不适用于关系描述，我们使用提示和[CLS]表示，并使用不同的dropout掩码。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Prompt-Mask Method&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>《Entity Concept-enhanced Few-shot Relation Extraction》笔记</title>
      <link>http://localhost:1313/posts/papernotes/entity_concept-enhanced_few-shot_relation_extraction/</link>
      <pubDate>Wed, 18 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/papernotes/entity_concept-enhanced_few-shot_relation_extraction/</guid>
      <description>&lt;h2 id=&#34;link&#34;&gt;Link&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2106.02401&#34;&gt;2106.02401 (arxiv.org)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Accepted ACL 2021。&lt;/p&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;
&lt;p&gt;小样本关系抽取（FSRE）大致可以分为两类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;仅使用纯文本数据，不包含外部信息。如：Siamese、Prototypical、BERT-PAIR&lt;/li&gt;
&lt;li&gt;引入外部信息，以补偿 FSRE 的信息不足，如：TD-Proto&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;虽然引入文本描述的知识可以为 FSRE 提供外部信息并实现最先进的性能，但 TD-Proto 仅为每个实体引入一个 Wikidata 中的文本描述。然而，这可能会因为实体和文本描述之间的不匹配而导致性能下降。此外，由于每个实体的文本描述通常较长，提取长文本描述中最有用的信息并不容易。&lt;/p&gt;
&lt;p&gt;与长文本描述相比，概念是对实体的直观和简洁的描述，可以从概念数据库（如 YAGO3、ConceptNet 和 Concept Graph 等）中轻松获得。此外，概念比每个实体的具体文本描述更抽象，这是对 FSRE 场景中有限信息的理想补充。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/PaperNotes/Entity_Concept-enhanced_Few-shot_Relation_Extraction/img1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;为了应对上述挑战，我们提出了一种新的实体概念增强的少样本关系抽取方案（&lt;strong&gt;CONCEPT&lt;/strong&gt;-enhanced &lt;strong&gt;FE&lt;/strong&gt;w-shot &lt;strong&gt;R&lt;/strong&gt;elation &lt;strong&gt;E&lt;/strong&gt;xtraction，&lt;strong&gt;ConceptFERE&lt;/strong&gt;），该方案引入实体概念以提供有效的关系预测线索。首先，如上表所示，一个实体可能有多个来自不同方面或层次的概念，只有一个概念可能对最终的关系分类有价值。因此，我们设计了一个概念-句子注意力模块，通过比较句子和每个概念的语义相似性来选择最合适的概念。其次，由于句子嵌入和预训练的概念嵌入不是在同一语义空间中学习的，我们采用自注意力机制对句子和选定概念进行词级语义融合，以进行最终的关系分类。&lt;/p&gt;
&lt;h2 id=&#34;model&#34;&gt;Model&lt;/h2&gt;
&lt;p&gt;下图为 ConceptFERE 的结构。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/PaperNotes/Entity_Concept-enhanced_Few-shot_Relation_Extraction/img2.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;h3 id=&#34;system-overview&#34;&gt;System Overview&lt;/h3&gt;
&lt;p&gt;Sentence Representation Module 使用 BERT 作为 Encoder 来获取 Sentence Embedding，Concept Representation Module 使用 skip-grim 在 Wikipedia 文本和概念图上学习概念的表示，得到 Concept Embedding 。Relation Classifier 采用全连接层实现。&lt;/p&gt;
&lt;h3 id=&#34;concept-sentence-attention-module&#34;&gt;Concept-Sentence Attention Module&lt;/h3&gt;
&lt;p&gt;直观上，需要更多关注与句子语义相关度高的概念，这些概念可以为关系抽取提供更有效的线索。&lt;/p&gt;
&lt;p&gt;首先，由于预训练的 Sentence Embedding $v_s$ 和 Concept Embedding  $v_c$ 不是在同一语义空间中学习的，因此不能直接比较语义相似度。所以通过将 $v_c$ 和 $v_s$ 乘以投影矩阵 $P$ 来进行语义转换，以在同一语义空间中获得它们的表示 $v_cP$ 和 $v_sP$ ，其中 $P$ 可以通过全连接网络学习。其次，通过计算句子和每个实体概念之间的语义相似度，得到 $v_c$ 和 $v_s$ 的点积作为相似度 $sim_{cs}$ 。最后，为了从计算的相似度值中选择合适的概念，我们设计了 01-GATE 。相似度值通过 Softmax 函数归一化。如果 $sim_{cs}$ 小于设定的阈值 $α$，01-GATE 将为相应概念的注意力分数分配 0，该概念将在后续的关系分类中被排除。我们选择注意力分数为 1 的合适概念，作为参与关系预测的有效线索。&lt;/p&gt;</description>
    </item>
    <item>
      <title>RAPL: A Relation-Aware Prototype Learning Approach for Few-Shot Document-Level Relation Extraction</title>
      <link>http://localhost:1313/posts/papernotes/rapl/</link>
      <pubDate>Tue, 17 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/papernotes/rapl/</guid>
      <description>&lt;h2 id=&#34;link&#34;&gt;Link&lt;/h2&gt;
&lt;p&gt;[&lt;a href=&#34;https://arxiv.org/abs/2310.15743&#34;&gt;2310.15743] RAPL: A Relation-Aware Prototype Learning Approach for Few-Shot Document-Level Relation Extraction (arxiv.org)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Accepted EMNLP 2023.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;EMNLP：CCF B&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;related-works&#34;&gt;Related Works&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;这一部分内容本来是在论文的最后面，但是考虑到这篇论文也算是打开了新世界的大门，所以把这个放在最前面。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;关系抽取（Relation Extraction，RE）大致可以分为三种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;语句级 RE（Sentence-Level RE）&lt;/strong&gt;：早期的研究主要集中在预测单个句子内两个实体之间的关系。各种基于模式和神经网络的方法在句子级关系抽取上取得了令人满意的结果。然而，句子级关系抽取在抽取范围和规模上有显著的局限性。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;可以说是早期的 RE 大多是这一类别。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;文档级 RE  （Document-Level RE，DocRE）&lt;/strong&gt;：现有的大多数文档级关系抽取研究都基于数据驱动的监督场景，通常分为基于图和基于序列的方法。基于图的方法通常通过图结构抽象文档，并使用图神经网络进行推理。基于序列的方法则使用仅包含变压器的架构来编码长距离的上下文依赖关系。这两类方法在文档级关系抽取中都取得了令人印象深刻的结果。然而，这些方法对大规模标注文档的依赖使得它们难以适应低资源场景。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;小样本文档级 RE （Few-Shot Document-Level RE，FSDLRE）&lt;/strong&gt;：为了应对现实世界文档级关系抽取场景中普遍存在的数据稀缺问题，&lt;a href=&#34;https://aclanthology.org/2022.naacl-main.421/&#34;&gt;Popovic等&lt;/a&gt;将文档级关系抽取任务形式化为小样本学习任务。为了完成这一任务，他们提出了多种基于度量的模型，这些模型建立在最先进的监督文档级关系抽取方法和少样本句子级关系抽取方法的基础上，旨在解决不同任务设置的问题。有效的基于度量的少样本文档级关系抽取方法的每个类别的原型应该准确捕捉相应的关系语义。然而，由于现有方法的粗粒度关系原型学习策略和”一刀切”的 NOTA 原型学习策略，这对现有方法来说是一个挑战。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;术语解释：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;原型学习（Prototype-Based Learning）是一种通过存储一组代表性样本（原型）来进行分类、回归或聚类的学习方法。原型学习的主要步骤包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;选择原型&lt;/strong&gt;：从训练数据中选择一组代表性的样本作为原型。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;计算距离&lt;/strong&gt;：使用距离度量（如欧氏距离、曼哈顿距离等）来确定测试样本与原型之间的相似性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;分类或聚类&lt;/strong&gt;：将测试样本分配给最接近的原型，从而确定其所属的类别或簇。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;NOTA Prototype&lt;/strong&gt; 在本文中指的是 &lt;strong&gt;“None-Of-The-Above”&lt;/strong&gt; 原型，用于处理那些不属于任何目标关系类型的实体对。以下是其主要特点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;任务特定&lt;/strong&gt;：每个任务生成特定的 NOTA 原型，以更好地捕捉该任务中的 NOTA 语义。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;基础原型&lt;/strong&gt;：引入一组可学习的基础 NOTA 原型，这些原型需要在每个任务中进一步修正。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;支持实例选择&lt;/strong&gt;：从支持文档中选择 NOTA 实例，并将其与基础NOTA原型融合，生成最终的任务特定NOTA 原型。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;语义捕捉&lt;/strong&gt;：通过这种方法，NOTA 原型不仅包含了元学习的通用知识，还能捕捉每个任务中的特定NOTA 语义。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;
&lt;p&gt;FSDLRE 任务的简单描述：&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/PaperNotes/RAPL/img1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
