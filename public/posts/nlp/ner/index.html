<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Named Entity Recognition 相关概念与技术 | KurongBlog</title>
<meta name=keywords content="NLP,NER,KnowledgeGraph"><meta name=description content="命名实体识别快速入门"><meta name=author content="Kurong"><link rel=canonical href=http://localhost:1313/posts/nlp/ner/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/posts/nlp/ner/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],throwOnError:!1})})</script><meta property="og:title" content="Named Entity Recognition 相关概念与技术"><meta property="og:description" content="命名实体识别快速入门"><meta property="og:type" content="article"><meta property="og:url" content="http://localhost:1313/posts/nlp/ner/"><meta property="og:image" content="http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-07-05T00:00:00+00:00"><meta property="article:modified_time" content="2024-07-05T00:00:00+00:00"><meta property="og:site_name" content="KurongBlog"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Named Entity Recognition 相关概念与技术"><meta name=twitter:description content="命名实体识别快速入门"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:1313/posts/"},{"@type":"ListItem","position":2,"name":"Named Entity Recognition 相关概念与技术","item":"http://localhost:1313/posts/nlp/ner/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Named Entity Recognition 相关概念与技术","name":"Named Entity Recognition 相关概念与技术","description":"命名实体识别快速入门","keywords":["NLP","NER","KnowledgeGraph"],"articleBody":"基本概念 实体：通常指文本中具有特定意义或指代性强的词或短语，如人名、地名、机构名等。 边界识别：确定实体在文本中的起始和结束位置。 分类：将识别出的实体归类到预定义的类别，如人名、地名、组织名、时间表达式、数量、货币值、百分比等。 序列标注：NER任务中常用的一种方法，将文本中的每个词标注为实体的一部分或非实体。 特征提取：从文本中提取有助于实体识别的特征，如词性、上下文信息等。 评估指标：用于衡量NER系统性能的指标，常见的有精确率（Precision）、召回率（Recall）和F1分数。 分类命名方法 BIO：这是最基本的标注方法，其中\"B\"代表实体的开始（Begin），“I\"代表实体的内部（Inside），而\"O\"代表非实体（Outside）。 BIOES：这种方法在BIO的基础上增加了\"E\"表示实体的结束（End），和\"S\"表示单独的实体（Single）。 BMES：这种方法使用\"B\"表示实体的开始，“M\"表示实体的中间（Middle），“E\"表示实体的结束，“S\"表示单个字符实体。 NER 的一般过程 数据准备：收集并标注一个包含目标实体的数据集。这个数据集应该包含足够的示例，以便模型能够学习如何识别和分类实体。 选择模型架构：选择一个适合任务的模型架构，如基于LSTM的序列模型或者是基于Transformers的预训练模型。 特征工程：根据需要，进行特征工程，提取有助于实体识别的特征，例如词性标注、上下文嵌入等。 模型训练：使用标注好的数据集来训练模型。这通常包括定义损失函数、选择优化器、设置学习率和训练周期等。 评估与优化：在独立的验证集上评估模型性能，使用诸如精确率、召回率和F1分数等指标，并根据结果进行模型调优。 一个小例子 以当前计组KG为例。\n数据集 数据格式见 transformers/examples/pytorch/token-classification at main · huggingface/transformers (github.com)\n数据来源：\n通过百度百科爬虫 BaiduSpider/BaiduSpider: BaiduSpider，一个爬取百度搜索结果的爬虫，目前支持百度网页搜索，百度图片搜索，百度知道搜索，百度视频搜索，百度资讯搜索，百度文库搜索，百度经验搜索和百度百科搜索。 (github.com) 爬取计算机组合原理的相关术语 从计组教材中提取出文本 数据处理：\n去掉无用字符、HTML标签等无关信息 使用Tokenizer将文本数据分解成Token 根据Token创建词汇表，每个唯一的Token对应一个唯一的索引 将文本中的Token转换为对应的索引值，以便模型能够处理 添加位置编码，以便模型能够理解Token在序列中的位置 数据集划分：\n将数据集划分为训练集、验证集和测试集 格式化数据集：\n使数据集符合transformer库NER任务模型的输入格式 模型 选用中文NER预训练模型：ckiplab/albert-base-chinese-ner · Hugging Face\n选用peft框架微调：peft/examples/token_classification at main · huggingface/peft (github.com)\n训练和测试 一般过程，略。\n应用 可以应用在语料中识别实体了。\n关系抽取 NER的下一步就是关系抽取了\n","wordCount":"62","inLanguage":"en","image":"http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E","datePublished":"2024-07-05T00:00:00Z","dateModified":"2024-07-05T00:00:00Z","author":{"@type":"Person","name":"Kurong"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/posts/nlp/ner/"},"publisher":{"@type":"Organization","name":"KurongBlog","logo":{"@type":"ImageObject","url":"http://localhost:1313/%3Clink%20/%20abs%20url%3E"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Home (Alt + H)"><img src=http://localhost:1313/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/categories/ title=categories><span>categories</span></a></li><li><a href=http://localhost:1313/tags/ title=tags><span>tags</span></a></li><li><a href=http://localhost:1313/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a>&nbsp;»&nbsp;<a href=http://localhost:1313/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Named Entity Recognition 相关概念与技术</h1><div class=post-description>命名实体识别快速入门</div><div class=post-meta><span title='2024-07-05 00:00:00 +0000 UTC'>July 5, 2024</span>&nbsp;·&nbsp;Kurong&nbsp;|&nbsp;<a href=https://github.com/KurongTohsaka/KurongTohsaka.github.io/content/posts/NLP/NER.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#基本概念>基本概念</a></li><li><a href=#分类命名方法>分类命名方法</a></li><li><a href=#ner-的一般过程>NER 的一般过程</a></li><li><a href=#一个小例子>一个小例子</a><ul><li><a href=#数据集>数据集</a></li><li><a href=#模型>模型</a></li><li><a href=#训练和测试>训练和测试</a></li><li><a href=#应用>应用</a></li><li><a href=#关系抽取>关系抽取</a></li></ul></li></ul></nav></div></details></div><div class=post-content><h2 id=基本概念>基本概念<a hidden class=anchor aria-hidden=true href=#基本概念>#</a></h2><ol><li><strong>实体</strong>：通常指文本中具有特定意义或指代性强的词或短语，如人名、地名、机构名等。</li><li><strong>边界识别</strong>：确定实体在文本中的起始和结束位置。</li><li><strong>分类</strong>：将识别出的实体归类到预定义的类别，如人名、地名、组织名、时间表达式、数量、货币值、百分比等。</li><li><strong>序列标注</strong>：NER任务中常用的一种方法，将文本中的每个词标注为实体的一部分或非实体。</li><li><strong>特征提取</strong>：从文本中提取有助于实体识别的特征，如词性、上下文信息等。</li><li><strong>评估指标</strong>：用于衡量NER系统性能的指标，常见的有精确率（Precision）、召回率（Recall）和F1分数。</li></ol><h2 id=分类命名方法>分类命名方法<a hidden class=anchor aria-hidden=true href=#分类命名方法>#</a></h2><ol><li><strong>BIO</strong>：这是最基本的标注方法，其中"B"代表实体的开始（Begin），&ldquo;I"代表实体的内部（Inside），而"O"代表非实体（Outside）。</li><li><strong>BIOES</strong>：这种方法在BIO的基础上增加了"E"表示实体的结束（End），和"S"表示单独的实体（Single）。</li><li><strong>BMES</strong>：这种方法使用"B"表示实体的开始，&ldquo;M"表示实体的中间（Middle），&ldquo;E"表示实体的结束，&ldquo;S"表示单个字符实体。</li></ol><h2 id=ner-的一般过程>NER 的一般过程<a hidden class=anchor aria-hidden=true href=#ner-的一般过程>#</a></h2><ol><li><strong>数据准备</strong>：收集并标注一个包含目标实体的数据集。这个数据集应该包含足够的示例，以便模型能够学习如何识别和分类实体。</li><li><strong>选择模型架构</strong>：选择一个适合任务的模型架构，如基于LSTM的序列模型或者是基于Transformers的预训练模型。</li><li><strong>特征工程</strong>：根据需要，进行特征工程，提取有助于实体识别的特征，例如词性标注、上下文嵌入等。</li><li><strong>模型训练</strong>：使用标注好的数据集来训练模型。这通常包括定义损失函数、选择优化器、设置学习率和训练周期等。</li><li><strong>评估与优化</strong>：在独立的验证集上评估模型性能，使用诸如精确率、召回率和F1分数等指标，并根据结果进行模型调优。</li></ol><h2 id=一个小例子>一个小例子<a hidden class=anchor aria-hidden=true href=#一个小例子>#</a></h2><p>以当前计组KG为例。</p><h3 id=数据集>数据集<a hidden class=anchor aria-hidden=true href=#数据集>#</a></h3><p>数据格式见 <a href=https://github.com/huggingface/transformers/tree/main/examples/pytorch/token-classification>transformers/examples/pytorch/token-classification at main · huggingface/transformers (github.com)</a></p><p>数据来源：</p><ul><li>通过百度百科爬虫 <a href=https://github.com/BaiduSpider/BaiduSpider>BaiduSpider/BaiduSpider: BaiduSpider，一个爬取百度搜索结果的爬虫，目前支持百度网页搜索，百度图片搜索，百度知道搜索，百度视频搜索，百度资讯搜索，百度文库搜索，百度经验搜索和百度百科搜索。 (github.com)</a> 爬取计算机组合原理的相关术语</li><li>从计组教材中提取出文本</li></ul><p>数据处理：</p><ul><li>去掉无用字符、HTML标签等无关信息</li><li>使用Tokenizer将文本数据分解成Token</li><li>根据Token创建词汇表，每个唯一的Token对应一个唯一的索引</li><li>将文本中的Token转换为对应的索引值，以便模型能够处理</li><li>添加位置编码，以便模型能够理解Token在序列中的位置</li></ul><p>数据集划分：</p><ul><li>将数据集划分为训练集、验证集和测试集</li></ul><p>格式化数据集：</p><ul><li>使数据集符合transformer库NER任务模型的输入格式</li></ul><h3 id=模型>模型<a hidden class=anchor aria-hidden=true href=#模型>#</a></h3><p>选用中文NER预训练模型：<a href="https://huggingface.co/ckiplab/albert-base-chinese-ner?text=%E6%88%91%E5%8F%AB%E8%90%A8%E6%8B%89%EF%BC%8C%E6%88%91%E4%BD%8F%E5%9C%A8%E4%BC%A6%E6%95%A6%E3%80%82">ckiplab/albert-base-chinese-ner · Hugging Face</a></p><p>选用peft框架微调：<a href=https://github.com/huggingface/peft/tree/main/examples/token_classification>peft/examples/token_classification at main · huggingface/peft (github.com)</a></p><h3 id=训练和测试>训练和测试<a hidden class=anchor aria-hidden=true href=#训练和测试>#</a></h3><p>一般过程，略。</p><h3 id=应用>应用<a hidden class=anchor aria-hidden=true href=#应用>#</a></h3><p>可以应用在语料中识别实体了。</p><h3 id=关系抽取>关系抽取<a hidden class=anchor aria-hidden=true href=#关系抽取>#</a></h3><p>NER的下一步就是关系抽取了</p></div><footer class=post-footer><ul class=post-tags><li><a href=http://localhost:1313/tags/nlp/>NLP</a></li><li><a href=http://localhost:1313/tags/ner/>NER</a></li><li><a href=http://localhost:1313/tags/knowledgegraph/>KnowledgeGraph</a></li></ul><nav class=paginav><a class=prev href=http://localhost:1313/posts/cs224n/lesson_5/><span class=title>« Prev</span><br><span>Lecture 5: Language Models and Recurrent Neural Network</span>
</a><a class=next href=http://localhost:1313/posts/cs224n/lesson_4/><span class=title>Next »</span><br><span>Lecture 4: Dependency parsing</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=http://localhost:1313/>KurongBlog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>