<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>RAPL: A Relation-Aware Prototype Learning Approach for Few-Shot Document-Level Relation Extraction | KurongBlog</title>
<meta name=keywords content="PaperNotes,RE,EMNLP,Meta Learning,Few-Shot Learning"><meta name=description content="Link
[2310.15743] RAPL: A Relation-Aware Prototype Learning Approach for Few-Shot Document-Level Relation Extraction (arxiv.org)
Accepted EMNLP 2023.

EMNLP：CCF B

Related Works

这一部分内容本来是在论文的最后面，但是考虑到这篇论文也算是打开了新世界的大门，所以把这个放在最前面。

关系抽取（Relation Extraction，RE）大致可以分为三种：


语句级 RE（Sentence-Level RE）：早期的研究主要集中在预测单个句子内两个实体之间的关系。各种基于模式和神经网络的方法在句子级关系抽取上取得了令人满意的结果。然而，句子级关系抽取在抽取范围和规模上有显著的局限性。

可以说是早期的 RE 大多是这一类别。



文档级 RE  （Document-Level RE，DocRE）：现有的大多数文档级关系抽取研究都基于数据驱动的监督场景，通常分为基于图和基于序列的方法。基于图的方法通常通过图结构抽象文档，并使用图神经网络进行推理。基于序列的方法则使用仅包含变压器的架构来编码长距离的上下文依赖关系。这两类方法在文档级关系抽取中都取得了令人印象深刻的结果。然而，这些方法对大规模标注文档的依赖使得它们难以适应低资源场景。


小样本文档级 RE （Few-Shot Document-Level RE，FSDLRE）：为了应对现实世界文档级关系抽取场景中普遍存在的数据稀缺问题，Popovic等将文档级关系抽取任务形式化为小样本学习任务。为了完成这一任务，他们提出了多种基于度量的模型，这些模型建立在最先进的监督文档级关系抽取方法和少样本句子级关系抽取方法的基础上，旨在解决不同任务设置的问题。有效的基于度量的少样本文档级关系抽取方法的每个类别的原型应该准确捕捉相应的关系语义。然而，由于现有方法的粗粒度关系原型学习策略和”一刀切”的 NOTA 原型学习策略，这对现有方法来说是一个挑战。

术语解释：


原型学习（Prototype-Based Learning）是一种通过存储一组代表性样本（原型）来进行分类、回归或聚类的学习方法。原型学习的主要步骤包括：

选择原型：从训练数据中选择一组代表性的样本作为原型。
计算距离：使用距离度量（如欧氏距离、曼哈顿距离等）来确定测试样本与原型之间的相似性。
分类或聚类：将测试样本分配给最接近的原型，从而确定其所属的类别或簇。



NOTA Prototype 在本文中指的是 “None-Of-The-Above” 原型，用于处理那些不属于任何目标关系类型的实体对。以下是其主要特点：


任务特定：每个任务生成特定的 NOTA 原型，以更好地捕捉该任务中的 NOTA 语义。


基础原型：引入一组可学习的基础 NOTA 原型，这些原型需要在每个任务中进一步修正。


支持实例选择：从支持文档中选择 NOTA 实例，并将其与基础NOTA原型融合，生成最终的任务特定NOTA 原型。


语义捕捉：通过这种方法，NOTA 原型不仅包含了元学习的通用知识，还能捕捉每个任务中的特定NOTA 语义。







Intro
FSDLRE 任务的简单描述：

"><meta name=author content="Kurong"><link rel=canonical href=http://localhost:1313/posts/papernotes/rapl/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/posts/papernotes/rapl/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],throwOnError:!1})})</script><meta property="og:title" content="RAPL: A Relation-Aware Prototype Learning Approach for Few-Shot Document-Level Relation Extraction"><meta property="og:description" content="Link
[2310.15743] RAPL: A Relation-Aware Prototype Learning Approach for Few-Shot Document-Level Relation Extraction (arxiv.org)
Accepted EMNLP 2023.

EMNLP：CCF B

Related Works

这一部分内容本来是在论文的最后面，但是考虑到这篇论文也算是打开了新世界的大门，所以把这个放在最前面。

关系抽取（Relation Extraction，RE）大致可以分为三种：


语句级 RE（Sentence-Level RE）：早期的研究主要集中在预测单个句子内两个实体之间的关系。各种基于模式和神经网络的方法在句子级关系抽取上取得了令人满意的结果。然而，句子级关系抽取在抽取范围和规模上有显著的局限性。

可以说是早期的 RE 大多是这一类别。



文档级 RE  （Document-Level RE，DocRE）：现有的大多数文档级关系抽取研究都基于数据驱动的监督场景，通常分为基于图和基于序列的方法。基于图的方法通常通过图结构抽象文档，并使用图神经网络进行推理。基于序列的方法则使用仅包含变压器的架构来编码长距离的上下文依赖关系。这两类方法在文档级关系抽取中都取得了令人印象深刻的结果。然而，这些方法对大规模标注文档的依赖使得它们难以适应低资源场景。


小样本文档级 RE （Few-Shot Document-Level RE，FSDLRE）：为了应对现实世界文档级关系抽取场景中普遍存在的数据稀缺问题，Popovic等将文档级关系抽取任务形式化为小样本学习任务。为了完成这一任务，他们提出了多种基于度量的模型，这些模型建立在最先进的监督文档级关系抽取方法和少样本句子级关系抽取方法的基础上，旨在解决不同任务设置的问题。有效的基于度量的少样本文档级关系抽取方法的每个类别的原型应该准确捕捉相应的关系语义。然而，由于现有方法的粗粒度关系原型学习策略和”一刀切”的 NOTA 原型学习策略，这对现有方法来说是一个挑战。

术语解释：


原型学习（Prototype-Based Learning）是一种通过存储一组代表性样本（原型）来进行分类、回归或聚类的学习方法。原型学习的主要步骤包括：

选择原型：从训练数据中选择一组代表性的样本作为原型。
计算距离：使用距离度量（如欧氏距离、曼哈顿距离等）来确定测试样本与原型之间的相似性。
分类或聚类：将测试样本分配给最接近的原型，从而确定其所属的类别或簇。



NOTA Prototype 在本文中指的是 “None-Of-The-Above” 原型，用于处理那些不属于任何目标关系类型的实体对。以下是其主要特点：


任务特定：每个任务生成特定的 NOTA 原型，以更好地捕捉该任务中的 NOTA 语义。


基础原型：引入一组可学习的基础 NOTA 原型，这些原型需要在每个任务中进一步修正。


支持实例选择：从支持文档中选择 NOTA 实例，并将其与基础NOTA原型融合，生成最终的任务特定NOTA 原型。


语义捕捉：通过这种方法，NOTA 原型不仅包含了元学习的通用知识，还能捕捉每个任务中的特定NOTA 语义。







Intro
FSDLRE 任务的简单描述：

"><meta property="og:type" content="article"><meta property="og:url" content="http://localhost:1313/posts/papernotes/rapl/"><meta property="og:image" content="http://localhost:1313/cover/RAPL.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-09-17T00:00:00+00:00"><meta property="article:modified_time" content="2024-09-17T00:00:00+00:00"><meta property="og:site_name" content="KurongBlog"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://localhost:1313/cover/RAPL.png"><meta name=twitter:title content="RAPL: A Relation-Aware Prototype Learning Approach for Few-Shot Document-Level Relation Extraction"><meta name=twitter:description content="Link
[2310.15743] RAPL: A Relation-Aware Prototype Learning Approach for Few-Shot Document-Level Relation Extraction (arxiv.org)
Accepted EMNLP 2023.

EMNLP：CCF B

Related Works

这一部分内容本来是在论文的最后面，但是考虑到这篇论文也算是打开了新世界的大门，所以把这个放在最前面。

关系抽取（Relation Extraction，RE）大致可以分为三种：


语句级 RE（Sentence-Level RE）：早期的研究主要集中在预测单个句子内两个实体之间的关系。各种基于模式和神经网络的方法在句子级关系抽取上取得了令人满意的结果。然而，句子级关系抽取在抽取范围和规模上有显著的局限性。

可以说是早期的 RE 大多是这一类别。



文档级 RE  （Document-Level RE，DocRE）：现有的大多数文档级关系抽取研究都基于数据驱动的监督场景，通常分为基于图和基于序列的方法。基于图的方法通常通过图结构抽象文档，并使用图神经网络进行推理。基于序列的方法则使用仅包含变压器的架构来编码长距离的上下文依赖关系。这两类方法在文档级关系抽取中都取得了令人印象深刻的结果。然而，这些方法对大规模标注文档的依赖使得它们难以适应低资源场景。


小样本文档级 RE （Few-Shot Document-Level RE，FSDLRE）：为了应对现实世界文档级关系抽取场景中普遍存在的数据稀缺问题，Popovic等将文档级关系抽取任务形式化为小样本学习任务。为了完成这一任务，他们提出了多种基于度量的模型，这些模型建立在最先进的监督文档级关系抽取方法和少样本句子级关系抽取方法的基础上，旨在解决不同任务设置的问题。有效的基于度量的少样本文档级关系抽取方法的每个类别的原型应该准确捕捉相应的关系语义。然而，由于现有方法的粗粒度关系原型学习策略和”一刀切”的 NOTA 原型学习策略，这对现有方法来说是一个挑战。

术语解释：


原型学习（Prototype-Based Learning）是一种通过存储一组代表性样本（原型）来进行分类、回归或聚类的学习方法。原型学习的主要步骤包括：

选择原型：从训练数据中选择一组代表性的样本作为原型。
计算距离：使用距离度量（如欧氏距离、曼哈顿距离等）来确定测试样本与原型之间的相似性。
分类或聚类：将测试样本分配给最接近的原型，从而确定其所属的类别或簇。



NOTA Prototype 在本文中指的是 “None-Of-The-Above” 原型，用于处理那些不属于任何目标关系类型的实体对。以下是其主要特点：


任务特定：每个任务生成特定的 NOTA 原型，以更好地捕捉该任务中的 NOTA 语义。


基础原型：引入一组可学习的基础 NOTA 原型，这些原型需要在每个任务中进一步修正。


支持实例选择：从支持文档中选择 NOTA 实例，并将其与基础NOTA原型融合，生成最终的任务特定NOTA 原型。


语义捕捉：通过这种方法，NOTA 原型不仅包含了元学习的通用知识，还能捕捉每个任务中的特定NOTA 语义。







Intro
FSDLRE 任务的简单描述：

"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:1313/posts/"},{"@type":"ListItem","position":2,"name":"RAPL: A Relation-Aware Prototype Learning Approach for Few-Shot Document-Level Relation Extraction","item":"http://localhost:1313/posts/papernotes/rapl/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"RAPL: A Relation-Aware Prototype Learning Approach for Few-Shot Document-Level Relation Extraction","name":"RAPL: A Relation-Aware Prototype Learning Approach for Few-Shot Document-Level Relation Extraction","description":"Link [2310.15743] RAPL: A Relation-Aware Prototype Learning Approach for Few-Shot Document-Level Relation Extraction (arxiv.org)\nAccepted EMNLP 2023.\nEMNLP：CCF B\nRelated Works 这一部分内容本来是在论文的最后面，但是考虑到这篇论文也算是打开了新世界的大门，所以把这个放在最前面。\n关系抽取（Relation Extraction，RE）大致可以分为三种：\n语句级 RE（Sentence-Level RE）：早期的研究主要集中在预测单个句子内两个实体之间的关系。各种基于模式和神经网络的方法在句子级关系抽取上取得了令人满意的结果。然而，句子级关系抽取在抽取范围和规模上有显著的局限性。\n可以说是早期的 RE 大多是这一类别。\n文档级 RE （Document-Level RE，DocRE）：现有的大多数文档级关系抽取研究都基于数据驱动的监督场景，通常分为基于图和基于序列的方法。基于图的方法通常通过图结构抽象文档，并使用图神经网络进行推理。基于序列的方法则使用仅包含变压器的架构来编码长距离的上下文依赖关系。这两类方法在文档级关系抽取中都取得了令人印象深刻的结果。然而，这些方法对大规模标注文档的依赖使得它们难以适应低资源场景。\n小样本文档级 RE （Few-Shot Document-Level RE，FSDLRE）：为了应对现实世界文档级关系抽取场景中普遍存在的数据稀缺问题，Popovic等将文档级关系抽取任务形式化为小样本学习任务。为了完成这一任务，他们提出了多种基于度量的模型，这些模型建立在最先进的监督文档级关系抽取方法和少样本句子级关系抽取方法的基础上，旨在解决不同任务设置的问题。有效的基于度量的少样本文档级关系抽取方法的每个类别的原型应该准确捕捉相应的关系语义。然而，由于现有方法的粗粒度关系原型学习策略和”一刀切”的 NOTA 原型学习策略，这对现有方法来说是一个挑战。\n术语解释：\n原型学习（Prototype-Based Learning）是一种通过存储一组代表性样本（原型）来进行分类、回归或聚类的学习方法。原型学习的主要步骤包括：\n选择原型：从训练数据中选择一组代表性的样本作为原型。 计算距离：使用距离度量（如欧氏距离、曼哈顿距离等）来确定测试样本与原型之间的相似性。 分类或聚类：将测试样本分配给最接近的原型，从而确定其所属的类别或簇。 NOTA Prototype 在本文中指的是 “None-Of-The-Above” 原型，用于处理那些不属于任何目标关系类型的实体对。以下是其主要特点：\n任务特定：每个任务生成特定的 NOTA 原型，以更好地捕捉该任务中的 NOTA 语义。\n基础原型：引入一组可学习的基础 NOTA 原型，这些原型需要在每个任务中进一步修正。\n支持实例选择：从支持文档中选择 NOTA 实例，并将其与基础NOTA原型融合，生成最终的任务特定NOTA 原型。\n语义捕捉：通过这种方法，NOTA 原型不仅包含了元学习的通用知识，还能捕捉每个任务中的特定NOTA 语义。\nIntro FSDLRE 任务的简单描述：\n","keywords":["PaperNotes","RE","EMNLP","Meta Learning","Few-Shot Learning"],"articleBody":"Link [2310.15743] RAPL: A Relation-Aware Prototype Learning Approach for Few-Shot Document-Level Relation Extraction (arxiv.org)\nAccepted EMNLP 2023.\nEMNLP：CCF B\nRelated Works 这一部分内容本来是在论文的最后面，但是考虑到这篇论文也算是打开了新世界的大门，所以把这个放在最前面。\n关系抽取（Relation Extraction，RE）大致可以分为三种：\n语句级 RE（Sentence-Level RE）：早期的研究主要集中在预测单个句子内两个实体之间的关系。各种基于模式和神经网络的方法在句子级关系抽取上取得了令人满意的结果。然而，句子级关系抽取在抽取范围和规模上有显著的局限性。\n可以说是早期的 RE 大多是这一类别。\n文档级 RE （Document-Level RE，DocRE）：现有的大多数文档级关系抽取研究都基于数据驱动的监督场景，通常分为基于图和基于序列的方法。基于图的方法通常通过图结构抽象文档，并使用图神经网络进行推理。基于序列的方法则使用仅包含变压器的架构来编码长距离的上下文依赖关系。这两类方法在文档级关系抽取中都取得了令人印象深刻的结果。然而，这些方法对大规模标注文档的依赖使得它们难以适应低资源场景。\n小样本文档级 RE （Few-Shot Document-Level RE，FSDLRE）：为了应对现实世界文档级关系抽取场景中普遍存在的数据稀缺问题，Popovic等将文档级关系抽取任务形式化为小样本学习任务。为了完成这一任务，他们提出了多种基于度量的模型，这些模型建立在最先进的监督文档级关系抽取方法和少样本句子级关系抽取方法的基础上，旨在解决不同任务设置的问题。有效的基于度量的少样本文档级关系抽取方法的每个类别的原型应该准确捕捉相应的关系语义。然而，由于现有方法的粗粒度关系原型学习策略和”一刀切”的 NOTA 原型学习策略，这对现有方法来说是一个挑战。\n术语解释：\n原型学习（Prototype-Based Learning）是一种通过存储一组代表性样本（原型）来进行分类、回归或聚类的学习方法。原型学习的主要步骤包括：\n选择原型：从训练数据中选择一组代表性的样本作为原型。 计算距离：使用距离度量（如欧氏距离、曼哈顿距离等）来确定测试样本与原型之间的相似性。 分类或聚类：将测试样本分配给最接近的原型，从而确定其所属的类别或簇。 NOTA Prototype 在本文中指的是 “None-Of-The-Above” 原型，用于处理那些不属于任何目标关系类型的实体对。以下是其主要特点：\n任务特定：每个任务生成特定的 NOTA 原型，以更好地捕捉该任务中的 NOTA 语义。\n基础原型：引入一组可学习的基础 NOTA 原型，这些原型需要在每个任务中进一步修正。\n支持实例选择：从支持文档中选择 NOTA 实例，并将其与基础NOTA原型融合，生成最终的任务特定NOTA 原型。\n语义捕捉：通过这种方法，NOTA 原型不仅包含了元学习的通用知识，还能捕捉每个任务中的特定NOTA 语义。\nIntro FSDLRE 任务的简单描述：\nIllustration of a 1-Doc FSDLRE task. Entity mentions involved in relation instances are colored and in bold. Other mentions are also in bold for clarity.\n基于度量的元学习（Metric-Based Meta Learning）是广泛采用的 FSDLRE 有效框架，它通过构建类原型进行分类。然而，现有工作在获取具有准确关系语义的类原型时往往存在困难：\n为了构建目标关系类型的原型，它们聚合了所有持有该关系的实体对的表示，而这些实体对可能还持有其他关系，从而干扰了原型。 它们在所有任务中使用一组通用的NOTA（none-of-the-above）原型，忽略了在具有不同目标关系类型的任务中，NOTA语义是不同的。 基于以上两点，本文提出了关系感知原型学习方法（Relation-Aware Prototype Learning，RAPL）。首先，对于支持文档中持有关系的每对实体，我们利用关系描述中的内在关系语义作为指导，推导出每个表达关系的实例级表示，如下图所示。通过聚合所有支持关系实例的表示来构建关系原型，从而更好地聚焦于与关系相关的信息。\nEmbedding space illustration of previous methods (left) and our method (right). Task 1\u00262 are two FSDLRE tasks with different target relation types.\nProblem Formulation The overall architecture of our proposed RAPL method.\nMethodology Document and Entity Encoding 我们使用预训练语言模型作为文档编码器来编码给定任务中的每个支持或查询文档。对于每个文档，我们首先在每个实体提及的开始和结束位置插入一个特殊标记 “*” 以标记实体提及的位置。然后我们将文档输入编码器以获得上下文的 token embedding 和 cross-token attention 。我们将到每个实体前的“*”标记为止的文本作为 mention embedding 。对于文档中提及的实体，我们通过对 mention embedding 进行log-sumexp 池化来获得 entity embedding 。\nRelation-Aware Relation Prototype Learning 对于给定任务中的每个目标关系类型，我们旨在获得一个能够更好地捕捉相应关系语义的原型表示。为此，我们首先提出基于实例级支持嵌入来构建关系原型，使每个原型能够更专注于支持文档中的关系相关信息。然后，我们提出一种实例级关系加权对比学习方法，进一步优化关系原型。\nInstance-Based Prototype Construction 对于支持文档中的关系实例，我们首先计算文档中所有 token 的 pair-level 重要性分布，以捕捉与实体对相关的上下文。同时，我们计算关系级注意力分布，以捕捉与关系相关的上下文。我们使用另一个预训练语言模型作为关系编码器，将关系的名称和描述连接成一个序列，然后将序列输入编码器。我们将“[CLS]”标记的输出嵌入作为 relation embedding 。\n基于 pair-level 和关系级注意力分布，我们进一步计算实例级注意力分布，以捕捉与实例相关的上下文。具体来说，实例级注意力分布的值由 pair-level 和关系级注意力分布的值相加得到。\nContrastive-Based Prototype Refining 之前的方法难以与对比目标整合，因为它们仅获得了对支持集实体对的嵌入。实体对的多标签特性使得合理定义正负对变得困难。此外，通过结合关系间的相似性，提出的对比损失更关注于将语义上接近的关系实例嵌入分开，从而有助于更好地区分相应的关系原型。\nRelation-Aware NOTA Prototype Learning 由于大多数查询实体对不持有任何目标关系，NOTA（none-of-the-above）也被视为一个类别。现有方法通常学习一组通用的 NOTA 原型，应用于所有任务，这在某些任务中可能并不理想。为此，我们提出一种任务特定的 NOTA 原型生成策略，以更好地捕捉每个任务中的 NOTA 语义。\n具体来说，我们首先引入一组可学习的向量，作为基础 NOTA 原型。与直接将这组向量视为最终 NOTA 原型不同，我们将其视为需要在每个任务中进一步修正的基础 NOTA 原型。由于支持文档的注释是完整的，我们可以访问支持 support-NOTA 分布，这隐含地表达了 NOTA 语义。因此，我们利用 support-NOTA 实例来捕捉每个特定任务中的 NOTA 语义。\nTraining Objective 给定查询文档中的实体对，我们使用 pair-level 注意力分布并采用类似的方法获得 pair-level 表示。对于任务中的每个目标关系类型，我们计算关系的概率。然后，我们计算分类损失。\nExperiments Results on FREDo and ReFREDo benchmarks. Reported results are macro averages across relation types. The best and second best performance methods are denoted in bold and underlined respectively.\n","wordCount":"248","inLanguage":"en","image":"http://localhost:1313/cover/RAPL.png","datePublished":"2024-09-17T00:00:00Z","dateModified":"2024-09-17T00:00:00Z","author":{"@type":"Person","name":"Kurong"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/posts/papernotes/rapl/"},"publisher":{"@type":"Organization","name":"KurongBlog","logo":{"@type":"ImageObject","url":"http://localhost:1313/%3Clink%20/%20abs%20url%3E"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Home (Alt + H)"><img src=http://localhost:1313/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/categories/ title=categories><span>categories</span></a></li><li><a href=http://localhost:1313/tags/ title=tags><span>tags</span></a></li><li><a href=http://localhost:1313/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a>&nbsp;»&nbsp;<a href=http://localhost:1313/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">RAPL: A Relation-Aware Prototype Learning Approach for Few-Shot Document-Level Relation Extraction</h1><div class=post-meta><span title='2024-09-17 00:00:00 +0000 UTC'>September 17, 2024</span>&nbsp;·&nbsp;Kurong&nbsp;|&nbsp;<a href=https://github.com/KurongTohsaka/KurongTohsaka.github.io/content/posts/PaperNotes/RAPL.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><figure class=entry-cover><img loading=eager src=http://localhost:1313/cover/RAPL.png alt><p></p></figure><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#link>Link</a></li><li><a href=#related-works>Related Works</a></li><li><a href=#intro>Intro</a></li><li><a href=#problem-formulation>Problem Formulation</a></li><li><a href=#methodology>Methodology</a><ul><li><a href=#document-and-entity-encoding>Document and Entity Encoding</a></li><li><a href=#relation-aware-relation-prototype-learning>Relation-Aware Relation Prototype Learning</a></li><li><a href=#relation-aware-nota-prototype-learning>Relation-Aware NOTA Prototype Learning</a></li><li><a href=#training-objective>Training Objective</a></li></ul></li><li><a href=#experiments>Experiments</a></li></ul></nav></div></details></div><div class=post-content><h2 id=link>Link<a hidden class=anchor aria-hidden=true href=#link>#</a></h2><p>[<a href=https://arxiv.org/abs/2310.15743>2310.15743] RAPL: A Relation-Aware Prototype Learning Approach for Few-Shot Document-Level Relation Extraction (arxiv.org)</a></p><p>Accepted EMNLP 2023.</p><blockquote><p>EMNLP：CCF B</p></blockquote><h2 id=related-works>Related Works<a hidden class=anchor aria-hidden=true href=#related-works>#</a></h2><blockquote><p>这一部分内容本来是在论文的最后面，但是考虑到这篇论文也算是打开了新世界的大门，所以把这个放在最前面。</p></blockquote><p>关系抽取（Relation Extraction，RE）大致可以分为三种：</p><ul><li><p><strong>语句级 RE（Sentence-Level RE）</strong>：早期的研究主要集中在预测单个句子内两个实体之间的关系。各种基于模式和神经网络的方法在句子级关系抽取上取得了令人满意的结果。然而，句子级关系抽取在抽取范围和规模上有显著的局限性。</p><blockquote><p>可以说是早期的 RE 大多是这一类别。</p></blockquote></li><li><p><strong>文档级 RE （Document-Level RE，DocRE）</strong>：现有的大多数文档级关系抽取研究都基于数据驱动的监督场景，通常分为基于图和基于序列的方法。基于图的方法通常通过图结构抽象文档，并使用图神经网络进行推理。基于序列的方法则使用仅包含变压器的架构来编码长距离的上下文依赖关系。这两类方法在文档级关系抽取中都取得了令人印象深刻的结果。然而，这些方法对大规模标注文档的依赖使得它们难以适应低资源场景。</p></li><li><p><strong>小样本文档级 RE （Few-Shot Document-Level RE，FSDLRE）</strong>：为了应对现实世界文档级关系抽取场景中普遍存在的数据稀缺问题，<a href=https://aclanthology.org/2022.naacl-main.421/>Popovic等</a>将文档级关系抽取任务形式化为小样本学习任务。为了完成这一任务，他们提出了多种基于度量的模型，这些模型建立在最先进的监督文档级关系抽取方法和少样本句子级关系抽取方法的基础上，旨在解决不同任务设置的问题。有效的基于度量的少样本文档级关系抽取方法的每个类别的原型应该准确捕捉相应的关系语义。然而，由于现有方法的粗粒度关系原型学习策略和”一刀切”的 NOTA 原型学习策略，这对现有方法来说是一个挑战。</p><blockquote><p>术语解释：</p><ul><li><p>原型学习（Prototype-Based Learning）是一种通过存储一组代表性样本（原型）来进行分类、回归或聚类的学习方法。原型学习的主要步骤包括：</p><ol><li><strong>选择原型</strong>：从训练数据中选择一组代表性的样本作为原型。</li><li><strong>计算距离</strong>：使用距离度量（如欧氏距离、曼哈顿距离等）来确定测试样本与原型之间的相似性。</li><li><strong>分类或聚类</strong>：将测试样本分配给最接近的原型，从而确定其所属的类别或簇。</li></ol></li><li><p><strong>NOTA Prototype</strong> 在本文中指的是 <strong>“None-Of-The-Above”</strong> 原型，用于处理那些不属于任何目标关系类型的实体对。以下是其主要特点：</p><ul><li><p><strong>任务特定</strong>：每个任务生成特定的 NOTA 原型，以更好地捕捉该任务中的 NOTA 语义。</p></li><li><p><strong>基础原型</strong>：引入一组可学习的基础 NOTA 原型，这些原型需要在每个任务中进一步修正。</p></li><li><p><strong>支持实例选择</strong>：从支持文档中选择 NOTA 实例，并将其与基础NOTA原型融合，生成最终的任务特定NOTA 原型。</p></li><li><p><strong>语义捕捉</strong>：通过这种方法，NOTA 原型不仅包含了元学习的通用知识，还能捕捉每个任务中的特定NOTA 语义。</p></li></ul></li></ul></blockquote></li></ul><h2 id=intro>Intro<a hidden class=anchor aria-hidden=true href=#intro>#</a></h2><p>FSDLRE 任务的简单描述：</p><p><img loading=lazy src=/img/PaperNotes/RAPL/img1.png alt></p><blockquote><p>Illustration of a 1-Doc FSDLRE task. Entity mentions involved in relation instances are colored and in bold. Other mentions are also in bold for clarity.</p></blockquote><p>基于度量的元学习（Metric-Based Meta Learning）是广泛采用的 FSDLRE 有效框架，它通过构建类原型进行分类。然而，现有工作在获取具有准确关系语义的类原型时往往存在困难：</p><ol><li>为了构建目标关系类型的原型，它们聚合了所有持有该关系的实体对的表示，而这些实体对可能还持有其他关系，从而干扰了原型。</li><li>它们在所有任务中使用一组通用的NOTA（none-of-the-above）原型，忽略了在具有不同目标关系类型的任务中，NOTA语义是不同的。</li></ol><p>基于以上两点，本文提出了<strong>关系感知原型学习方法（Relation-Aware Prototype Learning，RAPL）</strong>。首先，对于支持文档中持有关系的每对实体，我们利用关系描述中的内在关系语义作为指导，推导出每个表达关系的实例级表示，如下图所示。通过聚合所有支持关系实例的表示来构建关系原型，从而更好地聚焦于与关系相关的信息。</p><p><img loading=lazy src=/img/PaperNotes/RAPL/img2.png alt></p><blockquote><p>Embedding space illustration of previous methods (left) and our method (right). Task 1&amp;2 are two FSDLRE tasks with different target relation types.</p></blockquote><h2 id=problem-formulation>Problem Formulation<a hidden class=anchor aria-hidden=true href=#problem-formulation>#</a></h2><p><img loading=lazy src=/img/PaperNotes/RAPL/img3.png alt></p><blockquote><p>The overall architecture of our proposed RAPL method.</p></blockquote><h2 id=methodology>Methodology<a hidden class=anchor aria-hidden=true href=#methodology>#</a></h2><h3 id=document-and-entity-encoding>Document and Entity Encoding<a hidden class=anchor aria-hidden=true href=#document-and-entity-encoding>#</a></h3><p>我们使用预训练语言模型作为文档编码器来编码给定任务中的每个支持或查询文档。对于每个文档，我们首先在每个实体提及的开始和结束位置插入一个特殊标记 “*” 以标记实体提及的位置。然后我们将文档输入编码器以获得上下文的 token embedding 和 cross-token attention 。我们将到每个实体前的“*”标记为止的文本作为 mention embedding 。对于文档中提及的实体，我们通过对 mention embedding 进行log-sumexp 池化来获得 entity embedding 。</p><h3 id=relation-aware-relation-prototype-learning>Relation-Aware Relation Prototype Learning<a hidden class=anchor aria-hidden=true href=#relation-aware-relation-prototype-learning>#</a></h3><p>对于给定任务中的每个目标关系类型，我们旨在获得一个能够更好地捕捉相应关系语义的原型表示。为此，我们首先提出基于实例级支持嵌入来构建关系原型，使每个原型能够更专注于支持文档中的关系相关信息。然后，我们提出一种实例级关系加权对比学习方法，进一步优化关系原型。</p><h4 id=instance-based-prototype-construction>Instance-Based Prototype Construction<a hidden class=anchor aria-hidden=true href=#instance-based-prototype-construction>#</a></h4><p>对于支持文档中的关系实例，我们首先计算文档中所有 token 的 pair-level 重要性分布，以捕捉与实体对相关的上下文。同时，我们计算关系级注意力分布，以捕捉与关系相关的上下文。我们使用另一个预训练语言模型作为关系编码器，将关系的名称和描述连接成一个序列，然后将序列输入编码器。我们将“[CLS]”标记的输出嵌入作为 relation embedding 。</p><p>基于 pair-level 和关系级注意力分布，我们进一步计算实例级注意力分布，以捕捉与实例相关的上下文。具体来说，实例级注意力分布的值由 pair-level 和关系级注意力分布的值相加得到。</p><h4 id=contrastive-based-prototype-refining>Contrastive-Based Prototype Refining<a hidden class=anchor aria-hidden=true href=#contrastive-based-prototype-refining>#</a></h4><p>之前的方法难以与对比目标整合，因为它们仅获得了对支持集实体对的嵌入。实体对的多标签特性使得合理定义正负对变得困难。此外，通过结合关系间的相似性，提出的对比损失更关注于将语义上接近的关系实例嵌入分开，从而有助于更好地区分相应的关系原型。</p><h3 id=relation-aware-nota-prototype-learning>Relation-Aware NOTA Prototype Learning<a hidden class=anchor aria-hidden=true href=#relation-aware-nota-prototype-learning>#</a></h3><p>由于大多数查询实体对不持有任何目标关系，NOTA（none-of-the-above）也被视为一个类别。现有方法通常学习一组通用的 NOTA 原型，应用于所有任务，这在某些任务中可能并不理想。为此，我们提出一种任务特定的 NOTA 原型生成策略，以更好地捕捉每个任务中的 NOTA 语义。</p><p>具体来说，我们首先引入一组可学习的向量，作为基础 NOTA 原型。与直接将这组向量视为最终 NOTA 原型不同，我们将其视为需要在每个任务中进一步修正的基础 NOTA 原型。由于支持文档的注释是完整的，我们可以访问支持 support-NOTA 分布，这隐含地表达了 NOTA 语义。因此，我们利用 support-NOTA 实例来捕捉每个特定任务中的 NOTA 语义。</p><h3 id=training-objective>Training Objective<a hidden class=anchor aria-hidden=true href=#training-objective>#</a></h3><p>给定查询文档中的实体对，我们使用 pair-level 注意力分布并采用类似的方法获得 pair-level 表示。对于任务中的每个目标关系类型，我们计算关系的概率。然后，我们计算分类损失。</p><h2 id=experiments>Experiments<a hidden class=anchor aria-hidden=true href=#experiments>#</a></h2><p><img loading=lazy src=/img/PaperNotes/RAPL/img4.png alt></p><blockquote><p>Results on FREDo and ReFREDo benchmarks. Reported results are macro averages across relation types. The best and second best performance methods are denoted in bold and underlined respectively.</p></blockquote></div><footer class=post-footer><ul class=post-tags><li><a href=http://localhost:1313/tags/papernotes/>PaperNotes</a></li><li><a href=http://localhost:1313/tags/re/>RE</a></li><li><a href=http://localhost:1313/tags/emnlp/>EMNLP</a></li><li><a href=http://localhost:1313/tags/meta-learning/>Meta Learning</a></li><li><a href=http://localhost:1313/tags/few-shot-learning/>Few-Shot Learning</a></li></ul><nav class=paginav><a class=prev href=http://localhost:1313/posts/papernotes/entity_concept-enhanced_few-shot_relation_extraction/><span class=title>« Prev</span><br><span>《Entity Concept-enhanced Few-shot Relation Extraction》笔记</span>
</a><a class=next href=http://localhost:1313/posts/dailydev/%E8%AE%A1%E7%BB%84kg%E8%AF%BE%E9%A2%98%E5%BC%80%E5%8F%91%E8%BF%87%E7%A8%8B%E4%BA%8C/><span class=title>Next »</span><br><span>《计组KG》课题开发过程（二）</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=http://localhost:1313/>KurongBlog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>