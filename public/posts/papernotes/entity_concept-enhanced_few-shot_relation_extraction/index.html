<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>《Entity Concept-enhanced Few-shot Relation Extraction》笔记 | KurongBlog</title>
<meta name=keywords content="PaperNotes,RE,ACL,Few-Shot Learning"><meta name=description content="Link
2106.02401 (arxiv.org)
Accepted ACL 2021。
Intro
小样本关系抽取（FSRE）大致可以分为两类：

仅使用纯文本数据，不包含外部信息。如：Siamese、Prototypical、BERT-PAIR
引入外部信息，以补偿 FSRE 的信息不足，如：TD-Proto

虽然引入文本描述的知识可以为 FSRE 提供外部信息并实现最先进的性能，但 TD-Proto 仅为每个实体引入一个 Wikidata 中的文本描述。然而，这可能会因为实体和文本描述之间的不匹配而导致性能下降。此外，由于每个实体的文本描述通常较长，提取长文本描述中最有用的信息并不容易。
与长文本描述相比，概念是对实体的直观和简洁的描述，可以从概念数据库（如 YAGO3、ConceptNet 和 Concept Graph 等）中轻松获得。此外，概念比每个实体的具体文本描述更抽象，这是对 FSRE 场景中有限信息的理想补充。


为了应对上述挑战，我们提出了一种新的实体概念增强的少样本关系抽取方案（CONCEPT-enhanced FEw-shot Relation Extraction，ConceptFERE），该方案引入实体概念以提供有效的关系预测线索。首先，如上表所示，一个实体可能有多个来自不同方面或层次的概念，只有一个概念可能对最终的关系分类有价值。因此，我们设计了一个概念-句子注意力模块，通过比较句子和每个概念的语义相似性来选择最合适的概念。其次，由于句子嵌入和预训练的概念嵌入不是在同一语义空间中学习的，我们采用自注意力机制对句子和选定概念进行词级语义融合，以进行最终的关系分类。
Model
下图为 ConceptFERE 的结构。


System Overview
Sentence Representation Module 使用 BERT 作为 Encoder 来获取 Sentence Embedding，Concept Representation Module 使用 skip-grim 在 Wikipedia 文本和概念图上学习概念的表示，得到 Concept Embedding 。Relation Classifier 采用全连接层实现。
Concept-Sentence Attention Module
直观上，需要更多关注与句子语义相关度高的概念，这些概念可以为关系抽取提供更有效的线索。
首先，由于预训练的 Sentence Embedding $v_s$ 和 Concept Embedding  $v_c$ 不是在同一语义空间中学习的，因此不能直接比较语义相似度。所以通过将 $v_c$ 和 $v_s$ 乘以投影矩阵 $P$ 来进行语义转换，以在同一语义空间中获得它们的表示 $v_cP$ 和 $v_sP$ ，其中 $P$ 可以通过全连接网络学习。其次，通过计算句子和每个实体概念之间的语义相似度，得到 $v_c$ 和 $v_s$ 的点积作为相似度 $sim_{cs}$ 。最后，为了从计算的相似度值中选择合适的概念，我们设计了 01-GATE 。相似度值通过 Softmax 函数归一化。如果 $sim_{cs}$ 小于设定的阈值 $α$，01-GATE 将为相应概念的注意力分数分配 0，该概念将在后续的关系分类中被排除。我们选择注意力分数为 1 的合适概念，作为参与关系预测的有效线索。"><meta name=author content="Kurong"><link rel=canonical href=http://localhost:1313/posts/papernotes/entity_concept-enhanced_few-shot_relation_extraction/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/posts/papernotes/entity_concept-enhanced_few-shot_relation_extraction/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],throwOnError:!1})})</script><meta property="og:title" content="《Entity Concept-enhanced Few-shot Relation Extraction》笔记"><meta property="og:description" content="Link
2106.02401 (arxiv.org)
Accepted ACL 2021。
Intro
小样本关系抽取（FSRE）大致可以分为两类：

仅使用纯文本数据，不包含外部信息。如：Siamese、Prototypical、BERT-PAIR
引入外部信息，以补偿 FSRE 的信息不足，如：TD-Proto

虽然引入文本描述的知识可以为 FSRE 提供外部信息并实现最先进的性能，但 TD-Proto 仅为每个实体引入一个 Wikidata 中的文本描述。然而，这可能会因为实体和文本描述之间的不匹配而导致性能下降。此外，由于每个实体的文本描述通常较长，提取长文本描述中最有用的信息并不容易。
与长文本描述相比，概念是对实体的直观和简洁的描述，可以从概念数据库（如 YAGO3、ConceptNet 和 Concept Graph 等）中轻松获得。此外，概念比每个实体的具体文本描述更抽象，这是对 FSRE 场景中有限信息的理想补充。


为了应对上述挑战，我们提出了一种新的实体概念增强的少样本关系抽取方案（CONCEPT-enhanced FEw-shot Relation Extraction，ConceptFERE），该方案引入实体概念以提供有效的关系预测线索。首先，如上表所示，一个实体可能有多个来自不同方面或层次的概念，只有一个概念可能对最终的关系分类有价值。因此，我们设计了一个概念-句子注意力模块，通过比较句子和每个概念的语义相似性来选择最合适的概念。其次，由于句子嵌入和预训练的概念嵌入不是在同一语义空间中学习的，我们采用自注意力机制对句子和选定概念进行词级语义融合，以进行最终的关系分类。
Model
下图为 ConceptFERE 的结构。


System Overview
Sentence Representation Module 使用 BERT 作为 Encoder 来获取 Sentence Embedding，Concept Representation Module 使用 skip-grim 在 Wikipedia 文本和概念图上学习概念的表示，得到 Concept Embedding 。Relation Classifier 采用全连接层实现。
Concept-Sentence Attention Module
直观上，需要更多关注与句子语义相关度高的概念，这些概念可以为关系抽取提供更有效的线索。
首先，由于预训练的 Sentence Embedding $v_s$ 和 Concept Embedding  $v_c$ 不是在同一语义空间中学习的，因此不能直接比较语义相似度。所以通过将 $v_c$ 和 $v_s$ 乘以投影矩阵 $P$ 来进行语义转换，以在同一语义空间中获得它们的表示 $v_cP$ 和 $v_sP$ ，其中 $P$ 可以通过全连接网络学习。其次，通过计算句子和每个实体概念之间的语义相似度，得到 $v_c$ 和 $v_s$ 的点积作为相似度 $sim_{cs}$ 。最后，为了从计算的相似度值中选择合适的概念，我们设计了 01-GATE 。相似度值通过 Softmax 函数归一化。如果 $sim_{cs}$ 小于设定的阈值 $α$，01-GATE 将为相应概念的注意力分数分配 0，该概念将在后续的关系分类中被排除。我们选择注意力分数为 1 的合适概念，作为参与关系预测的有效线索。"><meta property="og:type" content="article"><meta property="og:url" content="http://localhost:1313/posts/papernotes/entity_concept-enhanced_few-shot_relation_extraction/"><meta property="og:image" content="http://localhost:1313/cover/Entity_Concept-enhanced_Few-shot_Relation_Extraction.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-09-18T00:00:00+00:00"><meta property="article:modified_time" content="2024-09-18T00:00:00+00:00"><meta property="og:site_name" content="KurongBlog"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://localhost:1313/cover/Entity_Concept-enhanced_Few-shot_Relation_Extraction.png"><meta name=twitter:title content="《Entity Concept-enhanced Few-shot Relation Extraction》笔记"><meta name=twitter:description content="Link
2106.02401 (arxiv.org)
Accepted ACL 2021。
Intro
小样本关系抽取（FSRE）大致可以分为两类：

仅使用纯文本数据，不包含外部信息。如：Siamese、Prototypical、BERT-PAIR
引入外部信息，以补偿 FSRE 的信息不足，如：TD-Proto

虽然引入文本描述的知识可以为 FSRE 提供外部信息并实现最先进的性能，但 TD-Proto 仅为每个实体引入一个 Wikidata 中的文本描述。然而，这可能会因为实体和文本描述之间的不匹配而导致性能下降。此外，由于每个实体的文本描述通常较长，提取长文本描述中最有用的信息并不容易。
与长文本描述相比，概念是对实体的直观和简洁的描述，可以从概念数据库（如 YAGO3、ConceptNet 和 Concept Graph 等）中轻松获得。此外，概念比每个实体的具体文本描述更抽象，这是对 FSRE 场景中有限信息的理想补充。


为了应对上述挑战，我们提出了一种新的实体概念增强的少样本关系抽取方案（CONCEPT-enhanced FEw-shot Relation Extraction，ConceptFERE），该方案引入实体概念以提供有效的关系预测线索。首先，如上表所示，一个实体可能有多个来自不同方面或层次的概念，只有一个概念可能对最终的关系分类有价值。因此，我们设计了一个概念-句子注意力模块，通过比较句子和每个概念的语义相似性来选择最合适的概念。其次，由于句子嵌入和预训练的概念嵌入不是在同一语义空间中学习的，我们采用自注意力机制对句子和选定概念进行词级语义融合，以进行最终的关系分类。
Model
下图为 ConceptFERE 的结构。


System Overview
Sentence Representation Module 使用 BERT 作为 Encoder 来获取 Sentence Embedding，Concept Representation Module 使用 skip-grim 在 Wikipedia 文本和概念图上学习概念的表示，得到 Concept Embedding 。Relation Classifier 采用全连接层实现。
Concept-Sentence Attention Module
直观上，需要更多关注与句子语义相关度高的概念，这些概念可以为关系抽取提供更有效的线索。
首先，由于预训练的 Sentence Embedding $v_s$ 和 Concept Embedding  $v_c$ 不是在同一语义空间中学习的，因此不能直接比较语义相似度。所以通过将 $v_c$ 和 $v_s$ 乘以投影矩阵 $P$ 来进行语义转换，以在同一语义空间中获得它们的表示 $v_cP$ 和 $v_sP$ ，其中 $P$ 可以通过全连接网络学习。其次，通过计算句子和每个实体概念之间的语义相似度，得到 $v_c$ 和 $v_s$ 的点积作为相似度 $sim_{cs}$ 。最后，为了从计算的相似度值中选择合适的概念，我们设计了 01-GATE 。相似度值通过 Softmax 函数归一化。如果 $sim_{cs}$ 小于设定的阈值 $α$，01-GATE 将为相应概念的注意力分数分配 0，该概念将在后续的关系分类中被排除。我们选择注意力分数为 1 的合适概念，作为参与关系预测的有效线索。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:1313/posts/"},{"@type":"ListItem","position":2,"name":"《Entity Concept-enhanced Few-shot Relation Extraction》笔记","item":"http://localhost:1313/posts/papernotes/entity_concept-enhanced_few-shot_relation_extraction/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"《Entity Concept-enhanced Few-shot Relation Extraction》笔记","name":"《Entity Concept-enhanced Few-shot Relation Extraction》笔记","description":"Link 2106.02401 (arxiv.org)\nAccepted ACL 2021。\nIntro 小样本关系抽取（FSRE）大致可以分为两类：\n仅使用纯文本数据，不包含外部信息。如：Siamese、Prototypical、BERT-PAIR 引入外部信息，以补偿 FSRE 的信息不足，如：TD-Proto 虽然引入文本描述的知识可以为 FSRE 提供外部信息并实现最先进的性能，但 TD-Proto 仅为每个实体引入一个 Wikidata 中的文本描述。然而，这可能会因为实体和文本描述之间的不匹配而导致性能下降。此外，由于每个实体的文本描述通常较长，提取长文本描述中最有用的信息并不容易。\n与长文本描述相比，概念是对实体的直观和简洁的描述，可以从概念数据库（如 YAGO3、ConceptNet 和 Concept Graph 等）中轻松获得。此外，概念比每个实体的具体文本描述更抽象，这是对 FSRE 场景中有限信息的理想补充。\n为了应对上述挑战，我们提出了一种新的实体概念增强的少样本关系抽取方案（CONCEPT-enhanced FEw-shot Relation Extraction，ConceptFERE），该方案引入实体概念以提供有效的关系预测线索。首先，如上表所示，一个实体可能有多个来自不同方面或层次的概念，只有一个概念可能对最终的关系分类有价值。因此，我们设计了一个概念-句子注意力模块，通过比较句子和每个概念的语义相似性来选择最合适的概念。其次，由于句子嵌入和预训练的概念嵌入不是在同一语义空间中学习的，我们采用自注意力机制对句子和选定概念进行词级语义融合，以进行最终的关系分类。\nModel 下图为 ConceptFERE 的结构。\nSystem Overview Sentence Representation Module 使用 BERT 作为 Encoder 来获取 Sentence Embedding，Concept Representation Module 使用 skip-grim 在 Wikipedia 文本和概念图上学习概念的表示，得到 Concept Embedding 。Relation Classifier 采用全连接层实现。\nConcept-Sentence Attention Module 直观上，需要更多关注与句子语义相关度高的概念，这些概念可以为关系抽取提供更有效的线索。\n首先，由于预训练的 Sentence Embedding $v_s$ 和 Concept Embedding $v_c$ 不是在同一语义空间中学习的，因此不能直接比较语义相似度。所以通过将 $v_c$ 和 $v_s$ 乘以投影矩阵 $P$ 来进行语义转换，以在同一语义空间中获得它们的表示 $v_cP$ 和 $v_sP$ ，其中 $P$ 可以通过全连接网络学习。其次，通过计算句子和每个实体概念之间的语义相似度，得到 $v_c$ 和 $v_s$ 的点积作为相似度 $sim_{cs}$ 。最后，为了从计算的相似度值中选择合适的概念，我们设计了 01-GATE 。相似度值通过 Softmax 函数归一化。如果 $sim_{cs}$ 小于设定的阈值 $α$，01-GATE 将为相应概念的注意力分数分配 0，该概念将在后续的关系分类中被排除。我们选择注意力分数为 1 的合适概念，作为参与关系预测的有效线索。\n","keywords":["PaperNotes","RE","ACL","Few-Shot Learning"],"articleBody":"Link 2106.02401 (arxiv.org)\nAccepted ACL 2021。\nIntro 小样本关系抽取（FSRE）大致可以分为两类：\n仅使用纯文本数据，不包含外部信息。如：Siamese、Prototypical、BERT-PAIR 引入外部信息，以补偿 FSRE 的信息不足，如：TD-Proto 虽然引入文本描述的知识可以为 FSRE 提供外部信息并实现最先进的性能，但 TD-Proto 仅为每个实体引入一个 Wikidata 中的文本描述。然而，这可能会因为实体和文本描述之间的不匹配而导致性能下降。此外，由于每个实体的文本描述通常较长，提取长文本描述中最有用的信息并不容易。\n与长文本描述相比，概念是对实体的直观和简洁的描述，可以从概念数据库（如 YAGO3、ConceptNet 和 Concept Graph 等）中轻松获得。此外，概念比每个实体的具体文本描述更抽象，这是对 FSRE 场景中有限信息的理想补充。\n为了应对上述挑战，我们提出了一种新的实体概念增强的少样本关系抽取方案（CONCEPT-enhanced FEw-shot Relation Extraction，ConceptFERE），该方案引入实体概念以提供有效的关系预测线索。首先，如上表所示，一个实体可能有多个来自不同方面或层次的概念，只有一个概念可能对最终的关系分类有价值。因此，我们设计了一个概念-句子注意力模块，通过比较句子和每个概念的语义相似性来选择最合适的概念。其次，由于句子嵌入和预训练的概念嵌入不是在同一语义空间中学习的，我们采用自注意力机制对句子和选定概念进行词级语义融合，以进行最终的关系分类。\nModel 下图为 ConceptFERE 的结构。\nSystem Overview Sentence Representation Module 使用 BERT 作为 Encoder 来获取 Sentence Embedding，Concept Representation Module 使用 skip-grim 在 Wikipedia 文本和概念图上学习概念的表示，得到 Concept Embedding 。Relation Classifier 采用全连接层实现。\nConcept-Sentence Attention Module 直观上，需要更多关注与句子语义相关度高的概念，这些概念可以为关系抽取提供更有效的线索。\n首先，由于预训练的 Sentence Embedding $v_s$ 和 Concept Embedding $v_c$ 不是在同一语义空间中学习的，因此不能直接比较语义相似度。所以通过将 $v_c$ 和 $v_s$ 乘以投影矩阵 $P$ 来进行语义转换，以在同一语义空间中获得它们的表示 $v_cP$ 和 $v_sP$ ，其中 $P$ 可以通过全连接网络学习。其次，通过计算句子和每个实体概念之间的语义相似度，得到 $v_c$ 和 $v_s$ 的点积作为相似度 $sim_{cs}$ 。最后，为了从计算的相似度值中选择合适的概念，我们设计了 01-GATE 。相似度值通过 Softmax 函数归一化。如果 $sim_{cs}$ 小于设定的阈值 $α$，01-GATE 将为相应概念的注意力分数分配 0，该概念将在后续的关系分类中被排除。我们选择注意力分数为 1 的合适概念，作为参与关系预测的有效线索。\nSelf-Attention based Fusion Module 将句子中所有单词的嵌入和选择的概念嵌入连接起来，然后输入自注意力模块。 $$ fusion_{v_i}=\\sum^N_{j=1}sim(q_i, k_j)v_j $$ 其中，$fusion_{v_i}$ 表示 $v_i$ 在进行单词级语义融合后的嵌入。$q_i$、$k_j$ 和 $v_j$ 来自自注意力，它们分别表示概念嵌入或单词嵌入。\nExperiment 在 Wikipedia 数据集上的实验，其中 ConceptFERE(Simple) 去掉了部分模块。\n下面是消融实验：\n","wordCount":"124","inLanguage":"en","image":"http://localhost:1313/cover/Entity_Concept-enhanced_Few-shot_Relation_Extraction.png","datePublished":"2024-09-18T00:00:00Z","dateModified":"2024-09-18T00:00:00Z","author":{"@type":"Person","name":"Kurong"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/posts/papernotes/entity_concept-enhanced_few-shot_relation_extraction/"},"publisher":{"@type":"Organization","name":"KurongBlog","logo":{"@type":"ImageObject","url":"http://localhost:1313/%3Clink%20/%20abs%20url%3E"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Home (Alt + H)"><img src=http://localhost:1313/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/categories/ title=categories><span>categories</span></a></li><li><a href=http://localhost:1313/tags/ title=tags><span>tags</span></a></li><li><a href=http://localhost:1313/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a>&nbsp;»&nbsp;<a href=http://localhost:1313/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">《Entity Concept-enhanced Few-shot Relation Extraction》笔记</h1><div class=post-meta><span title='2024-09-18 00:00:00 +0000 UTC'>September 18, 2024</span>&nbsp;·&nbsp;Kurong&nbsp;|&nbsp;<a href=https://github.com/KurongTohsaka/KurongTohsaka.github.io/content/posts/PaperNotes/Entity_Concept-enhanced_Few-shot_Relation_Extraction.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><figure class=entry-cover><img loading=eager src=http://localhost:1313/cover/Entity_Concept-enhanced_Few-shot_Relation_Extraction.png alt><p></p></figure><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#link>Link</a></li><li><a href=#intro>Intro</a></li><li><a href=#model>Model</a><ul><li><a href=#system-overview>System Overview</a></li><li><a href=#concept-sentence-attention-module>Concept-Sentence Attention Module</a></li><li><a href=#self-attention-based-fusion-module>Self-Attention based Fusion Module</a></li></ul></li><li><a href=#experiment>Experiment</a></li></ul></nav></div></details></div><div class=post-content><h2 id=link>Link<a hidden class=anchor aria-hidden=true href=#link>#</a></h2><p><a href=https://arxiv.org/pdf/2106.02401>2106.02401 (arxiv.org)</a></p><p>Accepted ACL 2021。</p><h2 id=intro>Intro<a hidden class=anchor aria-hidden=true href=#intro>#</a></h2><p>小样本关系抽取（FSRE）大致可以分为两类：</p><ul><li>仅使用纯文本数据，不包含外部信息。如：Siamese、Prototypical、BERT-PAIR</li><li>引入外部信息，以补偿 FSRE 的信息不足，如：TD-Proto</li></ul><p>虽然引入文本描述的知识可以为 FSRE 提供外部信息并实现最先进的性能，但 TD-Proto 仅为每个实体引入一个 Wikidata 中的文本描述。然而，这可能会因为实体和文本描述之间的不匹配而导致性能下降。此外，由于每个实体的文本描述通常较长，提取长文本描述中最有用的信息并不容易。</p><p>与长文本描述相比，概念是对实体的直观和简洁的描述，可以从概念数据库（如 YAGO3、ConceptNet 和 Concept Graph 等）中轻松获得。此外，概念比每个实体的具体文本描述更抽象，这是对 FSRE 场景中有限信息的理想补充。</p><p><img loading=lazy src=/img/PaperNotes/Entity_Concept-enhanced_Few-shot_Relation_Extraction/img1.png alt></p><p>为了应对上述挑战，我们提出了一种新的实体概念增强的少样本关系抽取方案（<strong>CONCEPT</strong>-enhanced <strong>FE</strong>w-shot <strong>R</strong>elation <strong>E</strong>xtraction，<strong>ConceptFERE</strong>），该方案引入实体概念以提供有效的关系预测线索。首先，如上表所示，一个实体可能有多个来自不同方面或层次的概念，只有一个概念可能对最终的关系分类有价值。因此，我们设计了一个概念-句子注意力模块，通过比较句子和每个概念的语义相似性来选择最合适的概念。其次，由于句子嵌入和预训练的概念嵌入不是在同一语义空间中学习的，我们采用自注意力机制对句子和选定概念进行词级语义融合，以进行最终的关系分类。</p><h2 id=model>Model<a hidden class=anchor aria-hidden=true href=#model>#</a></h2><p>下图为 ConceptFERE 的结构。</p><p><img loading=lazy src=/img/PaperNotes/Entity_Concept-enhanced_Few-shot_Relation_Extraction/img2.png alt></p><h3 id=system-overview>System Overview<a hidden class=anchor aria-hidden=true href=#system-overview>#</a></h3><p>Sentence Representation Module 使用 BERT 作为 Encoder 来获取 Sentence Embedding，Concept Representation Module 使用 skip-grim 在 Wikipedia 文本和概念图上学习概念的表示，得到 Concept Embedding 。Relation Classifier 采用全连接层实现。</p><h3 id=concept-sentence-attention-module>Concept-Sentence Attention Module<a hidden class=anchor aria-hidden=true href=#concept-sentence-attention-module>#</a></h3><p>直观上，需要更多关注与句子语义相关度高的概念，这些概念可以为关系抽取提供更有效的线索。</p><p>首先，由于预训练的 Sentence Embedding $v_s$ 和 Concept Embedding $v_c$ 不是在同一语义空间中学习的，因此不能直接比较语义相似度。所以通过将 $v_c$ 和 $v_s$ 乘以投影矩阵 $P$ 来进行语义转换，以在同一语义空间中获得它们的表示 $v_cP$ 和 $v_sP$ ，其中 $P$ 可以通过全连接网络学习。其次，通过计算句子和每个实体概念之间的语义相似度，得到 $v_c$ 和 $v_s$ 的点积作为相似度 $sim_{cs}$ 。最后，为了从计算的相似度值中选择合适的概念，我们设计了 01-GATE 。相似度值通过 Softmax 函数归一化。如果 $sim_{cs}$ 小于设定的阈值 $α$，01-GATE 将为相应概念的注意力分数分配 0，该概念将在后续的关系分类中被排除。我们选择注意力分数为 1 的合适概念，作为参与关系预测的有效线索。</p><h3 id=self-attention-based-fusion-module>Self-Attention based Fusion Module<a hidden class=anchor aria-hidden=true href=#self-attention-based-fusion-module>#</a></h3><p>将句子中所有单词的嵌入和选择的概念嵌入连接起来，然后输入自注意力模块。</p>$$
fusion_{v_i}=\sum^N_{j=1}sim(q_i, k_j)v_j
$$<p>其中，$fusion_{v_i}$ 表示 $v_i$ 在进行单词级语义融合后的嵌入。$q_i$、$k_j$ 和 $v_j$ 来自自注意力，它们分别表示概念嵌入或单词嵌入。</p><h2 id=experiment>Experiment<a hidden class=anchor aria-hidden=true href=#experiment>#</a></h2><p>在 Wikipedia 数据集上的实验，其中 ConceptFERE(Simple) 去掉了部分模块。</p><p><img loading=lazy src=/img/PaperNotes/Entity_Concept-enhanced_Few-shot_Relation_Extraction/img3.png alt></p><p>下面是消融实验：</p><p><img loading=lazy src=/img/PaperNotes/Entity_Concept-enhanced_Few-shot_Relation_Extraction/img4.png alt></p></div><footer class=post-footer><ul class=post-tags><li><a href=http://localhost:1313/tags/papernotes/>PaperNotes</a></li><li><a href=http://localhost:1313/tags/re/>RE</a></li><li><a href=http://localhost:1313/tags/acl/>ACL</a></li><li><a href=http://localhost:1313/tags/few-shot-learning/>Few-Shot Learning</a></li></ul><nav class=paginav><a class=prev href=http://localhost:1313/posts/papernotes/efficient_information_extraction_in_few-shot_relation_classification_through_contrastive_representation_learning/><span class=title>« Prev</span><br><span>《Efficient Information Extraction in Few-Shot Relation Classification through Contrastive Representation Learning》笔记</span>
</a><a class=next href=http://localhost:1313/posts/papernotes/rapl/><span class=title>Next »</span><br><span>RAPL: A Relation-Aware Prototype Learning Approach for Few-Shot Document-Level Relation Extraction</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=http://localhost:1313/>KurongBlog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>