<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>《Making Pre-trained Language Models Better Continual Few-Shot Relation Extractors》笔记 | KurongBlog</title>
<meta name=keywords content="PaperNotes,RE,COLING,Few-Shot Learning"><meta name=description content="Link
[2402.15713] Making Pre-trained Language Models Better Continual Few-Shot Relation Extractors (arxiv.org)
Accepted COLING 2024

COLING: CCF B

Intro
关系抽取是自然语言处理领域中的一个基本且重要的任务，旨在从句子或文档中提取实体之间的潜在关系。传统的 RE 方法在大量标注样本上训练模型，然后在具有相同标签空间的数据上进行测试。然而，在现实生活中，新关系不断涌现，这些模型在适应新关系时可能会出现显著的性能下降。此外，这些模型严重依赖于大量标注数据，这需要大量时间和精力来收集。
因此，提出了持续少样本关系抽取（Continual Few-shot Relation Extraction, CFRE），其目标是在有限的标注数据约束下，持续学习新关系的同时保留先前学习的关系知识。这一实际任务带来了两个重大挑战：

灾难性遗忘：模型在学习新任务时突然忘记从前任务中获得的知识。最新研究指出，即使在大型语言模型中也存在灾难性遗忘问题，这使得这一问题值得研究。
过拟合：模型在训练数据上表现异常好，但由于拟合噪声或无关模式，无法有效泛化到未见数据，这在训练数据稀少的低资源场景中更为明显。

总结一下，我们的主要贡献包括：

我们利用提示学习来探索预训练语言模型（PLM）的隐含能力，并提出了 Contrastive Prompt Learning framework (CPL) 框架，将其与一种新的基于边际的对比学习目标（CFRL）结合起来，同时缓解灾难性遗忘和过拟合问题。
我们通过利用大型语言模型（LLM）的力量引入了一种记忆增强策略，以提升较小的 PLM。这种策略使用精心设计的提示来指导 ChatGPT 生成样本，从而更好地对抗过拟合。
在两个 RE 基准上的大量实验表明，我们的方法优于最先进的模型，证明了缓解灾难性遗忘和过拟合的有效性。

Related Work
Continual Learning
持续学习（Continual Learning, CL）旨在从一系列任务中不断学习新知识，同时避免遗忘旧知识。CL的主要挑战是灾难性遗忘。
现有的CL方法分为三类：

正则化方法：使用额外的约束来限制参数更新，使模型能够记住更多旧知识。
动态架构方法：动态扩展模型架构，以在任务序列不断出现时存储新知识。
基于记忆的方法：存储当前任务的一些典型样本，并在学习任务序列后重放记忆以复习旧知识。

在这些方法中，基于记忆的方法在自然语言处理（NLP）任务中最为有效。然而，新任务的数据并不总是充足的，而且获取高质量数据往往既昂贵又耗时。我们也采用基于记忆的策略，但我们更注重如何更好地利用预训练语言模型（PLMs）来解决 CFRE。
Prompt Learning
提示学习随着GPT-3系列的诞生而出现，并在自然语言处理任务中取得了显著的性能，尤其是在小样本场景中。它通过添加提示词将下游任务重新表述为预训练任务，并引导预训练语言模型（PLMs）理解各种任务。之前的提示学习方法可以分为三类：

硬提示：在句子中添加手工制作的提示词，并将其转换为掩码语言建模问题。尽管有效，但它需要针对不同任务的复杂专家知识，这既繁琐又耗时。
软提示：在句子中添加可连续训练的向量，这些向量可以被模型自动学习。然而，在没有任何先验专家知识的情况下，模型并不总能学到合适的提示，尤其是在低资源场景中。
混合提示：结合不可调的硬提示和可调的软提示，使模型能够在少量人工干预下轻松学习合适的模板。它被验证为最有效的方法。

我们专注于少样本设置，并采用混合提示来帮助预训练语言模型（PLMs）缓解灾难性遗忘和过拟合问题。
Method
Framework Overview
整个 CPL 框架有三个模块：

Prompt Representation，Contrastive Learning，Memory Augmentation


"><meta name=author content="Kurong"><link rel=canonical href=http://localhost:1313/posts/papernotes/making_pre-trained_language_models_better_continual_few-shot_relation_extractors/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/posts/papernotes/making_pre-trained_language_models_better_continual_few-shot_relation_extractors/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],throwOnError:!1})})</script><meta property="og:title" content="《Making Pre-trained Language Models Better Continual Few-Shot Relation Extractors》笔记"><meta property="og:description" content="Link
[2402.15713] Making Pre-trained Language Models Better Continual Few-Shot Relation Extractors (arxiv.org)
Accepted COLING 2024

COLING: CCF B

Intro
关系抽取是自然语言处理领域中的一个基本且重要的任务，旨在从句子或文档中提取实体之间的潜在关系。传统的 RE 方法在大量标注样本上训练模型，然后在具有相同标签空间的数据上进行测试。然而，在现实生活中，新关系不断涌现，这些模型在适应新关系时可能会出现显著的性能下降。此外，这些模型严重依赖于大量标注数据，这需要大量时间和精力来收集。
因此，提出了持续少样本关系抽取（Continual Few-shot Relation Extraction, CFRE），其目标是在有限的标注数据约束下，持续学习新关系的同时保留先前学习的关系知识。这一实际任务带来了两个重大挑战：

灾难性遗忘：模型在学习新任务时突然忘记从前任务中获得的知识。最新研究指出，即使在大型语言模型中也存在灾难性遗忘问题，这使得这一问题值得研究。
过拟合：模型在训练数据上表现异常好，但由于拟合噪声或无关模式，无法有效泛化到未见数据，这在训练数据稀少的低资源场景中更为明显。

总结一下，我们的主要贡献包括：

我们利用提示学习来探索预训练语言模型（PLM）的隐含能力，并提出了 Contrastive Prompt Learning framework (CPL) 框架，将其与一种新的基于边际的对比学习目标（CFRL）结合起来，同时缓解灾难性遗忘和过拟合问题。
我们通过利用大型语言模型（LLM）的力量引入了一种记忆增强策略，以提升较小的 PLM。这种策略使用精心设计的提示来指导 ChatGPT 生成样本，从而更好地对抗过拟合。
在两个 RE 基准上的大量实验表明，我们的方法优于最先进的模型，证明了缓解灾难性遗忘和过拟合的有效性。

Related Work
Continual Learning
持续学习（Continual Learning, CL）旨在从一系列任务中不断学习新知识，同时避免遗忘旧知识。CL的主要挑战是灾难性遗忘。
现有的CL方法分为三类：

正则化方法：使用额外的约束来限制参数更新，使模型能够记住更多旧知识。
动态架构方法：动态扩展模型架构，以在任务序列不断出现时存储新知识。
基于记忆的方法：存储当前任务的一些典型样本，并在学习任务序列后重放记忆以复习旧知识。

在这些方法中，基于记忆的方法在自然语言处理（NLP）任务中最为有效。然而，新任务的数据并不总是充足的，而且获取高质量数据往往既昂贵又耗时。我们也采用基于记忆的策略，但我们更注重如何更好地利用预训练语言模型（PLMs）来解决 CFRE。
Prompt Learning
提示学习随着GPT-3系列的诞生而出现，并在自然语言处理任务中取得了显著的性能，尤其是在小样本场景中。它通过添加提示词将下游任务重新表述为预训练任务，并引导预训练语言模型（PLMs）理解各种任务。之前的提示学习方法可以分为三类：

硬提示：在句子中添加手工制作的提示词，并将其转换为掩码语言建模问题。尽管有效，但它需要针对不同任务的复杂专家知识，这既繁琐又耗时。
软提示：在句子中添加可连续训练的向量，这些向量可以被模型自动学习。然而，在没有任何先验专家知识的情况下，模型并不总能学到合适的提示，尤其是在低资源场景中。
混合提示：结合不可调的硬提示和可调的软提示，使模型能够在少量人工干预下轻松学习合适的模板。它被验证为最有效的方法。

我们专注于少样本设置，并采用混合提示来帮助预训练语言模型（PLMs）缓解灾难性遗忘和过拟合问题。
Method
Framework Overview
整个 CPL 框架有三个模块：

Prompt Representation，Contrastive Learning，Memory Augmentation


"><meta property="og:type" content="article"><meta property="og:url" content="http://localhost:1313/posts/papernotes/making_pre-trained_language_models_better_continual_few-shot_relation_extractors/"><meta property="og:image" content="http://localhost:1313/cover/Making_Pre-trained_Language_Models_Better_Continual_Few-Shot_Relation_Extractors.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-09-20T00:00:00+00:00"><meta property="article:modified_time" content="2024-09-20T00:00:00+00:00"><meta property="og:site_name" content="KurongBlog"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://localhost:1313/cover/Making_Pre-trained_Language_Models_Better_Continual_Few-Shot_Relation_Extractors.png"><meta name=twitter:title content="《Making Pre-trained Language Models Better Continual Few-Shot Relation Extractors》笔记"><meta name=twitter:description content="Link
[2402.15713] Making Pre-trained Language Models Better Continual Few-Shot Relation Extractors (arxiv.org)
Accepted COLING 2024

COLING: CCF B

Intro
关系抽取是自然语言处理领域中的一个基本且重要的任务，旨在从句子或文档中提取实体之间的潜在关系。传统的 RE 方法在大量标注样本上训练模型，然后在具有相同标签空间的数据上进行测试。然而，在现实生活中，新关系不断涌现，这些模型在适应新关系时可能会出现显著的性能下降。此外，这些模型严重依赖于大量标注数据，这需要大量时间和精力来收集。
因此，提出了持续少样本关系抽取（Continual Few-shot Relation Extraction, CFRE），其目标是在有限的标注数据约束下，持续学习新关系的同时保留先前学习的关系知识。这一实际任务带来了两个重大挑战：

灾难性遗忘：模型在学习新任务时突然忘记从前任务中获得的知识。最新研究指出，即使在大型语言模型中也存在灾难性遗忘问题，这使得这一问题值得研究。
过拟合：模型在训练数据上表现异常好，但由于拟合噪声或无关模式，无法有效泛化到未见数据，这在训练数据稀少的低资源场景中更为明显。

总结一下，我们的主要贡献包括：

我们利用提示学习来探索预训练语言模型（PLM）的隐含能力，并提出了 Contrastive Prompt Learning framework (CPL) 框架，将其与一种新的基于边际的对比学习目标（CFRL）结合起来，同时缓解灾难性遗忘和过拟合问题。
我们通过利用大型语言模型（LLM）的力量引入了一种记忆增强策略，以提升较小的 PLM。这种策略使用精心设计的提示来指导 ChatGPT 生成样本，从而更好地对抗过拟合。
在两个 RE 基准上的大量实验表明，我们的方法优于最先进的模型，证明了缓解灾难性遗忘和过拟合的有效性。

Related Work
Continual Learning
持续学习（Continual Learning, CL）旨在从一系列任务中不断学习新知识，同时避免遗忘旧知识。CL的主要挑战是灾难性遗忘。
现有的CL方法分为三类：

正则化方法：使用额外的约束来限制参数更新，使模型能够记住更多旧知识。
动态架构方法：动态扩展模型架构，以在任务序列不断出现时存储新知识。
基于记忆的方法：存储当前任务的一些典型样本，并在学习任务序列后重放记忆以复习旧知识。

在这些方法中，基于记忆的方法在自然语言处理（NLP）任务中最为有效。然而，新任务的数据并不总是充足的，而且获取高质量数据往往既昂贵又耗时。我们也采用基于记忆的策略，但我们更注重如何更好地利用预训练语言模型（PLMs）来解决 CFRE。
Prompt Learning
提示学习随着GPT-3系列的诞生而出现，并在自然语言处理任务中取得了显著的性能，尤其是在小样本场景中。它通过添加提示词将下游任务重新表述为预训练任务，并引导预训练语言模型（PLMs）理解各种任务。之前的提示学习方法可以分为三类：

硬提示：在句子中添加手工制作的提示词，并将其转换为掩码语言建模问题。尽管有效，但它需要针对不同任务的复杂专家知识，这既繁琐又耗时。
软提示：在句子中添加可连续训练的向量，这些向量可以被模型自动学习。然而，在没有任何先验专家知识的情况下，模型并不总能学到合适的提示，尤其是在低资源场景中。
混合提示：结合不可调的硬提示和可调的软提示，使模型能够在少量人工干预下轻松学习合适的模板。它被验证为最有效的方法。

我们专注于少样本设置，并采用混合提示来帮助预训练语言模型（PLMs）缓解灾难性遗忘和过拟合问题。
Method
Framework Overview
整个 CPL 框架有三个模块：

Prompt Representation，Contrastive Learning，Memory Augmentation


"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:1313/posts/"},{"@type":"ListItem","position":2,"name":"《Making Pre-trained Language Models Better Continual Few-Shot Relation Extractors》笔记","item":"http://localhost:1313/posts/papernotes/making_pre-trained_language_models_better_continual_few-shot_relation_extractors/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"《Making Pre-trained Language Models Better Continual Few-Shot Relation Extractors》笔记","name":"《Making Pre-trained Language Models Better Continual Few-Shot Relation Extractors》笔记","description":"Link [2402.15713] Making Pre-trained Language Models Better Continual Few-Shot Relation Extractors (arxiv.org)\nAccepted COLING 2024\nCOLING: CCF B\nIntro 关系抽取是自然语言处理领域中的一个基本且重要的任务，旨在从句子或文档中提取实体之间的潜在关系。传统的 RE 方法在大量标注样本上训练模型，然后在具有相同标签空间的数据上进行测试。然而，在现实生活中，新关系不断涌现，这些模型在适应新关系时可能会出现显著的性能下降。此外，这些模型严重依赖于大量标注数据，这需要大量时间和精力来收集。\n因此，提出了持续少样本关系抽取（Continual Few-shot Relation Extraction, CFRE），其目标是在有限的标注数据约束下，持续学习新关系的同时保留先前学习的关系知识。这一实际任务带来了两个重大挑战：\n灾难性遗忘：模型在学习新任务时突然忘记从前任务中获得的知识。最新研究指出，即使在大型语言模型中也存在灾难性遗忘问题，这使得这一问题值得研究。 过拟合：模型在训练数据上表现异常好，但由于拟合噪声或无关模式，无法有效泛化到未见数据，这在训练数据稀少的低资源场景中更为明显。 总结一下，我们的主要贡献包括：\n我们利用提示学习来探索预训练语言模型（PLM）的隐含能力，并提出了 Contrastive Prompt Learning framework (CPL) 框架，将其与一种新的基于边际的对比学习目标（CFRL）结合起来，同时缓解灾难性遗忘和过拟合问题。 我们通过利用大型语言模型（LLM）的力量引入了一种记忆增强策略，以提升较小的 PLM。这种策略使用精心设计的提示来指导 ChatGPT 生成样本，从而更好地对抗过拟合。 在两个 RE 基准上的大量实验表明，我们的方法优于最先进的模型，证明了缓解灾难性遗忘和过拟合的有效性。 Related Work Continual Learning 持续学习（Continual Learning, CL）旨在从一系列任务中不断学习新知识，同时避免遗忘旧知识。CL的主要挑战是灾难性遗忘。\n现有的CL方法分为三类：\n正则化方法：使用额外的约束来限制参数更新，使模型能够记住更多旧知识。 动态架构方法：动态扩展模型架构，以在任务序列不断出现时存储新知识。 基于记忆的方法：存储当前任务的一些典型样本，并在学习任务序列后重放记忆以复习旧知识。 在这些方法中，基于记忆的方法在自然语言处理（NLP）任务中最为有效。然而，新任务的数据并不总是充足的，而且获取高质量数据往往既昂贵又耗时。我们也采用基于记忆的策略，但我们更注重如何更好地利用预训练语言模型（PLMs）来解决 CFRE。\nPrompt Learning 提示学习随着GPT-3系列的诞生而出现，并在自然语言处理任务中取得了显著的性能，尤其是在小样本场景中。它通过添加提示词将下游任务重新表述为预训练任务，并引导预训练语言模型（PLMs）理解各种任务。之前的提示学习方法可以分为三类：\n硬提示：在句子中添加手工制作的提示词，并将其转换为掩码语言建模问题。尽管有效，但它需要针对不同任务的复杂专家知识，这既繁琐又耗时。 软提示：在句子中添加可连续训练的向量，这些向量可以被模型自动学习。然而，在没有任何先验专家知识的情况下，模型并不总能学到合适的提示，尤其是在低资源场景中。 混合提示：结合不可调的硬提示和可调的软提示，使模型能够在少量人工干预下轻松学习合适的模板。它被验证为最有效的方法。 我们专注于少样本设置，并采用混合提示来帮助预训练语言模型（PLMs）缓解灾难性遗忘和过拟合问题。\nMethod Framework Overview 整个 CPL 框架有三个模块：\nPrompt Representation，Contrastive Learning，Memory Augmentation ","keywords":["PaperNotes","RE","COLING","Few-Shot Learning"],"articleBody":"Link [2402.15713] Making Pre-trained Language Models Better Continual Few-Shot Relation Extractors (arxiv.org)\nAccepted COLING 2024\nCOLING: CCF B\nIntro 关系抽取是自然语言处理领域中的一个基本且重要的任务，旨在从句子或文档中提取实体之间的潜在关系。传统的 RE 方法在大量标注样本上训练模型，然后在具有相同标签空间的数据上进行测试。然而，在现实生活中，新关系不断涌现，这些模型在适应新关系时可能会出现显著的性能下降。此外，这些模型严重依赖于大量标注数据，这需要大量时间和精力来收集。\n因此，提出了持续少样本关系抽取（Continual Few-shot Relation Extraction, CFRE），其目标是在有限的标注数据约束下，持续学习新关系的同时保留先前学习的关系知识。这一实际任务带来了两个重大挑战：\n灾难性遗忘：模型在学习新任务时突然忘记从前任务中获得的知识。最新研究指出，即使在大型语言模型中也存在灾难性遗忘问题，这使得这一问题值得研究。 过拟合：模型在训练数据上表现异常好，但由于拟合噪声或无关模式，无法有效泛化到未见数据，这在训练数据稀少的低资源场景中更为明显。 总结一下，我们的主要贡献包括：\n我们利用提示学习来探索预训练语言模型（PLM）的隐含能力，并提出了 Contrastive Prompt Learning framework (CPL) 框架，将其与一种新的基于边际的对比学习目标（CFRL）结合起来，同时缓解灾难性遗忘和过拟合问题。 我们通过利用大型语言模型（LLM）的力量引入了一种记忆增强策略，以提升较小的 PLM。这种策略使用精心设计的提示来指导 ChatGPT 生成样本，从而更好地对抗过拟合。 在两个 RE 基准上的大量实验表明，我们的方法优于最先进的模型，证明了缓解灾难性遗忘和过拟合的有效性。 Related Work Continual Learning 持续学习（Continual Learning, CL）旨在从一系列任务中不断学习新知识，同时避免遗忘旧知识。CL的主要挑战是灾难性遗忘。\n现有的CL方法分为三类：\n正则化方法：使用额外的约束来限制参数更新，使模型能够记住更多旧知识。 动态架构方法：动态扩展模型架构，以在任务序列不断出现时存储新知识。 基于记忆的方法：存储当前任务的一些典型样本，并在学习任务序列后重放记忆以复习旧知识。 在这些方法中，基于记忆的方法在自然语言处理（NLP）任务中最为有效。然而，新任务的数据并不总是充足的，而且获取高质量数据往往既昂贵又耗时。我们也采用基于记忆的策略，但我们更注重如何更好地利用预训练语言模型（PLMs）来解决 CFRE。\nPrompt Learning 提示学习随着GPT-3系列的诞生而出现，并在自然语言处理任务中取得了显著的性能，尤其是在小样本场景中。它通过添加提示词将下游任务重新表述为预训练任务，并引导预训练语言模型（PLMs）理解各种任务。之前的提示学习方法可以分为三类：\n硬提示：在句子中添加手工制作的提示词，并将其转换为掩码语言建模问题。尽管有效，但它需要针对不同任务的复杂专家知识，这既繁琐又耗时。 软提示：在句子中添加可连续训练的向量，这些向量可以被模型自动学习。然而，在没有任何先验专家知识的情况下，模型并不总能学到合适的提示，尤其是在低资源场景中。 混合提示：结合不可调的硬提示和可调的软提示，使模型能够在少量人工干预下轻松学习合适的模板。它被验证为最有效的方法。 我们专注于少样本设置，并采用混合提示来帮助预训练语言模型（PLMs）缓解灾难性遗忘和过拟合问题。\nMethod Framework Overview 整个 CPL 框架有三个模块：\nPrompt Representation，Contrastive Learning，Memory Augmentation Prompt Representation 我们提出了一种有效的半自动模板用于关系抽取（RE），将RE从分类问题转换为基于上下文的文本填充问题。\n给定一个输入 $x = [x_0,...,x_n]$，先将其转换为模板 $T(x)=[x_0,...,[E_0], e_h,[E_1], ..., [E_2],e_t,[E_3],...,x_n]$，其中 $e_h$ 为实体首部，$e_t$ 为实体尾部，$E_0,...,E_3$ 为实体位置。\n然后讲模板嵌入到模型中 $Emb(T(x)) = \\{Emb(x_0), \\ldots, h_0, Emb(e_h), h_1, \\ldots, h_2, Emb(e_t), h_3, \\ldots, Emb(x_n)$ ，其中 $Emb()$ 为 Embedding 函数、$h_i$ 是可学习向量。\n接着，Embeddings 被输入进 Encoder 中，得到句子的 hidden representation $m=Enc(Emb(T(x)))$ ，其中 $Enc()$ 为 Encoder 的隐含层，而 $m$ 是 MASK 的 hidden representation.\nContrastive Learning 我们设计了一种新的基于边界的对比学习方法，以获得判别性表示并关注困难样本，从而缓解过拟合。值得注意的是，通过这种方法，模型不需要在传统提示工程中的语言模块，从而节省了提示工程所需的劳动，并使方法更加通用。与之前工作中的线性分类器不同，我们的方法基于无参数的度量方法进行关系预测，更适合增量分类问题。\nMemory Augmentation 在当前任务训练后，我们首先选择当前训练数据的典型样本存储在记忆中，然后设计精细的提示来引导ChatGPT生成多样化的样本以增强记忆。\n代表性记忆采样：我们使用 K-means 算法将特征{z_i}|R_k|i=0聚类为L个簇。然后，对于每个簇，选择最接近质心的样本作为典型样本存储在记忆Mˆ中。\n提示数据增强：为了利用LLMs的丰富知识，我们设计了精细的提示来激发LLMs强大的语言生成能力以生成相关示例。我们选择GPT-3.5作为生成模型。以下是提示 ChatGPT 生成具有“founded by”关系样本的示例：\nExperiments ","wordCount":"141","inLanguage":"en","image":"http://localhost:1313/cover/Making_Pre-trained_Language_Models_Better_Continual_Few-Shot_Relation_Extractors.png","datePublished":"2024-09-20T00:00:00Z","dateModified":"2024-09-20T00:00:00Z","author":{"@type":"Person","name":"Kurong"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/posts/papernotes/making_pre-trained_language_models_better_continual_few-shot_relation_extractors/"},"publisher":{"@type":"Organization","name":"KurongBlog","logo":{"@type":"ImageObject","url":"http://localhost:1313/%3Clink%20/%20abs%20url%3E"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Home (Alt + H)"><img src=http://localhost:1313/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/categories/ title=categories><span>categories</span></a></li><li><a href=http://localhost:1313/tags/ title=tags><span>tags</span></a></li><li><a href=http://localhost:1313/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a>&nbsp;»&nbsp;<a href=http://localhost:1313/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">《Making Pre-trained Language Models Better Continual Few-Shot Relation Extractors》笔记</h1><div class=post-meta><span title='2024-09-20 00:00:00 +0000 UTC'>September 20, 2024</span>&nbsp;·&nbsp;Kurong&nbsp;|&nbsp;<a href=https://github.com/KurongTohsaka/KurongTohsaka.github.io/content/posts/PaperNotes/Making_Pre-trained_Language_Models_Better_Continual_Few-Shot_Relation_Extractors.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><figure class=entry-cover><img loading=eager src=http://localhost:1313/cover/Making_Pre-trained_Language_Models_Better_Continual_Few-Shot_Relation_Extractors.png alt><p></p></figure><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#link>Link</a></li><li><a href=#intro>Intro</a></li><li><a href=#related-work>Related Work</a><ul><li><a href=#continual-learning>Continual Learning</a></li><li><a href=#prompt-learning>Prompt Learning</a></li></ul></li><li><a href=#method>Method</a><ul><li><a href=#framework-overview>Framework Overview</a></li><li><a href=#prompt-representation>Prompt Representation</a></li><li><a href=#contrastive-learning>Contrastive Learning</a></li><li><a href=#memory-augmentation>Memory Augmentation</a></li></ul></li><li><a href=#experiments>Experiments</a></li></ul></nav></div></details></div><div class=post-content><h2 id=link>Link<a hidden class=anchor aria-hidden=true href=#link>#</a></h2><p>[<a href=https://arxiv.org/abs/2402.15713>2402.15713] Making Pre-trained Language Models Better Continual Few-Shot Relation Extractors (arxiv.org)</a></p><p>Accepted COLING 2024</p><blockquote><p>COLING: CCF B</p></blockquote><h2 id=intro>Intro<a hidden class=anchor aria-hidden=true href=#intro>#</a></h2><p>关系抽取是自然语言处理领域中的一个基本且重要的任务，旨在从句子或文档中提取实体之间的潜在关系。传统的 RE 方法在大量标注样本上训练模型，然后在具有相同标签空间的数据上进行测试。然而，在现实生活中，新关系不断涌现，这些模型在适应新关系时可能会出现显著的性能下降。此外，这些模型严重依赖于大量标注数据，这需要大量时间和精力来收集。</p><p>因此，提出了<strong>持续少样本关系抽取（Continual Few-shot Relation Extraction, CFRE）</strong>，其目标是在有限的标注数据约束下，持续学习新关系的同时保留先前学习的关系知识。这一实际任务带来了两个重大挑战：</p><ul><li><strong>灾难性遗忘</strong>：模型在学习新任务时突然忘记从前任务中获得的知识。最新研究指出，即使在大型语言模型中也存在灾难性遗忘问题，这使得这一问题值得研究。</li><li><strong>过拟合</strong>：模型在训练数据上表现异常好，但由于拟合噪声或无关模式，无法有效泛化到未见数据，这在训练数据稀少的低资源场景中更为明显。</li></ul><p>总结一下，我们的主要贡献包括：</p><ul><li>我们利用提示学习来探索预训练语言模型（PLM）的隐含能力，并提出了 <strong>C</strong>ontrastive <strong>P</strong>rompt <strong>L</strong>earning framework (CPL) 框架，将其与一种新的基于边际的对比学习目标（CFRL）结合起来，同时缓解灾难性遗忘和过拟合问题。</li><li>我们通过利用大型语言模型（LLM）的力量引入了一种记忆增强策略，以提升较小的 PLM。这种策略使用精心设计的提示来指导 ChatGPT 生成样本，从而更好地对抗过拟合。</li><li>在两个 RE 基准上的大量实验表明，我们的方法优于最先进的模型，证明了缓解灾难性遗忘和过拟合的有效性。</li></ul><h2 id=related-work>Related Work<a hidden class=anchor aria-hidden=true href=#related-work>#</a></h2><h3 id=continual-learning>Continual Learning<a hidden class=anchor aria-hidden=true href=#continual-learning>#</a></h3><p>持续学习（Continual Learning, CL）旨在从一系列任务中不断学习新知识，同时避免遗忘旧知识。CL的主要挑战是灾难性遗忘。</p><p>现有的CL方法分为三类：</p><ul><li><strong>正则化方法</strong>：使用额外的约束来限制参数更新，使模型能够记住更多旧知识。</li><li><strong>动态架构方法</strong>：动态扩展模型架构，以在任务序列不断出现时存储新知识。</li><li><strong>基于记忆的方法</strong>：存储当前任务的一些典型样本，并在学习任务序列后重放记忆以复习旧知识。</li></ul><p>在这些方法中，基于记忆的方法在自然语言处理（NLP）任务中最为有效。然而，新任务的数据并不总是充足的，而且获取高质量数据往往既昂贵又耗时。我们也采用基于记忆的策略，但我们更注重如何更好地利用预训练语言模型（PLMs）来解决 CFRE。</p><h3 id=prompt-learning>Prompt Learning<a hidden class=anchor aria-hidden=true href=#prompt-learning>#</a></h3><p>提示学习随着GPT-3系列的诞生而出现，并在自然语言处理任务中取得了显著的性能，尤其是在小样本场景中。它通过添加提示词将下游任务重新表述为预训练任务，并引导预训练语言模型（PLMs）理解各种任务。之前的提示学习方法可以分为三类：</p><ol><li><strong>硬提示</strong>：在句子中添加手工制作的提示词，并将其转换为掩码语言建模问题。尽管有效，但它需要针对不同任务的复杂专家知识，这既繁琐又耗时。</li><li><strong>软提示</strong>：在句子中添加可连续训练的向量，这些向量可以被模型自动学习。然而，在没有任何先验专家知识的情况下，模型并不总能学到合适的提示，尤其是在低资源场景中。</li><li><strong>混合提示</strong>：结合不可调的硬提示和可调的软提示，使模型能够在少量人工干预下轻松学习合适的模板。它被验证为最有效的方法。</li></ol><p>我们专注于少样本设置，并采用混合提示来帮助预训练语言模型（PLMs）缓解灾难性遗忘和过拟合问题。</p><h2 id=method>Method<a hidden class=anchor aria-hidden=true href=#method>#</a></h2><h3 id=framework-overview>Framework Overview<a hidden class=anchor aria-hidden=true href=#framework-overview>#</a></h3><p>整个 CPL 框架有三个模块：</p><ul><li>Prompt Representation，Contrastive Learning，Memory Augmentation</li></ul><p><img loading=lazy src=/img/PaperNotes/Making_Pre-trained_Language_Models_Better_Continual_Few-Shot_Relation_Extractors/img1.png alt></p><h3 id=prompt-representation>Prompt Representation<a hidden class=anchor aria-hidden=true href=#prompt-representation>#</a></h3><p>我们提出了一种有效的半自动模板用于关系抽取（RE），将RE从分类问题转换为基于上下文的文本填充问题。</p><p>给定一个输入 $x = [x_0,...,x_n]$，先将其转换为模板 $T(x)=[x_0,...,[E_0], e_h,[E_1], ..., [E_2],e_t,[E_3],...,x_n]$，其中 $e_h$ 为实体首部，$e_t$ 为实体尾部，$E_0,...,E_3$ 为实体位置。</p><p>然后讲模板嵌入到模型中 $Emb(T(x)) = \{Emb(x_0), \ldots, h_0, Emb(e_h), h_1, \ldots, h_2, Emb(e_t), h_3, \ldots, Emb(x_n)$ ，其中 $Emb()$ 为 Embedding 函数、$h_i$ 是可学习向量。</p><p>接着，Embeddings 被输入进 Encoder 中，得到句子的 hidden representation $m=Enc(Emb(T(x)))$ ，其中 $Enc()$ 为 Encoder 的隐含层，而 $m$ 是 MASK 的 hidden representation.</p><h3 id=contrastive-learning>Contrastive Learning<a hidden class=anchor aria-hidden=true href=#contrastive-learning>#</a></h3><p>我们设计了一种新的基于边界的对比学习方法，以获得判别性表示并关注困难样本，从而缓解过拟合。值得注意的是，通过这种方法，模型不需要在传统提示工程中的语言模块，从而节省了提示工程所需的劳动，并使方法更加通用。与之前工作中的线性分类器不同，我们的方法基于无参数的度量方法进行关系预测，更适合增量分类问题。</p><h3 id=memory-augmentation>Memory Augmentation<a hidden class=anchor aria-hidden=true href=#memory-augmentation>#</a></h3><p>在当前任务训练后，我们首先选择当前训练数据的典型样本存储在记忆中，然后设计精细的提示来引导ChatGPT生成多样化的样本以增强记忆。</p><ul><li><p><strong>代表性记忆采样</strong>：我们使用 K-means 算法将特征{z_i}|R_k|i=0聚类为L个簇。然后，对于每个簇，选择最接近质心的样本作为典型样本存储在记忆Mˆ中。</p></li><li><p><strong>提示数据增强</strong>：为了利用LLMs的丰富知识，我们设计了精细的提示来激发LLMs强大的语言生成能力以生成相关示例。我们选择GPT-3.5作为生成模型。以下是提示 ChatGPT 生成具有“founded by”关系样本的示例：</p><p><img loading=lazy src=/img/PaperNotes/Making_Pre-trained_Language_Models_Better_Continual_Few-Shot_Relation_Extractors/img2.png alt></p></li></ul><h2 id=experiments>Experiments<a hidden class=anchor aria-hidden=true href=#experiments>#</a></h2><p><img loading=lazy src=/img/PaperNotes/Making_Pre-trained_Language_Models_Better_Continual_Few-Shot_Relation_Extractors/img3.png alt></p><p><img loading=lazy src=/img/PaperNotes/Making_Pre-trained_Language_Models_Better_Continual_Few-Shot_Relation_Extractors/img4.png alt></p></div><footer class=post-footer><ul class=post-tags><li><a href=http://localhost:1313/tags/papernotes/>PaperNotes</a></li><li><a href=http://localhost:1313/tags/re/>RE</a></li><li><a href=http://localhost:1313/tags/coling/>COLING</a></li><li><a href=http://localhost:1313/tags/few-shot-learning/>Few-Shot Learning</a></li></ul><nav class=paginav><a class=prev href=http://localhost:1313/posts/papernotes/better_few-shot_relation_extraction_with_label_prompt_dropout/><span class=title>« Prev</span><br><span>《Better Few-Shot Relation Extraction with Label Prompt Dropout》笔记</span>
</a><a class=next href=http://localhost:1313/posts/papernotes/efficient_information_extraction_in_few-shot_relation_classification_through_contrastive_representation_learning/><span class=title>Next »</span><br><span>《Efficient Information Extraction in Few-Shot Relation Classification through Contrastive Representation Learning》笔记</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=http://localhost:1313/>KurongBlog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>