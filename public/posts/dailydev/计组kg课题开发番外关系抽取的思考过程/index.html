<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>《计组KG》课题开发番外：关系抽取的思考过程 | KurongBlog</title>
<meta name=keywords content="Daily Dev,Project Dev"><meta name=description content="现状
目前课题进行到了关系抽取这一步。在看完之前的RE综述后，我决定整一个 Joint 的 NER+RE 模型。目前已经完成了 NER 的标注工作，下一步工作自然就是 RE 的标注。但是 RE 的标注要比 NER 要困难的多，一个是对于关系的定义依赖于实体类型、句子词性等多种复杂要素，二是手工标注势必工作量巨大。所以 RE 的标注有什么解决方法呢？
我决定把整个思考过程记录下来，方便复盘。
相关开源库
thunlp/OpenNRE：用于神经关系提取 （NRE） 的开源包 (github.com)
SapienzaNLP/relik：检索、读取和 LinK：学术预算上的快速准确的实体链接和关系提取 （ACL 2024） (github.com)
huggingface/setfit：使用句子转换器进行高效的少样本学习 (github.com)
EleutherAI/lm-evaluation-harness：一种用于语言模型小样本评估的框架。 (github.com)
关系抽取的可能方案
首先能想到的两种常见方案：

使用 RE 预训练模型预标注：和 NER 的标注工作流程一致，但是中文 RE 预训练模型很难找
远程监督：使用已有的知识库或实体关系词典，对大规模文本进行远程监督标注。但是不适合当前课题的小规模数据集，而且没有现成的大量 RE 标注数据

以上两种方案中只有预训练模型的预标注还算可行，那有没有什么方法可以加速这一过程？可以看看下面的两种方法：


半监督学习：结合少量人工标注数据和大量未标注数据，通过半监督学习的方法训练模型


few-shot 小样本学习：使用少量人工标注的数据对few-shot模型进行训练，以提高模型在少样本情况下的泛化能力


这两种方案值得单独进行介绍。
半监督学习
半监督学习（Semi-Supervised Learning）是一种结合了监督学习和无监督学习的机器学习方法。它利用少量的标记数据和大量的未标记数据来训练模型，从而提高模型的泛化能力和性能。
半监督学习的样本标注依赖假设，以下是部分常见假设：

平滑性假设：如果两个数据点在高密度区域中且距离很近，那么它们的输出也应该相似
聚类假设：如果数据点形成簇，那么同一簇中的数据点应该属于同一类
流形假设：高维数据通常位于低维流形上，同一流形上的数据点具有相同的标签

常用的方法有：

一致性正则化：假设对未标记数据加入小扰动后，其分类结果不应改变
伪标签：使用已标记数据训练初始模型，然后用该模型对未标记数据进行预测，生成伪标签，再将这些伪标签数据加入训练集中进行再训练
生成式模型：利用生成模型（如GANs）从数据分布中生成样本，并将这些样本用于训练分类器

优势：

利用未标注数据，提高模型的泛化能力和性能
较低标注成本
适应性强，可以应用于多种任务

缺点：

依赖数据假设：半监督学习通常假设未标记数据和标记数据在特征空间中具有相似性，这在实际应用中并不总是成立。如果这些假设不成立，可能会导致模型性能下降
标签传播误差
数据不平衡问题

我曾经在 kaggle 比赛中使用过半监督学习中的伪标签方法，只从工程实现的角度看比较容易，但是模型性能不一定有提升。"><meta name=author content="Kurong"><link rel=canonical href=http://localhost:1313/posts/dailydev/%E8%AE%A1%E7%BB%84kg%E8%AF%BE%E9%A2%98%E5%BC%80%E5%8F%91%E7%95%AA%E5%A4%96%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E7%9A%84%E6%80%9D%E8%80%83%E8%BF%87%E7%A8%8B/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/posts/dailydev/%E8%AE%A1%E7%BB%84kg%E8%AF%BE%E9%A2%98%E5%BC%80%E5%8F%91%E7%95%AA%E5%A4%96%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E7%9A%84%E6%80%9D%E8%80%83%E8%BF%87%E7%A8%8B/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],throwOnError:!1})})</script><meta property="og:title" content="《计组KG》课题开发番外：关系抽取的思考过程"><meta property="og:description" content="现状
目前课题进行到了关系抽取这一步。在看完之前的RE综述后，我决定整一个 Joint 的 NER+RE 模型。目前已经完成了 NER 的标注工作，下一步工作自然就是 RE 的标注。但是 RE 的标注要比 NER 要困难的多，一个是对于关系的定义依赖于实体类型、句子词性等多种复杂要素，二是手工标注势必工作量巨大。所以 RE 的标注有什么解决方法呢？
我决定把整个思考过程记录下来，方便复盘。
相关开源库
thunlp/OpenNRE：用于神经关系提取 （NRE） 的开源包 (github.com)
SapienzaNLP/relik：检索、读取和 LinK：学术预算上的快速准确的实体链接和关系提取 （ACL 2024） (github.com)
huggingface/setfit：使用句子转换器进行高效的少样本学习 (github.com)
EleutherAI/lm-evaluation-harness：一种用于语言模型小样本评估的框架。 (github.com)
关系抽取的可能方案
首先能想到的两种常见方案：

使用 RE 预训练模型预标注：和 NER 的标注工作流程一致，但是中文 RE 预训练模型很难找
远程监督：使用已有的知识库或实体关系词典，对大规模文本进行远程监督标注。但是不适合当前课题的小规模数据集，而且没有现成的大量 RE 标注数据

以上两种方案中只有预训练模型的预标注还算可行，那有没有什么方法可以加速这一过程？可以看看下面的两种方法：


半监督学习：结合少量人工标注数据和大量未标注数据，通过半监督学习的方法训练模型


few-shot 小样本学习：使用少量人工标注的数据对few-shot模型进行训练，以提高模型在少样本情况下的泛化能力


这两种方案值得单独进行介绍。
半监督学习
半监督学习（Semi-Supervised Learning）是一种结合了监督学习和无监督学习的机器学习方法。它利用少量的标记数据和大量的未标记数据来训练模型，从而提高模型的泛化能力和性能。
半监督学习的样本标注依赖假设，以下是部分常见假设：

平滑性假设：如果两个数据点在高密度区域中且距离很近，那么它们的输出也应该相似
聚类假设：如果数据点形成簇，那么同一簇中的数据点应该属于同一类
流形假设：高维数据通常位于低维流形上，同一流形上的数据点具有相同的标签

常用的方法有：

一致性正则化：假设对未标记数据加入小扰动后，其分类结果不应改变
伪标签：使用已标记数据训练初始模型，然后用该模型对未标记数据进行预测，生成伪标签，再将这些伪标签数据加入训练集中进行再训练
生成式模型：利用生成模型（如GANs）从数据分布中生成样本，并将这些样本用于训练分类器

优势：

利用未标注数据，提高模型的泛化能力和性能
较低标注成本
适应性强，可以应用于多种任务

缺点：

依赖数据假设：半监督学习通常假设未标记数据和标记数据在特征空间中具有相似性，这在实际应用中并不总是成立。如果这些假设不成立，可能会导致模型性能下降
标签传播误差
数据不平衡问题

我曾经在 kaggle 比赛中使用过半监督学习中的伪标签方法，只从工程实现的角度看比较容易，但是模型性能不一定有提升。"><meta property="og:type" content="article"><meta property="og:url" content="http://localhost:1313/posts/dailydev/%E8%AE%A1%E7%BB%84kg%E8%AF%BE%E9%A2%98%E5%BC%80%E5%8F%91%E7%95%AA%E5%A4%96%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E7%9A%84%E6%80%9D%E8%80%83%E8%BF%87%E7%A8%8B/"><meta property="og:image" content="http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-08-24T00:00:00+00:00"><meta property="article:modified_time" content="2024-08-24T00:00:00+00:00"><meta property="og:site_name" content="KurongBlog"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="《计组KG》课题开发番外：关系抽取的思考过程"><meta name=twitter:description content="现状
目前课题进行到了关系抽取这一步。在看完之前的RE综述后，我决定整一个 Joint 的 NER+RE 模型。目前已经完成了 NER 的标注工作，下一步工作自然就是 RE 的标注。但是 RE 的标注要比 NER 要困难的多，一个是对于关系的定义依赖于实体类型、句子词性等多种复杂要素，二是手工标注势必工作量巨大。所以 RE 的标注有什么解决方法呢？
我决定把整个思考过程记录下来，方便复盘。
相关开源库
thunlp/OpenNRE：用于神经关系提取 （NRE） 的开源包 (github.com)
SapienzaNLP/relik：检索、读取和 LinK：学术预算上的快速准确的实体链接和关系提取 （ACL 2024） (github.com)
huggingface/setfit：使用句子转换器进行高效的少样本学习 (github.com)
EleutherAI/lm-evaluation-harness：一种用于语言模型小样本评估的框架。 (github.com)
关系抽取的可能方案
首先能想到的两种常见方案：

使用 RE 预训练模型预标注：和 NER 的标注工作流程一致，但是中文 RE 预训练模型很难找
远程监督：使用已有的知识库或实体关系词典，对大规模文本进行远程监督标注。但是不适合当前课题的小规模数据集，而且没有现成的大量 RE 标注数据

以上两种方案中只有预训练模型的预标注还算可行，那有没有什么方法可以加速这一过程？可以看看下面的两种方法：


半监督学习：结合少量人工标注数据和大量未标注数据，通过半监督学习的方法训练模型


few-shot 小样本学习：使用少量人工标注的数据对few-shot模型进行训练，以提高模型在少样本情况下的泛化能力


这两种方案值得单独进行介绍。
半监督学习
半监督学习（Semi-Supervised Learning）是一种结合了监督学习和无监督学习的机器学习方法。它利用少量的标记数据和大量的未标记数据来训练模型，从而提高模型的泛化能力和性能。
半监督学习的样本标注依赖假设，以下是部分常见假设：

平滑性假设：如果两个数据点在高密度区域中且距离很近，那么它们的输出也应该相似
聚类假设：如果数据点形成簇，那么同一簇中的数据点应该属于同一类
流形假设：高维数据通常位于低维流形上，同一流形上的数据点具有相同的标签

常用的方法有：

一致性正则化：假设对未标记数据加入小扰动后，其分类结果不应改变
伪标签：使用已标记数据训练初始模型，然后用该模型对未标记数据进行预测，生成伪标签，再将这些伪标签数据加入训练集中进行再训练
生成式模型：利用生成模型（如GANs）从数据分布中生成样本，并将这些样本用于训练分类器

优势：

利用未标注数据，提高模型的泛化能力和性能
较低标注成本
适应性强，可以应用于多种任务

缺点：

依赖数据假设：半监督学习通常假设未标记数据和标记数据在特征空间中具有相似性，这在实际应用中并不总是成立。如果这些假设不成立，可能会导致模型性能下降
标签传播误差
数据不平衡问题

我曾经在 kaggle 比赛中使用过半监督学习中的伪标签方法，只从工程实现的角度看比较容易，但是模型性能不一定有提升。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:1313/posts/"},{"@type":"ListItem","position":2,"name":"《计组KG》课题开发番外：关系抽取的思考过程","item":"http://localhost:1313/posts/dailydev/%E8%AE%A1%E7%BB%84kg%E8%AF%BE%E9%A2%98%E5%BC%80%E5%8F%91%E7%95%AA%E5%A4%96%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E7%9A%84%E6%80%9D%E8%80%83%E8%BF%87%E7%A8%8B/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"《计组KG》课题开发番外：关系抽取的思考过程","name":"《计组KG》课题开发番外：关系抽取的思考过程","description":"现状 目前课题进行到了关系抽取这一步。在看完之前的RE综述后，我决定整一个 Joint 的 NER+RE 模型。目前已经完成了 NER 的标注工作，下一步工作自然就是 RE 的标注。但是 RE 的标注要比 NER 要困难的多，一个是对于关系的定义依赖于实体类型、句子词性等多种复杂要素，二是手工标注势必工作量巨大。所以 RE 的标注有什么解决方法呢？\n我决定把整个思考过程记录下来，方便复盘。\n相关开源库 thunlp/OpenNRE：用于神经关系提取 （NRE） 的开源包 (github.com)\nSapienzaNLP/relik：检索、读取和 LinK：学术预算上的快速准确的实体链接和关系提取 （ACL 2024） (github.com)\nhuggingface/setfit：使用句子转换器进行高效的少样本学习 (github.com)\nEleutherAI/lm-evaluation-harness：一种用于语言模型小样本评估的框架。 (github.com)\n关系抽取的可能方案 首先能想到的两种常见方案：\n使用 RE 预训练模型预标注：和 NER 的标注工作流程一致，但是中文 RE 预训练模型很难找 远程监督：使用已有的知识库或实体关系词典，对大规模文本进行远程监督标注。但是不适合当前课题的小规模数据集，而且没有现成的大量 RE 标注数据 以上两种方案中只有预训练模型的预标注还算可行，那有没有什么方法可以加速这一过程？可以看看下面的两种方法：\n半监督学习：结合少量人工标注数据和大量未标注数据，通过半监督学习的方法训练模型\nfew-shot 小样本学习：使用少量人工标注的数据对few-shot模型进行训练，以提高模型在少样本情况下的泛化能力\n这两种方案值得单独进行介绍。\n半监督学习 半监督学习（Semi-Supervised Learning）是一种结合了监督学习和无监督学习的机器学习方法。它利用少量的标记数据和大量的未标记数据来训练模型，从而提高模型的泛化能力和性能。\n半监督学习的样本标注依赖假设，以下是部分常见假设：\n平滑性假设：如果两个数据点在高密度区域中且距离很近，那么它们的输出也应该相似 聚类假设：如果数据点形成簇，那么同一簇中的数据点应该属于同一类 流形假设：高维数据通常位于低维流形上，同一流形上的数据点具有相同的标签 常用的方法有：\n一致性正则化：假设对未标记数据加入小扰动后，其分类结果不应改变 伪标签：使用已标记数据训练初始模型，然后用该模型对未标记数据进行预测，生成伪标签，再将这些伪标签数据加入训练集中进行再训练 生成式模型：利用生成模型（如GANs）从数据分布中生成样本，并将这些样本用于训练分类器 优势：\n利用未标注数据，提高模型的泛化能力和性能 较低标注成本 适应性强，可以应用于多种任务 缺点：\n依赖数据假设：半监督学习通常假设未标记数据和标记数据在特征空间中具有相似性，这在实际应用中并不总是成立。如果这些假设不成立，可能会导致模型性能下降 标签传播误差 数据不平衡问题 我曾经在 kaggle 比赛中使用过半监督学习中的伪标签方法，只从工程实现的角度看比较容易，但是模型性能不一定有提升。\n","keywords":["Daily Dev","Project Dev"],"articleBody":"现状 目前课题进行到了关系抽取这一步。在看完之前的RE综述后，我决定整一个 Joint 的 NER+RE 模型。目前已经完成了 NER 的标注工作，下一步工作自然就是 RE 的标注。但是 RE 的标注要比 NER 要困难的多，一个是对于关系的定义依赖于实体类型、句子词性等多种复杂要素，二是手工标注势必工作量巨大。所以 RE 的标注有什么解决方法呢？\n我决定把整个思考过程记录下来，方便复盘。\n相关开源库 thunlp/OpenNRE：用于神经关系提取 （NRE） 的开源包 (github.com)\nSapienzaNLP/relik：检索、读取和 LinK：学术预算上的快速准确的实体链接和关系提取 （ACL 2024） (github.com)\nhuggingface/setfit：使用句子转换器进行高效的少样本学习 (github.com)\nEleutherAI/lm-evaluation-harness：一种用于语言模型小样本评估的框架。 (github.com)\n关系抽取的可能方案 首先能想到的两种常见方案：\n使用 RE 预训练模型预标注：和 NER 的标注工作流程一致，但是中文 RE 预训练模型很难找 远程监督：使用已有的知识库或实体关系词典，对大规模文本进行远程监督标注。但是不适合当前课题的小规模数据集，而且没有现成的大量 RE 标注数据 以上两种方案中只有预训练模型的预标注还算可行，那有没有什么方法可以加速这一过程？可以看看下面的两种方法：\n半监督学习：结合少量人工标注数据和大量未标注数据，通过半监督学习的方法训练模型\nfew-shot 小样本学习：使用少量人工标注的数据对few-shot模型进行训练，以提高模型在少样本情况下的泛化能力\n这两种方案值得单独进行介绍。\n半监督学习 半监督学习（Semi-Supervised Learning）是一种结合了监督学习和无监督学习的机器学习方法。它利用少量的标记数据和大量的未标记数据来训练模型，从而提高模型的泛化能力和性能。\n半监督学习的样本标注依赖假设，以下是部分常见假设：\n平滑性假设：如果两个数据点在高密度区域中且距离很近，那么它们的输出也应该相似 聚类假设：如果数据点形成簇，那么同一簇中的数据点应该属于同一类 流形假设：高维数据通常位于低维流形上，同一流形上的数据点具有相同的标签 常用的方法有：\n一致性正则化：假设对未标记数据加入小扰动后，其分类结果不应改变 伪标签：使用已标记数据训练初始模型，然后用该模型对未标记数据进行预测，生成伪标签，再将这些伪标签数据加入训练集中进行再训练 生成式模型：利用生成模型（如GANs）从数据分布中生成样本，并将这些样本用于训练分类器 优势：\n利用未标注数据，提高模型的泛化能力和性能 较低标注成本 适应性强，可以应用于多种任务 缺点：\n依赖数据假设：半监督学习通常假设未标记数据和标记数据在特征空间中具有相似性，这在实际应用中并不总是成立。如果这些假设不成立，可能会导致模型性能下降 标签传播误差 数据不平衡问题 我曾经在 kaggle 比赛中使用过半监督学习中的伪标签方法，只从工程实现的角度看比较容易，但是模型性能不一定有提升。\n该方法在本任务上的应用比较困难：\n使用这种方法如何生成比较准确的标签是一个比较难的问题，尤其是现在还没有标签 不好与 NER 构建 Joint 模型 few-shot 小样本学习 few-shot 学习是一种机器学习方法，旨在通过极少量的训练样本进行学习和泛化。与传统的机器学习方法需要大量标注数据不同，few-shot 学习能够在数据稀缺的情况下仍然有效地进行学习和预测。\nfew-shot 主要分为以下几类：\n基于生成模型的方法：通过生成模型来模拟数据分布，从而生成更多的训练样本\n基于判别模型的方法：通过判别模型直接学习样本之间的相似性或差异性\n元学习（Meta-learning）：通过学习如何学习，使模型能够快速适应新任务\n优势：\n数据需求少：能够在少量标注数据的情况下进行有效学习，降低数据标注成本 快速适应新任务：通过元学习等方法，模型可以快速适应新的任务和数据分布 缺点：\n对样本质量要求高：由于样本数量少，样本的质量对模型性能影响较大。 模型复杂度高：一些 few-shot 学习方法（如元学习）需要复杂的模型设计和训练过程 在 RE 中使用 few-shot 的一种基于预标注的方案：\n先少量标注下每个关系标签下的样本，然后用这部分数据去微调一个结合了 few-shot 的小预训练模型，再用该模型去做预标注。得到预标注数据集之后，再去训练一个更大的预训练模型来完成 RE 决定采用的方案 我决定用 few-shot 方案，原因有以下几点：\nKG 对关系抽取任务的指标要求很高，使用半监督学习的话会使数据集中满是噪声和错误样本 标注少量数据，使用元学习来完成 few-shot 学习。这一过程很好的与预标注契合到了一起 few-shot 近几年相对热门，蹭蹭热度 元学习参见：\n小样本学习——概念、原理与方法简介（Few-shot learning） - 知乎 (zhihu.com) 目前暂定的可行方案，大致如下：\n少量标注下每个关系标签下的样本 训练一个多层 BiLSTM-CRF 模型作为 few-shot 学习的 base ，然后在训练阶段用元学习中的 MAML 方法优化训练过程 用上面的模型做一次预标注，然后再人工优化一下 构建一个 NER-RE 的 Joint End2end模型 示例代码参考如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 import torch import torch.nn as nn import torch.optim as optim from torchcrf import CRF # 定义BiLSTM-CRF模型 class BiLSTM_CRF(nn.Module): def __init__(self, vocab_size, embedding_dim, hidden_dim, tagset_size): super(BiLSTM_CRF, self).__init__() self.embedding = nn.Embedding(vocab_size, embedding_dim) self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2, num_layers=2, bidirectional=True, batch_first=True) self.hidden2tag = nn.Linear(hidden_dim, tagset_size) self.crf = CRF(tagset_size, batch_first=True) def forward(self, x): embeds = self.embedding(x) lstm_out, _ = self.lstm(embeds) emissions = self.hidden2tag(lstm_out) return emissions def loss(self, emissions, tags, mask): return -self.crf(emissions, tags, mask=mask) def decode(self, emissions, mask): return self.crf.decode(emissions, mask=mask) # MAML训练函数 def train_maml(model, tasks, inner_lr, outer_lr, inner_steps, outer_steps): optimizer = optim.Adam(model.parameters(), lr=outer_lr) for step in range(outer_steps): meta_loss = 0 for task in tasks: # 内层优化 task_model = BiLSTM_CRF(vocab_size, embedding_dim, hidden_dim, tagset_size) task_model.load_state_dict(model.state_dict()) task_optimizer = optim.SGD(task_model.parameters(), lr=inner_lr) for _ in range(inner_steps): x, y, mask = task.sample() emissions = task_model(x) loss = task_model.loss(emissions, y, mask) task_optimizer.zero_grad() loss.backward() task_optimizer.step() # 外层优化 x, y, mask = task.sample() emissions = task_model(x) loss = task_model.loss(emissions, y, mask) meta_loss += loss optimizer.zero_grad() meta_loss.backward() optimizer.step() # 示例任务 class Task: def __init__(self, data): self.data = data def sample(self): x, y, mask = zip(*self.data) return torch.tensor(x), torch.tensor(y), torch.tensor(mask) # 训练MAML模型 vocab_size = 5000 # 词汇表大小 embedding_dim = 100 # 词向量维度 hidden_dim = 256 # 隐藏层维度 tagset_size = 10 # 标签集大小 model = BiLSTM_CRF(vocab_size, embedding_dim, hidden_dim, tagset_size) tasks = [Task(data) for data in task_data] # task_data为预处理好的任务数据 train_maml(model, tasks, inner_lr=0.01, outer_lr=0.001, inner_steps=5, outer_steps=1000) ","wordCount":"431","inLanguage":"en","image":"http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E","datePublished":"2024-08-24T00:00:00Z","dateModified":"2024-08-24T00:00:00Z","author":{"@type":"Person","name":"Kurong"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/posts/dailydev/%E8%AE%A1%E7%BB%84kg%E8%AF%BE%E9%A2%98%E5%BC%80%E5%8F%91%E7%95%AA%E5%A4%96%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E7%9A%84%E6%80%9D%E8%80%83%E8%BF%87%E7%A8%8B/"},"publisher":{"@type":"Organization","name":"KurongBlog","logo":{"@type":"ImageObject","url":"http://localhost:1313/%3Clink%20/%20abs%20url%3E"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Home (Alt + H)"><img src=http://localhost:1313/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/categories/ title=categories><span>categories</span></a></li><li><a href=http://localhost:1313/tags/ title=tags><span>tags</span></a></li><li><a href=http://localhost:1313/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a>&nbsp;»&nbsp;<a href=http://localhost:1313/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">《计组KG》课题开发番外：关系抽取的思考过程</h1><div class=post-meta><span title='2024-08-24 00:00:00 +0000 UTC'>August 24, 2024</span>&nbsp;·&nbsp;Kurong&nbsp;|&nbsp;<a href=https://github.com/KurongTohsaka/KurongTohsaka.github.io/content/posts/DailyDev/%e3%80%8a%e8%ae%a1%e7%bb%84KG%e3%80%8b%e8%af%be%e9%a2%98%e5%bc%80%e5%8f%91%e7%95%aa%e5%a4%96%ef%bc%9a%e5%85%b3%e7%b3%bb%e6%8a%bd%e5%8f%96%e7%9a%84%e6%80%9d%e8%80%83%e8%bf%87%e7%a8%8b.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#现状>现状</a></li><li><a href=#相关开源库>相关开源库</a></li><li><a href=#关系抽取的可能方案>关系抽取的可能方案</a><ul><li><a href=#半监督学习>半监督学习</a></li><li><a href=#few-shot-小样本学习>few-shot 小样本学习</a></li></ul></li><li><a href=#决定采用的方案>决定采用的方案</a></li></ul></nav></div></details></div><div class=post-content><h2 id=现状>现状<a hidden class=anchor aria-hidden=true href=#现状>#</a></h2><p>目前课题进行到了关系抽取这一步。在看完之前的RE综述后，我决定整一个 Joint 的 NER+RE 模型。目前已经完成了 NER 的标注工作，下一步工作自然就是 RE 的标注。但是 RE 的标注要比 NER 要困难的多，一个是对于关系的定义依赖于实体类型、句子词性等多种复杂要素，二是手工标注势必工作量巨大。所以 RE 的标注有什么解决方法呢？</p><p>我决定把整个思考过程记录下来，方便复盘。</p><h2 id=相关开源库>相关开源库<a hidden class=anchor aria-hidden=true href=#相关开源库>#</a></h2><p><a href=https://github.com/thunlp/OpenNRE>thunlp/OpenNRE：用于神经关系提取 （NRE） 的开源包 (github.com)</a></p><p><a href="https://github.com/SapienzaNLP/relik?tab=readme-ov-file">SapienzaNLP/relik：检索、读取和 LinK：学术预算上的快速准确的实体链接和关系提取 （ACL 2024） (github.com)</a></p><p><a href=https://github.com/huggingface/setfit>huggingface/setfit：使用句子转换器进行高效的少样本学习 (github.com)</a></p><p><a href=https://github.com/EleutherAI/lm-evaluation-harness>EleutherAI/lm-evaluation-harness：一种用于语言模型小样本评估的框架。 (github.com)</a></p><h2 id=关系抽取的可能方案>关系抽取的可能方案<a hidden class=anchor aria-hidden=true href=#关系抽取的可能方案>#</a></h2><p>首先能想到的两种常见方案：</p><ul><li>使用 RE 预训练模型预标注：和 NER 的标注工作流程一致，但是中文 RE 预训练模型很难找</li><li>远程监督：使用已有的知识库或实体关系词典，对大规模文本进行远程监督标注。但是不适合当前课题的小规模数据集，而且没有现成的大量 RE 标注数据</li></ul><p>以上两种方案中只有预训练模型的预标注还算可行，那有没有什么方法可以加速这一过程？可以看看下面的两种方法：</p><ul><li><p>半监督学习：结合少量人工标注数据和大量未标注数据，通过半监督学习的方法训练模型</p></li><li><p>few-shot 小样本学习：使用少量人工标注的数据对few-shot模型进行训练，以提高模型在少样本情况下的泛化能力</p></li></ul><p>这两种方案值得单独进行介绍。</p><h3 id=半监督学习>半监督学习<a hidden class=anchor aria-hidden=true href=#半监督学习>#</a></h3><p>半监督学习（Semi-Supervised Learning）是一种结合了监督学习和无监督学习的机器学习方法。它利用少量的标记数据和大量的未标记数据来训练模型，从而提高模型的泛化能力和性能。</p><p>半监督学习的样本标注依赖假设，以下是部分常见假设：</p><ul><li>平滑性假设：如果两个数据点在高密度区域中且距离很近，那么它们的输出也应该相似</li><li>聚类假设：如果数据点形成簇，那么同一簇中的数据点应该属于同一类</li><li>流形假设：高维数据通常位于低维流形上，同一流形上的数据点具有相同的标签</li></ul><p>常用的方法有：</p><ul><li>一致性正则化：假设对未标记数据加入小扰动后，其分类结果不应改变</li><li>伪标签：使用已标记数据训练初始模型，然后用该模型对未标记数据进行预测，生成伪标签，再将这些伪标签数据加入训练集中进行再训练</li><li>生成式模型：利用生成模型（如GANs）从数据分布中生成样本，并将这些样本用于训练分类器</li></ul><p>优势：</p><ul><li>利用未标注数据，提高模型的泛化能力和性能</li><li>较低标注成本</li><li>适应性强，可以应用于多种任务</li></ul><p>缺点：</p><ul><li>依赖数据假设：半监督学习通常假设未标记数据和标记数据在特征空间中具有相似性，这在实际应用中并不总是成立。如果这些假设不成立，可能会导致模型性能下降</li><li>标签传播误差</li><li>数据不平衡问题</li></ul><p>我曾经在 kaggle 比赛中使用过半监督学习中的伪标签方法，只从工程实现的角度看比较容易，但是模型性能不一定有提升。</p><p>该方法在本任务上的应用比较困难：</p><ul><li>使用这种方法如何生成比较准确的标签是一个比较难的问题，尤其是现在还没有标签</li><li>不好与 NER 构建 Joint 模型</li></ul><h3 id=few-shot-小样本学习>few-shot 小样本学习<a hidden class=anchor aria-hidden=true href=#few-shot-小样本学习>#</a></h3><p>few-shot 学习是一种机器学习方法，旨在通过极少量的训练样本进行学习和泛化。与传统的机器学习方法需要大量标注数据不同，few-shot 学习能够在数据稀缺的情况下仍然有效地进行学习和预测。</p><p>few-shot 主要分为以下几类：</p><ul><li><p>基于生成模型的方法：通过生成模型来模拟数据分布，从而生成更多的训练样本</p></li><li><p>基于判别模型的方法：通过判别模型直接学习样本之间的相似性或差异性</p></li><li><p>元学习（Meta-learning）：通过学习如何学习，使模型能够快速适应新任务</p></li></ul><p>优势：</p><ul><li>数据需求少：能够在少量标注数据的情况下进行有效学习，降低数据标注成本</li><li>快速适应新任务：通过元学习等方法，模型可以快速适应新的任务和数据分布</li></ul><p>缺点：</p><ul><li>对样本质量要求高：由于样本数量少，样本的质量对模型性能影响较大。</li><li>模型复杂度高：一些 few-shot 学习方法（如元学习）需要复杂的模型设计和训练过程</li></ul><p>在 RE 中使用 few-shot 的一种基于预标注的方案：</p><ul><li>先少量标注下每个关系标签下的样本，然后用这部分数据去微调一个结合了 few-shot 的小预训练模型，再用该模型去做预标注。得到预标注数据集之后，再去训练一个更大的预训练模型来完成 RE</li></ul><h2 id=决定采用的方案>决定采用的方案<a hidden class=anchor aria-hidden=true href=#决定采用的方案>#</a></h2><p>我决定用 few-shot 方案，原因有以下几点：</p><ol><li>KG 对关系抽取任务的指标要求很高，使用半监督学习的话会使数据集中满是噪声和错误样本</li><li>标注少量数据，使用元学习来完成 few-shot 学习。这一过程很好的与预标注契合到了一起</li><li>few-shot 近几年相对热门，蹭蹭热度</li></ol><p>元学习参见：</p><ul><li><a href=https://zhuanlan.zhihu.com/p/258562899>小样本学习——概念、原理与方法简介（Few-shot learning） - 知乎 (zhihu.com)</a></li></ul><p>目前暂定的可行方案，大致如下：</p><ul><li>少量标注下每个关系标签下的样本</li><li>训练一个多层 BiLSTM-CRF 模型作为 few-shot 学习的 base ，然后在训练阶段用元学习中的 MAML 方法优化训练过程</li><li>用上面的模型做一次预标注，然后再人工优化一下</li><li>构建一个 NER-RE 的 Joint End2end模型</li></ul><p>示例代码参考如下：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-0-1><a class=lnlinks href=#hl-0-1> 1</a>
</span><span class=lnt id=hl-0-2><a class=lnlinks href=#hl-0-2> 2</a>
</span><span class=lnt id=hl-0-3><a class=lnlinks href=#hl-0-3> 3</a>
</span><span class=lnt id=hl-0-4><a class=lnlinks href=#hl-0-4> 4</a>
</span><span class=lnt id=hl-0-5><a class=lnlinks href=#hl-0-5> 5</a>
</span><span class=lnt id=hl-0-6><a class=lnlinks href=#hl-0-6> 6</a>
</span><span class=lnt id=hl-0-7><a class=lnlinks href=#hl-0-7> 7</a>
</span><span class=lnt id=hl-0-8><a class=lnlinks href=#hl-0-8> 8</a>
</span><span class=lnt id=hl-0-9><a class=lnlinks href=#hl-0-9> 9</a>
</span><span class=lnt id=hl-0-10><a class=lnlinks href=#hl-0-10>10</a>
</span><span class=lnt id=hl-0-11><a class=lnlinks href=#hl-0-11>11</a>
</span><span class=lnt id=hl-0-12><a class=lnlinks href=#hl-0-12>12</a>
</span><span class=lnt id=hl-0-13><a class=lnlinks href=#hl-0-13>13</a>
</span><span class=lnt id=hl-0-14><a class=lnlinks href=#hl-0-14>14</a>
</span><span class=lnt id=hl-0-15><a class=lnlinks href=#hl-0-15>15</a>
</span><span class=lnt id=hl-0-16><a class=lnlinks href=#hl-0-16>16</a>
</span><span class=lnt id=hl-0-17><a class=lnlinks href=#hl-0-17>17</a>
</span><span class=lnt id=hl-0-18><a class=lnlinks href=#hl-0-18>18</a>
</span><span class=lnt id=hl-0-19><a class=lnlinks href=#hl-0-19>19</a>
</span><span class=lnt id=hl-0-20><a class=lnlinks href=#hl-0-20>20</a>
</span><span class=lnt id=hl-0-21><a class=lnlinks href=#hl-0-21>21</a>
</span><span class=lnt id=hl-0-22><a class=lnlinks href=#hl-0-22>22</a>
</span><span class=lnt id=hl-0-23><a class=lnlinks href=#hl-0-23>23</a>
</span><span class=lnt id=hl-0-24><a class=lnlinks href=#hl-0-24>24</a>
</span><span class=lnt id=hl-0-25><a class=lnlinks href=#hl-0-25>25</a>
</span><span class=lnt id=hl-0-26><a class=lnlinks href=#hl-0-26>26</a>
</span><span class=lnt id=hl-0-27><a class=lnlinks href=#hl-0-27>27</a>
</span><span class=lnt id=hl-0-28><a class=lnlinks href=#hl-0-28>28</a>
</span><span class=lnt id=hl-0-29><a class=lnlinks href=#hl-0-29>29</a>
</span><span class=lnt id=hl-0-30><a class=lnlinks href=#hl-0-30>30</a>
</span><span class=lnt id=hl-0-31><a class=lnlinks href=#hl-0-31>31</a>
</span><span class=lnt id=hl-0-32><a class=lnlinks href=#hl-0-32>32</a>
</span><span class=lnt id=hl-0-33><a class=lnlinks href=#hl-0-33>33</a>
</span><span class=lnt id=hl-0-34><a class=lnlinks href=#hl-0-34>34</a>
</span><span class=lnt id=hl-0-35><a class=lnlinks href=#hl-0-35>35</a>
</span><span class=lnt id=hl-0-36><a class=lnlinks href=#hl-0-36>36</a>
</span><span class=lnt id=hl-0-37><a class=lnlinks href=#hl-0-37>37</a>
</span><span class=lnt id=hl-0-38><a class=lnlinks href=#hl-0-38>38</a>
</span><span class=lnt id=hl-0-39><a class=lnlinks href=#hl-0-39>39</a>
</span><span class=lnt id=hl-0-40><a class=lnlinks href=#hl-0-40>40</a>
</span><span class=lnt id=hl-0-41><a class=lnlinks href=#hl-0-41>41</a>
</span><span class=lnt id=hl-0-42><a class=lnlinks href=#hl-0-42>42</a>
</span><span class=lnt id=hl-0-43><a class=lnlinks href=#hl-0-43>43</a>
</span><span class=lnt id=hl-0-44><a class=lnlinks href=#hl-0-44>44</a>
</span><span class=lnt id=hl-0-45><a class=lnlinks href=#hl-0-45>45</a>
</span><span class=lnt id=hl-0-46><a class=lnlinks href=#hl-0-46>46</a>
</span><span class=lnt id=hl-0-47><a class=lnlinks href=#hl-0-47>47</a>
</span><span class=lnt id=hl-0-48><a class=lnlinks href=#hl-0-48>48</a>
</span><span class=lnt id=hl-0-49><a class=lnlinks href=#hl-0-49>49</a>
</span><span class=lnt id=hl-0-50><a class=lnlinks href=#hl-0-50>50</a>
</span><span class=lnt id=hl-0-51><a class=lnlinks href=#hl-0-51>51</a>
</span><span class=lnt id=hl-0-52><a class=lnlinks href=#hl-0-52>52</a>
</span><span class=lnt id=hl-0-53><a class=lnlinks href=#hl-0-53>53</a>
</span><span class=lnt id=hl-0-54><a class=lnlinks href=#hl-0-54>54</a>
</span><span class=lnt id=hl-0-55><a class=lnlinks href=#hl-0-55>55</a>
</span><span class=lnt id=hl-0-56><a class=lnlinks href=#hl-0-56>56</a>
</span><span class=lnt id=hl-0-57><a class=lnlinks href=#hl-0-57>57</a>
</span><span class=lnt id=hl-0-58><a class=lnlinks href=#hl-0-58>58</a>
</span><span class=lnt id=hl-0-59><a class=lnlinks href=#hl-0-59>59</a>
</span><span class=lnt id=hl-0-60><a class=lnlinks href=#hl-0-60>60</a>
</span><span class=lnt id=hl-0-61><a class=lnlinks href=#hl-0-61>61</a>
</span><span class=lnt id=hl-0-62><a class=lnlinks href=#hl-0-62>62</a>
</span><span class=lnt id=hl-0-63><a class=lnlinks href=#hl-0-63>63</a>
</span><span class=lnt id=hl-0-64><a class=lnlinks href=#hl-0-64>64</a>
</span><span class=lnt id=hl-0-65><a class=lnlinks href=#hl-0-65>65</a>
</span><span class=lnt id=hl-0-66><a class=lnlinks href=#hl-0-66>66</a>
</span><span class=lnt id=hl-0-67><a class=lnlinks href=#hl-0-67>67</a>
</span><span class=lnt id=hl-0-68><a class=lnlinks href=#hl-0-68>68</a>
</span><span class=lnt id=hl-0-69><a class=lnlinks href=#hl-0-69>69</a>
</span><span class=lnt id=hl-0-70><a class=lnlinks href=#hl-0-70>70</a>
</span><span class=lnt id=hl-0-71><a class=lnlinks href=#hl-0-71>71</a>
</span><span class=lnt id=hl-0-72><a class=lnlinks href=#hl-0-72>72</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.optim</span> <span class=k>as</span> <span class=nn>optim</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torchcrf</span> <span class=kn>import</span> <span class=n>CRF</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 定义BiLSTM-CRF模型</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>BiLSTM_CRF</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>vocab_size</span><span class=p>,</span> <span class=n>embedding_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>,</span> <span class=n>tagset_size</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>(</span><span class=n>BiLSTM_CRF</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>embedding</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Embedding</span><span class=p>(</span><span class=n>vocab_size</span><span class=p>,</span> <span class=n>embedding_dim</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>lstm</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>LSTM</span><span class=p>(</span><span class=n>embedding_dim</span><span class=p>,</span> <span class=n>hidden_dim</span> <span class=o>//</span> <span class=mi>2</span><span class=p>,</span> <span class=n>num_layers</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>bidirectional</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>batch_first</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>hidden2tag</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>hidden_dim</span><span class=p>,</span> <span class=n>tagset_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>crf</span> <span class=o>=</span> <span class=n>CRF</span><span class=p>(</span><span class=n>tagset_size</span><span class=p>,</span> <span class=n>batch_first</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>embeds</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>embedding</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>lstm_out</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>lstm</span><span class=p>(</span><span class=n>embeds</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>emissions</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>hidden2tag</span><span class=p>(</span><span class=n>lstm_out</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>emissions</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>loss</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>emissions</span><span class=p>,</span> <span class=n>tags</span><span class=p>,</span> <span class=n>mask</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=o>-</span><span class=bp>self</span><span class=o>.</span><span class=n>crf</span><span class=p>(</span><span class=n>emissions</span><span class=p>,</span> <span class=n>tags</span><span class=p>,</span> <span class=n>mask</span><span class=o>=</span><span class=n>mask</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>decode</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>emissions</span><span class=p>,</span> <span class=n>mask</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>crf</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=n>emissions</span><span class=p>,</span> <span class=n>mask</span><span class=o>=</span><span class=n>mask</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># MAML训练函数</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>train_maml</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>tasks</span><span class=p>,</span> <span class=n>inner_lr</span><span class=p>,</span> <span class=n>outer_lr</span><span class=p>,</span> <span class=n>inner_steps</span><span class=p>,</span> <span class=n>outer_steps</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>optimizer</span> <span class=o>=</span> <span class=n>optim</span><span class=o>.</span><span class=n>Adam</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=n>outer_lr</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>step</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>outer_steps</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>meta_loss</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>task</span> <span class=ow>in</span> <span class=n>tasks</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=c1># 内层优化</span>
</span></span><span class=line><span class=cl>            <span class=n>task_model</span> <span class=o>=</span> <span class=n>BiLSTM_CRF</span><span class=p>(</span><span class=n>vocab_size</span><span class=p>,</span> <span class=n>embedding_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>,</span> <span class=n>tagset_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>task_model</span><span class=o>.</span><span class=n>load_state_dict</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>state_dict</span><span class=p>())</span>
</span></span><span class=line><span class=cl>            <span class=n>task_optimizer</span> <span class=o>=</span> <span class=n>optim</span><span class=o>.</span><span class=n>SGD</span><span class=p>(</span><span class=n>task_model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=n>inner_lr</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>inner_steps</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                <span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>mask</span> <span class=o>=</span> <span class=n>task</span><span class=o>.</span><span class=n>sample</span><span class=p>()</span>
</span></span><span class=line><span class=cl>                <span class=n>emissions</span> <span class=o>=</span> <span class=n>task_model</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>loss</span> <span class=o>=</span> <span class=n>task_model</span><span class=o>.</span><span class=n>loss</span><span class=p>(</span><span class=n>emissions</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>mask</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>task_optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span></span><span class=line><span class=cl>                <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl>                <span class=n>task_optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=c1># 外层优化</span>
</span></span><span class=line><span class=cl>            <span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>mask</span> <span class=o>=</span> <span class=n>task</span><span class=o>.</span><span class=n>sample</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>emissions</span> <span class=o>=</span> <span class=n>task_model</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>loss</span> <span class=o>=</span> <span class=n>task_model</span><span class=o>.</span><span class=n>loss</span><span class=p>(</span><span class=n>emissions</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>mask</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>meta_loss</span> <span class=o>+=</span> <span class=n>loss</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>meta_loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 示例任务</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>Task</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>data</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>data</span> <span class=o>=</span> <span class=n>data</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>sample</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>mask</span> <span class=o>=</span> <span class=nb>zip</span><span class=p>(</span><span class=o>*</span><span class=bp>self</span><span class=o>.</span><span class=n>data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=n>x</span><span class=p>),</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=n>y</span><span class=p>),</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=n>mask</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 训练MAML模型</span>
</span></span><span class=line><span class=cl><span class=n>vocab_size</span> <span class=o>=</span> <span class=mi>5000</span>  <span class=c1># 词汇表大小</span>
</span></span><span class=line><span class=cl><span class=n>embedding_dim</span> <span class=o>=</span> <span class=mi>100</span>  <span class=c1># 词向量维度</span>
</span></span><span class=line><span class=cl><span class=n>hidden_dim</span> <span class=o>=</span> <span class=mi>256</span>  <span class=c1># 隐藏层维度</span>
</span></span><span class=line><span class=cl><span class=n>tagset_size</span> <span class=o>=</span> <span class=mi>10</span>  <span class=c1># 标签集大小</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>BiLSTM_CRF</span><span class=p>(</span><span class=n>vocab_size</span><span class=p>,</span> <span class=n>embedding_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>,</span> <span class=n>tagset_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>tasks</span> <span class=o>=</span> <span class=p>[</span><span class=n>Task</span><span class=p>(</span><span class=n>data</span><span class=p>)</span> <span class=k>for</span> <span class=n>data</span> <span class=ow>in</span> <span class=n>task_data</span><span class=p>]</span>  <span class=c1># task_data为预处理好的任务数据</span>
</span></span><span class=line><span class=cl><span class=n>train_maml</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>tasks</span><span class=p>,</span> <span class=n>inner_lr</span><span class=o>=</span><span class=mf>0.01</span><span class=p>,</span> <span class=n>outer_lr</span><span class=o>=</span><span class=mf>0.001</span><span class=p>,</span> <span class=n>inner_steps</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>outer_steps</span><span class=o>=</span><span class=mi>1000</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div></div><footer class=post-footer><ul class=post-tags><li><a href=http://localhost:1313/tags/daily-dev/>Daily Dev</a></li><li><a href=http://localhost:1313/tags/project-dev/>Project Dev</a></li></ul><nav class=paginav><a class=prev href=http://localhost:1313/posts/dailydev/%E8%AE%A1%E7%BB%84kg%E8%AF%BE%E9%A2%98%E5%BC%80%E5%8F%91%E8%BF%87%E7%A8%8B%E4%BA%8C/><span class=title>« Prev</span><br><span>《计组KG》课题开发过程（二）</span>
</a><a class=next href=http://localhost:1313/posts/nlp/bpe/><span class=title>Next »</span><br><span>BPE算法</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=http://localhost:1313/>KurongBlog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>