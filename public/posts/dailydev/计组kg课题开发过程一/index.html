<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>《计组KG》课题开发过程（一） | KurongBlog</title>
<meta name=keywords content="Daily Dev,Project Dev"><meta name=description content='前言
开发该课题也有一个月了，整个过程并不是很顺利，很多细节部分如果没有得到及时梳理，对以后的研究和论文写作也有坏处。基于以上和其他原因，遂决定分阶段进行记录。
数据集
深度学习项目的良好开端就是有一个优良标注的数据集。而由于本课题起源于一个极小领域下，导致数据集必须完全自建。所有工作由我一人进行，工作量不可避免的大。所以必须尽可能的减少工作量，尽量实现在课题的中后期的所有标注工作都由程序自动化解决。
计组数据集的构建分为了以下几个过程：

计组数据集来源
数据预处理
数据集的预标注
基于词典的多次迭代标注
数据集格式的转换

接下来对每一个部分进行详述。
计组数据集来源
目前数据的来源如下：

计算机组成原理第6版 (白中英)，pdf 转 txt
计算机组成原理第6版 (白中英) 课件，ppt 转 txt

数据预处理
以下是大概的预处理过程：

将所有的文本合并到一个文件，方便后续操作；
手工去掉一些与课题无关的文本和小部分错误内容；
去掉所有的空白字符（空格、换行符、制表符等）；
去掉所有的特殊字符（数字、半角符号、特殊字符）；
以中文句号进行分割，分别以整句、分词的形式输出到 json 文件中。

处理结果：




1
2
3
4


// 整句
{
  "0": "\u8ba1\u7b97\u673a\u7cfb\u7edf\u4e0d\u540c\u4e8e\u4e00\u822c\u7684\u7535\u5b50\u8bbe\u5907\uff0c\u5b83\u662f\u4e00\u4e2a\u7531\u786c\u4ef6\u3001\u8f6f\u4ef6\u7ec4\u6210\u7684\u590d\u6742\u7684\u81ea\u52a8\u5316\u8bbe\u5907"
}






1
2
3
4


// 分词
{
  "0": ["\u8ba1", "\u7b97", "\u673a", "\u7cfb", "\u7edf", "\u4e0d", "\u540c", "\u4e8e", "\u4e00", "\u822c", "\u7684", "\u7535", "\u5b50", "\u8bbe", "\u5907", "\uff0c", "\u5b83", "\u662f", "\u4e00", "\u4e2a", "\u7531", "\u786c", "\u4ef6", "\u3001", "\u8f6f", "\u4ef6", "\u7ec4", "\u6210", "\u7684", "\u590d", "\u6742", "\u7684", "\u81ea", "\u52a8", "\u5316", "\u8bbe", "\u5907"]
}




数据集的预标注
以上所有数据处理完后，共得到5632条文本。如果要自己一条条的标注，真就是整一个月啥也别干，所以还是要用比较省力的方式进行标注。我选择用一个在中文语料集上训练过的预训练模型进行第一轮标注，也就是预标注。
我选择了 RaNER命名实体识别-中文-通用领域-large 作为预标注阶段的预训练模型。该模型的标签如下：

  
      
          实体类型
          英文名
      
  
  
      
          公司名
          CORP
      
      
          创作名
          CW
      
      
          其他组织名
          GRP
      
      
          地名
          LOC
      
      
          人名
          PER
      
      
          消费品
          PROD
      
  

为什么要选择这个模型呢？我当时认为有以下几点可以考虑：'><meta name=author content="Kurong"><link rel=canonical href=http://localhost:1313/posts/dailydev/%E8%AE%A1%E7%BB%84kg%E8%AF%BE%E9%A2%98%E5%BC%80%E5%8F%91%E8%BF%87%E7%A8%8B%E4%B8%80/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/posts/dailydev/%E8%AE%A1%E7%BB%84kg%E8%AF%BE%E9%A2%98%E5%BC%80%E5%8F%91%E8%BF%87%E7%A8%8B%E4%B8%80/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],throwOnError:!1})})</script><meta property="og:title" content="《计组KG》课题开发过程（一）"><meta property="og:description" content='前言
开发该课题也有一个月了，整个过程并不是很顺利，很多细节部分如果没有得到及时梳理，对以后的研究和论文写作也有坏处。基于以上和其他原因，遂决定分阶段进行记录。
数据集
深度学习项目的良好开端就是有一个优良标注的数据集。而由于本课题起源于一个极小领域下，导致数据集必须完全自建。所有工作由我一人进行，工作量不可避免的大。所以必须尽可能的减少工作量，尽量实现在课题的中后期的所有标注工作都由程序自动化解决。
计组数据集的构建分为了以下几个过程：

计组数据集来源
数据预处理
数据集的预标注
基于词典的多次迭代标注
数据集格式的转换

接下来对每一个部分进行详述。
计组数据集来源
目前数据的来源如下：

计算机组成原理第6版 (白中英)，pdf 转 txt
计算机组成原理第6版 (白中英) 课件，ppt 转 txt

数据预处理
以下是大概的预处理过程：

将所有的文本合并到一个文件，方便后续操作；
手工去掉一些与课题无关的文本和小部分错误内容；
去掉所有的空白字符（空格、换行符、制表符等）；
去掉所有的特殊字符（数字、半角符号、特殊字符）；
以中文句号进行分割，分别以整句、分词的形式输出到 json 文件中。

处理结果：




1
2
3
4


// 整句
{
  "0": "\u8ba1\u7b97\u673a\u7cfb\u7edf\u4e0d\u540c\u4e8e\u4e00\u822c\u7684\u7535\u5b50\u8bbe\u5907\uff0c\u5b83\u662f\u4e00\u4e2a\u7531\u786c\u4ef6\u3001\u8f6f\u4ef6\u7ec4\u6210\u7684\u590d\u6742\u7684\u81ea\u52a8\u5316\u8bbe\u5907"
}






1
2
3
4


// 分词
{
  "0": ["\u8ba1", "\u7b97", "\u673a", "\u7cfb", "\u7edf", "\u4e0d", "\u540c", "\u4e8e", "\u4e00", "\u822c", "\u7684", "\u7535", "\u5b50", "\u8bbe", "\u5907", "\uff0c", "\u5b83", "\u662f", "\u4e00", "\u4e2a", "\u7531", "\u786c", "\u4ef6", "\u3001", "\u8f6f", "\u4ef6", "\u7ec4", "\u6210", "\u7684", "\u590d", "\u6742", "\u7684", "\u81ea", "\u52a8", "\u5316", "\u8bbe", "\u5907"]
}




数据集的预标注
以上所有数据处理完后，共得到5632条文本。如果要自己一条条的标注，真就是整一个月啥也别干，所以还是要用比较省力的方式进行标注。我选择用一个在中文语料集上训练过的预训练模型进行第一轮标注，也就是预标注。
我选择了 RaNER命名实体识别-中文-通用领域-large 作为预标注阶段的预训练模型。该模型的标签如下：

  
      
          实体类型
          英文名
      
  
  
      
          公司名
          CORP
      
      
          创作名
          CW
      
      
          其他组织名
          GRP
      
      
          地名
          LOC
      
      
          人名
          PER
      
      
          消费品
          PROD
      
  

为什么要选择这个模型呢？我当时认为有以下几点可以考虑：'><meta property="og:type" content="article"><meta property="og:url" content="http://localhost:1313/posts/dailydev/%E8%AE%A1%E7%BB%84kg%E8%AF%BE%E9%A2%98%E5%BC%80%E5%8F%91%E8%BF%87%E7%A8%8B%E4%B8%80/"><meta property="og:image" content="http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-08-01T00:00:00+00:00"><meta property="article:modified_time" content="2024-08-01T00:00:00+00:00"><meta property="og:site_name" content="KurongBlog"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="《计组KG》课题开发过程（一）"><meta name=twitter:description content='前言
开发该课题也有一个月了，整个过程并不是很顺利，很多细节部分如果没有得到及时梳理，对以后的研究和论文写作也有坏处。基于以上和其他原因，遂决定分阶段进行记录。
数据集
深度学习项目的良好开端就是有一个优良标注的数据集。而由于本课题起源于一个极小领域下，导致数据集必须完全自建。所有工作由我一人进行，工作量不可避免的大。所以必须尽可能的减少工作量，尽量实现在课题的中后期的所有标注工作都由程序自动化解决。
计组数据集的构建分为了以下几个过程：

计组数据集来源
数据预处理
数据集的预标注
基于词典的多次迭代标注
数据集格式的转换

接下来对每一个部分进行详述。
计组数据集来源
目前数据的来源如下：

计算机组成原理第6版 (白中英)，pdf 转 txt
计算机组成原理第6版 (白中英) 课件，ppt 转 txt

数据预处理
以下是大概的预处理过程：

将所有的文本合并到一个文件，方便后续操作；
手工去掉一些与课题无关的文本和小部分错误内容；
去掉所有的空白字符（空格、换行符、制表符等）；
去掉所有的特殊字符（数字、半角符号、特殊字符）；
以中文句号进行分割，分别以整句、分词的形式输出到 json 文件中。

处理结果：




1
2
3
4


// 整句
{
  "0": "\u8ba1\u7b97\u673a\u7cfb\u7edf\u4e0d\u540c\u4e8e\u4e00\u822c\u7684\u7535\u5b50\u8bbe\u5907\uff0c\u5b83\u662f\u4e00\u4e2a\u7531\u786c\u4ef6\u3001\u8f6f\u4ef6\u7ec4\u6210\u7684\u590d\u6742\u7684\u81ea\u52a8\u5316\u8bbe\u5907"
}






1
2
3
4


// 分词
{
  "0": ["\u8ba1", "\u7b97", "\u673a", "\u7cfb", "\u7edf", "\u4e0d", "\u540c", "\u4e8e", "\u4e00", "\u822c", "\u7684", "\u7535", "\u5b50", "\u8bbe", "\u5907", "\uff0c", "\u5b83", "\u662f", "\u4e00", "\u4e2a", "\u7531", "\u786c", "\u4ef6", "\u3001", "\u8f6f", "\u4ef6", "\u7ec4", "\u6210", "\u7684", "\u590d", "\u6742", "\u7684", "\u81ea", "\u52a8", "\u5316", "\u8bbe", "\u5907"]
}




数据集的预标注
以上所有数据处理完后，共得到5632条文本。如果要自己一条条的标注，真就是整一个月啥也别干，所以还是要用比较省力的方式进行标注。我选择用一个在中文语料集上训练过的预训练模型进行第一轮标注，也就是预标注。
我选择了 RaNER命名实体识别-中文-通用领域-large 作为预标注阶段的预训练模型。该模型的标签如下：

  
      
          实体类型
          英文名
      
  
  
      
          公司名
          CORP
      
      
          创作名
          CW
      
      
          其他组织名
          GRP
      
      
          地名
          LOC
      
      
          人名
          PER
      
      
          消费品
          PROD
      
  

为什么要选择这个模型呢？我当时认为有以下几点可以考虑：'><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:1313/posts/"},{"@type":"ListItem","position":2,"name":"《计组KG》课题开发过程（一）","item":"http://localhost:1313/posts/dailydev/%E8%AE%A1%E7%BB%84kg%E8%AF%BE%E9%A2%98%E5%BC%80%E5%8F%91%E8%BF%87%E7%A8%8B%E4%B8%80/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"《计组KG》课题开发过程（一）","name":"《计组KG》课题开发过程（一）","description":"前言 开发该课题也有一个月了，整个过程并不是很顺利，很多细节部分如果没有得到及时梳理，对以后的研究和论文写作也有坏处。基于以上和其他原因，遂决定分阶段进行记录。\n数据集 深度学习项目的良好开端就是有一个优良标注的数据集。而由于本课题起源于一个极小领域下，导致数据集必须完全自建。所有工作由我一人进行，工作量不可避免的大。所以必须尽可能的减少工作量，尽量实现在课题的中后期的所有标注工作都由程序自动化解决。\n计组数据集的构建分为了以下几个过程：\n计组数据集来源 数据预处理 数据集的预标注 基于词典的多次迭代标注 数据集格式的转换 接下来对每一个部分进行详述。\n计组数据集来源 目前数据的来源如下：\n计算机组成原理第6版 (白中英)，pdf 转 txt 计算机组成原理第6版 (白中英) 课件，ppt 转 txt 数据预处理 以下是大概的预处理过程：\n将所有的文本合并到一个文件，方便后续操作； 手工去掉一些与课题无关的文本和小部分错误内容； 去掉所有的空白字符（空格、换行符、制表符等）； 去掉所有的特殊字符（数字、半角符号、特殊字符）； 以中文句号进行分割，分别以整句、分词的形式输出到 json 文件中。 处理结果：\n1 2 3 4 // 整句 { \u0026#34;0\u0026#34;: \u0026#34;\\u8ba1\\u7b97\\u673a\\u7cfb\\u7edf\\u4e0d\\u540c\\u4e8e\\u4e00\\u822c\\u7684\\u7535\\u5b50\\u8bbe\\u5907\\uff0c\\u5b83\\u662f\\u4e00\\u4e2a\\u7531\\u786c\\u4ef6\\u3001\\u8f6f\\u4ef6\\u7ec4\\u6210\\u7684\\u590d\\u6742\\u7684\\u81ea\\u52a8\\u5316\\u8bbe\\u5907\u0026#34; } 1 2 3 4 // 分词 { \u0026#34;0\u0026#34;: [\u0026#34;\\u8ba1\u0026#34;, \u0026#34;\\u7b97\u0026#34;, \u0026#34;\\u673a\u0026#34;, \u0026#34;\\u7cfb\u0026#34;, \u0026#34;\\u7edf\u0026#34;, \u0026#34;\\u4e0d\u0026#34;, \u0026#34;\\u540c\u0026#34;, \u0026#34;\\u4e8e\u0026#34;, \u0026#34;\\u4e00\u0026#34;, \u0026#34;\\u822c\u0026#34;, \u0026#34;\\u7684\u0026#34;, \u0026#34;\\u7535\u0026#34;, \u0026#34;\\u5b50\u0026#34;, \u0026#34;\\u8bbe\u0026#34;, \u0026#34;\\u5907\u0026#34;, \u0026#34;\\uff0c\u0026#34;, \u0026#34;\\u5b83\u0026#34;, \u0026#34;\\u662f\u0026#34;, \u0026#34;\\u4e00\u0026#34;, \u0026#34;\\u4e2a\u0026#34;, \u0026#34;\\u7531\u0026#34;, \u0026#34;\\u786c\u0026#34;, \u0026#34;\\u4ef6\u0026#34;, \u0026#34;\\u3001\u0026#34;, \u0026#34;\\u8f6f\u0026#34;, \u0026#34;\\u4ef6\u0026#34;, \u0026#34;\\u7ec4\u0026#34;, \u0026#34;\\u6210\u0026#34;, \u0026#34;\\u7684\u0026#34;, \u0026#34;\\u590d\u0026#34;, \u0026#34;\\u6742\u0026#34;, \u0026#34;\\u7684\u0026#34;, \u0026#34;\\u81ea\u0026#34;, \u0026#34;\\u52a8\u0026#34;, \u0026#34;\\u5316\u0026#34;, \u0026#34;\\u8bbe\u0026#34;, \u0026#34;\\u5907\u0026#34;] } 数据集的预标注 以上所有数据处理完后，共得到5632条文本。如果要自己一条条的标注，真就是整一个月啥也别干，所以还是要用比较省力的方式进行标注。我选择用一个在中文语料集上训练过的预训练模型进行第一轮标注，也就是预标注。\n我选择了 RaNER命名实体识别-中文-通用领域-large 作为预标注阶段的预训练模型。该模型的标签如下：\n实体类型 英文名 公司名 CORP 创作名 CW 其他组织名 GRP 地名 LOC 人名 PER 消费品 PROD 为什么要选择这个模型呢？我当时认为有以下几点可以考虑：\n","keywords":["Daily Dev","Project Dev"],"articleBody":"前言 开发该课题也有一个月了，整个过程并不是很顺利，很多细节部分如果没有得到及时梳理，对以后的研究和论文写作也有坏处。基于以上和其他原因，遂决定分阶段进行记录。\n数据集 深度学习项目的良好开端就是有一个优良标注的数据集。而由于本课题起源于一个极小领域下，导致数据集必须完全自建。所有工作由我一人进行，工作量不可避免的大。所以必须尽可能的减少工作量，尽量实现在课题的中后期的所有标注工作都由程序自动化解决。\n计组数据集的构建分为了以下几个过程：\n计组数据集来源 数据预处理 数据集的预标注 基于词典的多次迭代标注 数据集格式的转换 接下来对每一个部分进行详述。\n计组数据集来源 目前数据的来源如下：\n计算机组成原理第6版 (白中英)，pdf 转 txt 计算机组成原理第6版 (白中英) 课件，ppt 转 txt 数据预处理 以下是大概的预处理过程：\n将所有的文本合并到一个文件，方便后续操作； 手工去掉一些与课题无关的文本和小部分错误内容； 去掉所有的空白字符（空格、换行符、制表符等）； 去掉所有的特殊字符（数字、半角符号、特殊字符）； 以中文句号进行分割，分别以整句、分词的形式输出到 json 文件中。 处理结果：\n1 2 3 4 // 整句 { \"0\": \"\\u8ba1\\u7b97\\u673a\\u7cfb\\u7edf\\u4e0d\\u540c\\u4e8e\\u4e00\\u822c\\u7684\\u7535\\u5b50\\u8bbe\\u5907\\uff0c\\u5b83\\u662f\\u4e00\\u4e2a\\u7531\\u786c\\u4ef6\\u3001\\u8f6f\\u4ef6\\u7ec4\\u6210\\u7684\\u590d\\u6742\\u7684\\u81ea\\u52a8\\u5316\\u8bbe\\u5907\" } 1 2 3 4 // 分词 { \"0\": [\"\\u8ba1\", \"\\u7b97\", \"\\u673a\", \"\\u7cfb\", \"\\u7edf\", \"\\u4e0d\", \"\\u540c\", \"\\u4e8e\", \"\\u4e00\", \"\\u822c\", \"\\u7684\", \"\\u7535\", \"\\u5b50\", \"\\u8bbe\", \"\\u5907\", \"\\uff0c\", \"\\u5b83\", \"\\u662f\", \"\\u4e00\", \"\\u4e2a\", \"\\u7531\", \"\\u786c\", \"\\u4ef6\", \"\\u3001\", \"\\u8f6f\", \"\\u4ef6\", \"\\u7ec4\", \"\\u6210\", \"\\u7684\", \"\\u590d\", \"\\u6742\", \"\\u7684\", \"\\u81ea\", \"\\u52a8\", \"\\u5316\", \"\\u8bbe\", \"\\u5907\"] } 数据集的预标注 以上所有数据处理完后，共得到5632条文本。如果要自己一条条的标注，真就是整一个月啥也别干，所以还是要用比较省力的方式进行标注。我选择用一个在中文语料集上训练过的预训练模型进行第一轮标注，也就是预标注。\n我选择了 RaNER命名实体识别-中文-通用领域-large 作为预标注阶段的预训练模型。该模型的标签如下：\n实体类型 英文名 公司名 CORP 创作名 CW 其他组织名 GRP 地名 LOC 人名 PER 消费品 PROD 为什么要选择这个模型呢？我当时认为有以下几点可以考虑：\n标签覆盖范围广：其他的预训练模型只对 PER、LOC、ORG 这三种基本实体有所覆盖，如 CPU、内存这类实体反而识别不出来。相比以上，该模型能成功将计组教材中的大部分实体识别出来，并赋予 PROD、CW、GRP、CORP、PER等标签； 中文平台 ModelScope：因为 ModelScope 在国内，所以各种工具使用起来相对方便。 整个预标注过程如下：\n读取以整句进行分割的语料集； 构建 Pytorch 的 Dataset 、DataLoader ，方便后续分批加载数据； 创建 ModelScope 的 Pipeline ； 将数据顺序输入到 Pipeline 中，由模型进行推理； 将结果输出到 txt 文件中。 1 2 文本：计算机系统不同于一般的电子设备，它是一个由硬件、软件组成的复杂的自动化设备。 预标注结果：{'output': [{'type': 'PROD', 'start': 0, 'end': 5, 'prob': 0.12411527, 'span': '计算机系统'}]} 可以从上面的结果中看到，计算机系统这个实体被识别了出来，并被标注为 PROD 消费品。但是硬件、软件这两个概念实体没有识别出来，说明预标注的结果只能在一定程度上减少工作量，其余的大部分工作仍需要更高精度的校对。\n（标注的结果分析：在所有数据集都处理完成之后才能进行这一步）\n基于词典的多次迭代标注 预标注的准确率极为有限，出现了大量识别错漏的情况。这伴随而来的是超大工作量，想要在短时间内修复绝大部分错误几乎是不可能的。那有没有什么方法可以半自动，甚至在之后可以全自动的解决这些问题呢？我想到的是基于词典的多次迭代标注方法。\n为了能快速准确的校对大量数据，引入了词典。所谓词典就是 Python 的字典数据结构，由大量键值对组成。为了方便进行迭代标注，我做了以下三个工作：\n分割数据集：数据集以训练集 : 验证集 : 测试集 = 8 : 1 : 1 的比例进行划分，而训练集又分成了 5 份；\n细分标签：\n将计组实体分为了以下十一类： Label Meaning Use COMP 组件 用于标注计算机系统的具体组件，如“寄存器”、“总线”、“控制单元”等 DATA 数据 用于标注数据类型和格式，如“二进制数据”、“十六进制数据”等 ARCH 架构 用于标注计算机体系结构相关的实体，如冯·诺依曼架构、RISC等 PROG 程序与软件 用于标注具体的程序或软件，如“操作系统”、“编译器”等 PROT 网络协议 用于标注网络协议或通信协议，如“TCP/IP”、“HTTP”等 PERF 性能指标 用于标注与计算机性能相关的实体，如处理速度、吞吐量、延迟、响应时间等 STOR 存储器 用于标注各种存储类型和技术，如“RAM”、“ROM”、“闪存”等 ALG 算法 用于标注算法相关的实体，如排序算法、加密算法 IO IO设备 用于标注与输入输出设备相关的实体，如键盘、鼠标、显示器、打印机等 TECH 技术 用于标注计算机科学技术和概念，如“虚拟内存”、“流水线”、“缓存”等 INST 指令 用于标注具体的指令或指令集，如“ADD指令”、“MIPS指令集”等 最长匹配原则：\n以“页式虚拟存储系统中，虚地址空间被分成等长的页，称为逻辑页”为例； 地址空间、虚地址空间都被标记为 DATA 实体。在这里标记地址空间为 DATA 不完整的，而遵循最长匹配原则，虚地址空间被标记为 DATA 。 以上部分完成后，才正式开始迭代标注，以下是一个大致过程：\n以第一份数据集的校对结果构建初始词典； 在其他份数据集校对前先用词典进行一次快速校对； 每次人工校对完一份数据集，就以其标注结果更新词典； 重复 1~3 ，直到基于完整数据集的词典更新完毕，得到最终版本词典。 值得一提的是，第一份训练集、验证集、测试集都参与了初始词典的构建，主要采用人工校对。标注平台选用开源库 Open Source Data Labeling | Label Studio 在本地进行标注。\n最终版本的词典精确率和召回率都很高，明显高于没有微调的预训练模型。之后还有什么文本，直接用以上方法进行一次快速标注。\n数据集格式的转换 模型训练的数据格式有两种：\njson-tag\n1 {\"words\": [\"痛\", \"1\", \"天\", \"。\"], \"ner\": [\"B-SIGNS\", \"O\", \"O\", \"O\"]} conll\n1 2 3 4 5 6 7 8 9 10 当\tO 一\tO c\tB-STOR a\tI-STOR c\tI-STOR h\tI-STOR e\tI-STOR 行\tE-STOR 已\tO 授\tO 把标注过的数据转换为以上格式，就得到用于训练的标准数据集了。\n","wordCount":"283","inLanguage":"en","image":"http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E","datePublished":"2024-08-01T00:00:00Z","dateModified":"2024-08-01T00:00:00Z","author":{"@type":"Person","name":"Kurong"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/posts/dailydev/%E8%AE%A1%E7%BB%84kg%E8%AF%BE%E9%A2%98%E5%BC%80%E5%8F%91%E8%BF%87%E7%A8%8B%E4%B8%80/"},"publisher":{"@type":"Organization","name":"KurongBlog","logo":{"@type":"ImageObject","url":"http://localhost:1313/%3Clink%20/%20abs%20url%3E"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Home (Alt + H)"><img src=http://localhost:1313/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/categories/ title=categories><span>categories</span></a></li><li><a href=http://localhost:1313/tags/ title=tags><span>tags</span></a></li><li><a href=http://localhost:1313/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a>&nbsp;»&nbsp;<a href=http://localhost:1313/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">《计组KG》课题开发过程（一）</h1><div class=post-meta><span title='2024-08-01 00:00:00 +0000 UTC'>August 1, 2024</span>&nbsp;·&nbsp;Kurong&nbsp;|&nbsp;<a href=https://github.com/KurongTohsaka/KurongTohsaka.github.io/content/posts/DailyDev/%e3%80%8a%e8%ae%a1%e7%bb%84KG%e3%80%8b%e8%af%be%e9%a2%98%e5%bc%80%e5%8f%91%e8%bf%87%e7%a8%8b%ef%bc%88%e4%b8%80%ef%bc%89.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#前言>前言</a></li><li><a href=#数据集>数据集</a><ul><li><a href=#计组数据集来源>计组数据集来源</a></li><li><a href=#数据预处理>数据预处理</a></li><li><a href=#数据集的预标注>数据集的预标注</a></li><li><a href=#基于词典的多次迭代标注>基于词典的多次迭代标注</a></li><li><a href=#数据集格式的转换>数据集格式的转换</a></li></ul></li></ul></nav></div></details></div><div class=post-content><h2 id=前言>前言<a hidden class=anchor aria-hidden=true href=#前言>#</a></h2><p>开发该课题也有一个月了，整个过程并不是很顺利，很多细节部分如果没有得到及时梳理，对以后的研究和论文写作也有坏处。基于以上和其他原因，遂决定分阶段进行记录。</p><h2 id=数据集>数据集<a hidden class=anchor aria-hidden=true href=#数据集>#</a></h2><p>深度学习项目的良好开端就是有一个优良标注的数据集。而由于本课题起源于一个极小领域下，导致数据集必须完全自建。所有工作由我一人进行，工作量不可避免的大。所以必须尽可能的减少工作量，尽量实现在课题的中后期的所有标注工作都由程序自动化解决。</p><p>计组数据集的构建分为了以下几个过程：</p><ul><li>计组数据集来源</li><li>数据预处理</li><li>数据集的预标注</li><li>基于词典的多次迭代标注</li><li>数据集格式的转换</li></ul><p>接下来对每一个部分进行详述。</p><h3 id=计组数据集来源>计组数据集来源<a hidden class=anchor aria-hidden=true href=#计组数据集来源>#</a></h3><p>目前数据的来源如下：</p><ul><li>计算机组成原理第6版 (白中英)，pdf 转 txt</li><li>计算机组成原理第6版 (白中英) 课件，ppt 转 txt</li></ul><h3 id=数据预处理>数据预处理<a hidden class=anchor aria-hidden=true href=#数据预处理>#</a></h3><p>以下是大概的预处理过程：</p><ol><li>将所有的文本合并到一个文件，方便后续操作；</li><li>手工去掉一些与课题无关的文本和小部分错误内容；</li><li>去掉所有的空白字符（空格、换行符、制表符等）；</li><li>去掉所有的特殊字符（数字、半角符号、特殊字符）；</li><li>以中文句号进行分割，分别以整句、分词的形式输出到 json 文件中。</li></ol><p>处理结果：</p><ul><li><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-0-1><a class=lnlinks href=#hl-0-1>1</a>
</span><span class=lnt id=hl-0-2><a class=lnlinks href=#hl-0-2>2</a>
</span><span class=lnt id=hl-0-3><a class=lnlinks href=#hl-0-3>3</a>
</span><span class=lnt id=hl-0-4><a class=lnlinks href=#hl-0-4>4</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=c1>// 整句
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;0&#34;</span><span class=p>:</span> <span class=s2>&#34;\u8ba1\u7b97\u673a\u7cfb\u7edf\u4e0d\u540c\u4e8e\u4e00\u822c\u7684\u7535\u5b50\u8bbe\u5907\uff0c\u5b83\u662f\u4e00\u4e2a\u7531\u786c\u4ef6\u3001\u8f6f\u4ef6\u7ec4\u6210\u7684\u590d\u6742\u7684\u81ea\u52a8\u5316\u8bbe\u5907&#34;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div></li><li><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-1-1><a class=lnlinks href=#hl-1-1>1</a>
</span><span class=lnt id=hl-1-2><a class=lnlinks href=#hl-1-2>2</a>
</span><span class=lnt id=hl-1-3><a class=lnlinks href=#hl-1-3>3</a>
</span><span class=lnt id=hl-1-4><a class=lnlinks href=#hl-1-4>4</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=c1>// 分词
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;0&#34;</span><span class=p>:</span> <span class=p>[</span><span class=s2>&#34;\u8ba1&#34;</span><span class=p>,</span> <span class=s2>&#34;\u7b97&#34;</span><span class=p>,</span> <span class=s2>&#34;\u673a&#34;</span><span class=p>,</span> <span class=s2>&#34;\u7cfb&#34;</span><span class=p>,</span> <span class=s2>&#34;\u7edf&#34;</span><span class=p>,</span> <span class=s2>&#34;\u4e0d&#34;</span><span class=p>,</span> <span class=s2>&#34;\u540c&#34;</span><span class=p>,</span> <span class=s2>&#34;\u4e8e&#34;</span><span class=p>,</span> <span class=s2>&#34;\u4e00&#34;</span><span class=p>,</span> <span class=s2>&#34;\u822c&#34;</span><span class=p>,</span> <span class=s2>&#34;\u7684&#34;</span><span class=p>,</span> <span class=s2>&#34;\u7535&#34;</span><span class=p>,</span> <span class=s2>&#34;\u5b50&#34;</span><span class=p>,</span> <span class=s2>&#34;\u8bbe&#34;</span><span class=p>,</span> <span class=s2>&#34;\u5907&#34;</span><span class=p>,</span> <span class=s2>&#34;\uff0c&#34;</span><span class=p>,</span> <span class=s2>&#34;\u5b83&#34;</span><span class=p>,</span> <span class=s2>&#34;\u662f&#34;</span><span class=p>,</span> <span class=s2>&#34;\u4e00&#34;</span><span class=p>,</span> <span class=s2>&#34;\u4e2a&#34;</span><span class=p>,</span> <span class=s2>&#34;\u7531&#34;</span><span class=p>,</span> <span class=s2>&#34;\u786c&#34;</span><span class=p>,</span> <span class=s2>&#34;\u4ef6&#34;</span><span class=p>,</span> <span class=s2>&#34;\u3001&#34;</span><span class=p>,</span> <span class=s2>&#34;\u8f6f&#34;</span><span class=p>,</span> <span class=s2>&#34;\u4ef6&#34;</span><span class=p>,</span> <span class=s2>&#34;\u7ec4&#34;</span><span class=p>,</span> <span class=s2>&#34;\u6210&#34;</span><span class=p>,</span> <span class=s2>&#34;\u7684&#34;</span><span class=p>,</span> <span class=s2>&#34;\u590d&#34;</span><span class=p>,</span> <span class=s2>&#34;\u6742&#34;</span><span class=p>,</span> <span class=s2>&#34;\u7684&#34;</span><span class=p>,</span> <span class=s2>&#34;\u81ea&#34;</span><span class=p>,</span> <span class=s2>&#34;\u52a8&#34;</span><span class=p>,</span> <span class=s2>&#34;\u5316&#34;</span><span class=p>,</span> <span class=s2>&#34;\u8bbe&#34;</span><span class=p>,</span> <span class=s2>&#34;\u5907&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div></li></ul><h3 id=数据集的预标注>数据集的预标注<a hidden class=anchor aria-hidden=true href=#数据集的预标注>#</a></h3><p>以上所有数据处理完后，共得到5632条文本。如果要自己一条条的标注，真就是整一个月啥也别干，所以还是要用比较省力的方式进行标注。我选择用一个在中文语料集上训练过的预训练模型进行第一轮标注，也就是预标注。</p><p>我选择了 <a href=https://modelscope.cn/models/iic/nlp_raner_named-entity-recognition_chinese-large-generic>RaNER命名实体识别-中文-通用领域-large</a> 作为预标注阶段的预训练模型。该模型的标签如下：</p><table><thead><tr><th style=text-align:left>实体类型</th><th style=text-align:left>英文名</th></tr></thead><tbody><tr><td style=text-align:left>公司名</td><td style=text-align:left>CORP</td></tr><tr><td style=text-align:left>创作名</td><td style=text-align:left>CW</td></tr><tr><td style=text-align:left>其他组织名</td><td style=text-align:left>GRP</td></tr><tr><td style=text-align:left>地名</td><td style=text-align:left>LOC</td></tr><tr><td style=text-align:left>人名</td><td style=text-align:left>PER</td></tr><tr><td style=text-align:left>消费品</td><td style=text-align:left>PROD</td></tr></tbody></table><p>为什么要选择这个模型呢？我当时认为有以下几点可以考虑：</p><ul><li>标签覆盖范围广：其他的预训练模型只对 PER、LOC、ORG 这三种基本实体有所覆盖，如 CPU、内存这类实体反而识别不出来。相比以上，该模型能成功将计组教材中的大部分实体识别出来，并赋予 PROD、CW、GRP、CORP、PER等标签；</li><li>中文平台 ModelScope：因为 ModelScope 在国内，所以各种工具使用起来相对方便。</li></ul><p>整个预标注过程如下：</p><ol><li>读取以整句进行分割的语料集；</li><li>构建 Pytorch 的 Dataset 、DataLoader ，方便后续分批加载数据；</li><li>创建 ModelScope 的 Pipeline ；</li><li>将数据顺序输入到 Pipeline 中，由模型进行推理；</li><li>将结果输出到 txt 文件中。</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-2-1><a class=lnlinks href=#hl-2-1>1</a>
</span><span class=lnt id=hl-2-2><a class=lnlinks href=#hl-2-2>2</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>文本：计算机系统不同于一般的电子设备，它是一个由硬件、软件组成的复杂的自动化设备。
</span></span><span class=line><span class=cl>预标注结果：{&#39;output&#39;: [{&#39;type&#39;: &#39;PROD&#39;, &#39;start&#39;: 0, &#39;end&#39;: 5, &#39;prob&#39;: 0.12411527, &#39;span&#39;: &#39;计算机系统&#39;}]}
</span></span></code></pre></td></tr></table></div></div><p>可以从上面的结果中看到，计算机系统这个实体被识别了出来，并被标注为 PROD 消费品。但是硬件、软件这两个概念实体没有识别出来，说明预标注的结果只能在一定程度上减少工作量，其余的大部分工作仍需要更高精度的校对。</p><p>（标注的结果分析：在所有数据集都处理完成之后才能进行这一步）</p><h3 id=基于词典的多次迭代标注>基于词典的多次迭代标注<a hidden class=anchor aria-hidden=true href=#基于词典的多次迭代标注>#</a></h3><p>预标注的准确率极为有限，出现了大量识别错漏的情况。这伴随而来的是超大工作量，想要在短时间内修复绝大部分错误几乎是不可能的。那有没有什么方法可以半自动，甚至在之后可以全自动的解决这些问题呢？我想到的是基于词典的多次迭代标注方法。</p><p>为了能快速准确的校对大量数据，引入了词典。所谓词典就是 Python 的字典数据结构，由大量键值对组成。为了方便进行迭代标注，我做了以下三个工作：</p><ul><li><p>分割数据集：数据集以训练集 : 验证集 : 测试集 = 8 : 1 : 1 的比例进行划分，而训练集又分成了 5 份；</p></li><li><p>细分标签：</p><ul><li>将计组实体分为了以下十一类：<table><thead><tr><th style=text-align:left>Label</th><th style=text-align:left>Meaning</th><th style=text-align:left>Use</th></tr></thead><tbody><tr><td style=text-align:left>COMP</td><td style=text-align:left>组件</td><td style=text-align:left>用于标注计算机系统的具体组件，如“寄存器”、“总线”、“控制单元”等</td></tr><tr><td style=text-align:left>DATA</td><td style=text-align:left>数据</td><td style=text-align:left>用于标注数据类型和格式，如“二进制数据”、“十六进制数据”等</td></tr><tr><td style=text-align:left>ARCH</td><td style=text-align:left>架构</td><td style=text-align:left>用于标注计算机体系结构相关的实体，如冯·诺依曼架构、RISC等</td></tr><tr><td style=text-align:left>PROG</td><td style=text-align:left>程序与软件</td><td style=text-align:left>用于标注具体的程序或软件，如“操作系统”、“编译器”等</td></tr><tr><td style=text-align:left>PROT</td><td style=text-align:left>网络协议</td><td style=text-align:left>用于标注网络协议或通信协议，如“TCP/IP”、“HTTP”等</td></tr><tr><td style=text-align:left>PERF</td><td style=text-align:left>性能指标</td><td style=text-align:left>用于标注与计算机性能相关的实体，如处理速度、吞吐量、延迟、响应时间等</td></tr><tr><td style=text-align:left>STOR</td><td style=text-align:left>存储器</td><td style=text-align:left>用于标注各种存储类型和技术，如“RAM”、“ROM”、“闪存”等</td></tr><tr><td style=text-align:left>ALG</td><td style=text-align:left>算法</td><td style=text-align:left>用于标注算法相关的实体，如排序算法、加密算法</td></tr><tr><td style=text-align:left>IO</td><td style=text-align:left>IO设备</td><td style=text-align:left>用于标注与输入输出设备相关的实体，如键盘、鼠标、显示器、打印机等</td></tr><tr><td style=text-align:left>TECH</td><td style=text-align:left>技术</td><td style=text-align:left>用于标注计算机科学技术和概念，如“虚拟内存”、“流水线”、“缓存”等</td></tr><tr><td style=text-align:left>INST</td><td style=text-align:left>指令</td><td style=text-align:left>用于标注具体的指令或指令集，如“ADD指令”、“MIPS指令集”等</td></tr></tbody></table></li></ul></li><li><p>最长匹配原则：</p><ul><li>以“页式虚拟存储系统中，虚地址空间被分成等长的页，称为逻辑页”为例；</li><li>地址空间、虚地址空间都被标记为 DATA 实体。在这里标记地址空间为 DATA 不完整的，而遵循最长匹配原则，虚地址空间被标记为 DATA 。</li></ul></li></ul><p>以上部分完成后，才正式开始迭代标注，以下是一个大致过程：</p><ol><li>以第一份数据集的校对结果构建初始词典；</li><li>在其他份数据集校对前先用词典进行一次快速校对；</li><li>每次人工校对完一份数据集，就以其标注结果更新词典；</li><li>重复 1~3 ，直到基于完整数据集的词典更新完毕，得到最终版本词典。</li></ol><p>值得一提的是，第一份训练集、验证集、测试集都参与了初始词典的构建，主要采用人工校对。标注平台选用开源库 <a href=https://labelstud.io/>Open Source Data Labeling | Label Studio</a> 在本地进行标注。</p><p>最终版本的词典精确率和召回率都很高，明显高于没有微调的预训练模型。之后还有什么文本，直接用以上方法进行一次快速标注。</p><h3 id=数据集格式的转换>数据集格式的转换<a hidden class=anchor aria-hidden=true href=#数据集格式的转换>#</a></h3><p>模型训练的数据格式有两种：</p><ul><li><p>json-tag</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-3-1><a class=lnlinks href=#hl-3-1>1</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>{&#34;words&#34;: [&#34;痛&#34;, &#34;1&#34;, &#34;天&#34;, &#34;。&#34;], &#34;ner&#34;: [&#34;B-SIGNS&#34;, &#34;O&#34;, &#34;O&#34;, &#34;O&#34;]}
</span></span></code></pre></td></tr></table></div></div></li><li><p>conll</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-4-1><a class=lnlinks href=#hl-4-1> 1</a>
</span><span class=lnt id=hl-4-2><a class=lnlinks href=#hl-4-2> 2</a>
</span><span class=lnt id=hl-4-3><a class=lnlinks href=#hl-4-3> 3</a>
</span><span class=lnt id=hl-4-4><a class=lnlinks href=#hl-4-4> 4</a>
</span><span class=lnt id=hl-4-5><a class=lnlinks href=#hl-4-5> 5</a>
</span><span class=lnt id=hl-4-6><a class=lnlinks href=#hl-4-6> 6</a>
</span><span class=lnt id=hl-4-7><a class=lnlinks href=#hl-4-7> 7</a>
</span><span class=lnt id=hl-4-8><a class=lnlinks href=#hl-4-8> 8</a>
</span><span class=lnt id=hl-4-9><a class=lnlinks href=#hl-4-9> 9</a>
</span><span class=lnt id=hl-4-10><a class=lnlinks href=#hl-4-10>10</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>当	O
</span></span><span class=line><span class=cl>一	O
</span></span><span class=line><span class=cl>c	B-STOR
</span></span><span class=line><span class=cl>a	I-STOR
</span></span><span class=line><span class=cl>c	I-STOR
</span></span><span class=line><span class=cl>h	I-STOR
</span></span><span class=line><span class=cl>e	I-STOR
</span></span><span class=line><span class=cl>行	E-STOR
</span></span><span class=line><span class=cl>已	O
</span></span><span class=line><span class=cl>授	O
</span></span></code></pre></td></tr></table></div></div></li></ul><p>把标注过的数据转换为以上格式，就得到用于训练的标准数据集了。</p></div><footer class=post-footer><ul class=post-tags><li><a href=http://localhost:1313/tags/daily-dev/>Daily Dev</a></li><li><a href=http://localhost:1313/tags/project-dev/>Project Dev</a></li></ul><nav class=paginav><a class=prev href=http://localhost:1313/posts/weeklyworking/2024_07_29-2024_08_04/><span class=title>« Prev</span><br><span>7.29-8.04：一周总结</span>
</a><a class=next href=http://localhost:1313/posts/papernotes/%E5%9F%BA%E4%BA%8E%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8C%BB%E8%8D%AF%E8%AF%B4%E6%98%8E%E4%B9%A6%E5%AE%9E%E4%BD%93%E6%8A%BD%E5%8F%96%E6%96%B9%E6%B3%95%E7%A0%94%E7%A9%B6_%E9%99%88%E4%BB%B2%E6%B0%B8/><span class=title>Next »</span><br><span>《基于预训练模型的医药说明书实体抽取方法研究》笔记</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=http://localhost:1313/>KurongBlog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>