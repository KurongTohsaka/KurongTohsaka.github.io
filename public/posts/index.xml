<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on KurongBlog</title>
    <link>http://localhost:1313/posts/</link>
    <description>Recent content in Posts on KurongBlog</description>
    <image>
      <title>KurongBlog</title>
      <url>http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- 0.135.0</generator>
    <language>en</language>
    <lastBuildDate>Sun, 02 Mar 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>《深入理解设计模式》记录</title>
      <link>http://localhost:1313/posts/dailydev/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Sun, 02 Mar 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/dailydev/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E8%AE%B0%E5%BD%95/</guid>
      <description>&lt;h1 id=&#34;深入理解设计模式记录&#34;&gt;《深入理解设计模式》记录&lt;/h1&gt;
&lt;h2 id=&#34;单例模式&#34;&gt;单例模式&lt;/h2&gt;
&lt;p&gt;单例模式（Singleton Pattern）是一种创建型设计模式，其核心目标是确保一个类仅有一个实例，并提供全局访问点。它适用于需要全局唯一对象且频繁访问的场景，例如配置管理、线程池、日志记录器等。&lt;/p&gt;
&lt;p&gt;单例模式需要注意三点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;私有化构造函数：防止外部通过 &lt;code&gt;new&lt;/code&gt; 直接创建实例。&lt;/li&gt;
&lt;li&gt;自行创建实例：类内部负责生成唯一实例。&lt;/li&gt;
&lt;li&gt;全局访问方法：提供静态方法供外部获取实例。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;懒汉模式&#34;&gt;懒汉模式&lt;/h3&gt;
&lt;p&gt;特点：延迟实例化，首次调用时创建实例，需处理线程安全问题。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-1&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-1&#34;&gt; 1&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-2&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-2&#34;&gt; 2&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-3&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-3&#34;&gt; 3&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-4&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-4&#34;&gt; 4&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-5&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-5&#34;&gt; 5&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-6&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-6&#34;&gt; 6&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-7&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-7&#34;&gt; 7&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-8&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-8&#34;&gt; 8&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-9&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-9&#34;&gt; 9&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-10&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-10&#34;&gt;10&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-11&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-11&#34;&gt;11&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-12&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-12&#34;&gt;12&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-13&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-13&#34;&gt;13&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-14&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-14&#34;&gt;14&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-15&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-15&#34;&gt;15&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-16&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-16&#34;&gt;16&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-17&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-17&#34;&gt;17&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-18&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-18&#34;&gt;18&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-19&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-19&#34;&gt;19&lt;/a&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;package&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;singleton&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;sync&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kd&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;lazySingleton&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kd&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;nx&#34;&gt;instance&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;lazySingleton&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nx&#34;&gt;once&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;sync&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Once&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;GetLazyInstance&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;lazySingleton&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nx&#34;&gt;once&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Do&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nx&#34;&gt;instance&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;lazySingleton&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;})&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;instance&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;饿汉模式&#34;&gt;饿汉模式&lt;/h3&gt;
&lt;p&gt;特点：在包加载时直接初始化实例，无需考虑线程安全。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-1-1&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-1-1&#34;&gt; 1&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-1-2&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-1-2&#34;&gt; 2&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-1-3&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-1-3&#34;&gt; 3&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-1-4&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-1-4&#34;&gt; 4&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-1-5&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-1-5&#34;&gt; 5&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-1-6&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-1-6&#34;&gt; 6&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-1-7&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-1-7&#34;&gt; 7&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-1-8&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-1-8&#34;&gt; 8&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-1-9&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-1-9&#34;&gt; 9&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-1-10&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-1-10&#34;&gt;10&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-1-11&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-1-11&#34;&gt;11&lt;/a&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;package&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;singleton&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kd&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;eagerSingleton&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kd&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;instance&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;eagerSingleton&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;GetEagerInstance&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;eagerSingleton&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;instance&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;懒汉模式的另一实现形式静态内部类&#34;&gt;懒汉模式的另一实现形式：静态内部类&lt;/h3&gt;
&lt;p&gt;特点：通过嵌套结构体延迟加载，结合 &lt;code&gt;sync.Once&lt;/code&gt; 实现线程安全。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Leetcode-75 总结</title>
      <link>http://localhost:1313/posts/algorithmlearning/leetcode_75_%E6%80%BB%E7%BB%93/</link>
      <pubDate>Sun, 02 Mar 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/algorithmlearning/leetcode_75_%E6%80%BB%E7%BB%93/</guid>
      <description>&lt;h1 id=&#34;leetcode-75-总结&#34;&gt;Leetcode-75 总结&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;代码链接：&lt;a href=&#34;https://github.com/KurongTohsaka/my-lc75-go&#34;&gt;KurongTohsaka/my-lc75-go&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;arraystring&#34;&gt;Array&amp;amp;String&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;151 反转字符串中的单词：双指针。&lt;/li&gt;
&lt;li&gt;238 除自身以外数组的乘积：线性 DP 。&lt;/li&gt;
&lt;li&gt;334 递增的三元子序列：双指针。&lt;/li&gt;
&lt;li&gt;345 反转字符串中的元音字母：双指针。&lt;/li&gt;
&lt;li&gt;443 压缩字符串：双指针。&lt;/li&gt;
&lt;li&gt;605 种花问题：列出三种种花情况，依次进行处理即可。&lt;/li&gt;
&lt;li&gt;1071 字符串的最大公因式：根据特殊的 &lt;code&gt;str1 + str2 == str2 + str1&lt;/code&gt; 公式和辗转相除法解题。&lt;/li&gt;
&lt;li&gt;1431 拥有最多糖果的孩子：先找最大值，然后进行比较。&lt;/li&gt;
&lt;li&gt;1768 交替合并字符串：取较小长度最为切割位置，然后交替合并，最后处理剩余部分。&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    <item>
      <title>《数据密集型系统设计》记录</title>
      <link>http://localhost:1313/posts/dailydev/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Fri, 07 Feb 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/dailydev/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E8%AE%B0%E5%BD%95/</guid>
      <description>&lt;h1 id=&#34;数据密集型系统设计记录&#34;&gt;《数据密集型系统设计》记录&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;本书的电子版本链接：&lt;a href=&#34;https://github.com/Vonng/ddia&#34;&gt;Vonng/ddia: 《Designing Data-Intensive Application》DDIA中文翻译&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;3-存储与检索&#34;&gt;3. 存储与检索&lt;/h2&gt;
&lt;p&gt;本章围绕两大类存储引擎：日志结构（log-structured）的存储引擎，以及面向页面（page-oriented）的存储引擎（例如 B 树）。&lt;/p&gt;
&lt;h3 id=&#34;数据库核心数据结构&#34;&gt;数据库核心：数据结构&lt;/h3&gt;
&lt;p&gt;这里所使用的“日志”是一个更一般性的概念：一个支持 &lt;code&gt;append-only&lt;/code&gt; 仅追加操作的记录序列。&lt;/p&gt;
&lt;p&gt;为了高效查找数据库中特定键的值，需要用到索引。索引是从主要数据中衍生的额外结构，维护它会产生额外开销，特别是写入时。任何类型的索引通常都会减慢写入速度，因为每次写入数据时都需要更新索引。这是存储系统中一个重要的权衡：精心选择的索引加快了读查询的速度，但是每个索引都会拖慢写入速度。因为这个原因，数据库默认并不会索引所有的内容，而需要程序员或数据库管理员（DBA），基于对应用的典型查询模式的了解来手动选择索引。&lt;/p&gt;
&lt;h4 id=&#34;sstable&#34;&gt;SSTable&lt;/h4&gt;
&lt;p&gt;把键值对的序列按照键进行排序，这个格式称为排序字符串表（Sorted String Table, SSTable）。此时再要求每个键值在每个合并的段文件中出现一次。与使用散列索引的日志段相比，SSTable 有几个大的优势：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;即使文件大于可用内存，合并段的操作仍然是简单高效：
&lt;ul&gt;
&lt;li&gt;一开始并排读取多个输入文件，查看每个文件中的第一个键，复制最低的键（根据排序顺序）到输出文件，不断重复此步骤，将产生一个新的合并段文件，而且它也是也按键排序的。&lt;/li&gt;
&lt;li&gt;如果在几个输入段中出现相同的键，该怎么办？请记住，每个段都包含在一段时间内写入数据库的所有值。这意味着一个输入段中的所有值一定比另一个段中的所有值都更近（假设我们总是合并相邻的段）。当多个段包含相同的键时，我们可以保留最近段的值，并丢弃旧段中的值。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;为了在文件中找到一个特定的键，你不再需要在内存中保存所有键的索引：
&lt;ul&gt;
&lt;li&gt;假设你正在内存中寻找键 &lt;code&gt;handiwork&lt;/code&gt;，但是你不知道这个键在段文件中的确切偏移量。然而，你知道 &lt;code&gt;handbag&lt;/code&gt; 和 &lt;code&gt;handsome&lt;/code&gt; 的偏移，而且由于排序特性，你知道 &lt;code&gt;handiwork&lt;/code&gt; 必须出现在这两者之间。这意味着你可以跳到 &lt;code&gt;handbag&lt;/code&gt; 的偏移位置并从那里扫描，直到你找到 &lt;code&gt;handiwork&lt;/code&gt;（或没找到，如果该文件中没有该键）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;由于读取请求无论如何都需要扫描所请求范围内的多个键值对，因此可以将这些记录分组为块（block），并在将其写入硬盘之前对其进行压缩。稀疏内存索引中的每个条目都指向压缩块的开始处。除了节省硬盘空间之外，压缩还可以减少对 I/O 带宽的使用。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;那么，可以构建 SSTable 了，可以让存储引擎这样工作：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;有新写入时，将其添加到内存中的平衡树数据结构（例如红黑树），这个内存树有时被称为内存表（memtable）。&lt;/li&gt;
&lt;li&gt;当内存表大于某个阈值（通常为几兆字节）时，将其作为 SSTable 文件写入硬盘。这可以高效地完成，因为树已经维护了按键排序的键值对。新的 SSTable 文件将成为数据库中最新的段。当该 SSTable 被写入硬盘时，新的写入可以在一个新的内存表实例上继续进行。&lt;/li&gt;
&lt;li&gt;收到读取请求时，首先尝试在内存表中找到对应的键，如果没有就在最近的硬盘段中寻找，如果还没有就在下一个较旧的段中继续寻找，以此类推。&lt;/li&gt;
&lt;li&gt;后台进程周期性地执行合并和压缩过程，以合并段文件，并将已覆盖或已删除的值丢弃。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这样的索引结构被称为 LSM-Tree（Log-Structured Merge-Tree）。&lt;/p&gt;
&lt;p&gt;当查找数据库中不存在的键时，LSM 树算法可能会很慢。为了优化这种访问，存储引擎通常会使用布隆过滤器。还可以使用大小分级和分层压缩。对于大小分级，较新和较小的 SSTables 相继被合并到较旧的和较大的 SSTable 中。对于分层压缩，键的范围被拆分到多个较小的 SSTables，而较旧的数据被移动到单独的层级，这使得压缩能够逐步进行并且使用较少的硬盘空间。&lt;/p&gt;
&lt;h4 id=&#34;b-tree&#34;&gt;B-Tree&lt;/h4&gt;
&lt;p&gt;前面看到的日志结构索引将数据库分解为可变大小的段，通常是几兆字节或更大的大小，并且总是按顺序写入段。相比之下，B 树将数据库分解成固定大小的块或分页，传统上大小为 4KB（有时会更大），并且一次只能读取或写入一个页面。这种设计更接近于底层硬件，因为硬盘空间也是按固定大小的块来组织的。&lt;/p&gt;
&lt;p&gt;在 B 树的底层中，写操作是用新数据覆写硬盘上的页面，并假定覆写不改变页面的位置。即当页面被覆写时，对该页面的所有引用保持完整。这与日志结构索引（如 LSM 树）形成鲜明对比，后者只追加到文件（并最终删除过时的文件），但从不修改文件中已有的内容。&lt;/p&gt;</description>
    </item>
    <item>
      <title>《Kubernetes微服务实战》记录</title>
      <link>http://localhost:1313/posts/dailydev/kubernetes%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E6%88%98%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Sat, 25 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/dailydev/kubernetes%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E6%88%98%E8%AE%B0%E5%BD%95/</guid>
      <description>&lt;h1 id=&#34;kubernetes微服务实战记录&#34;&gt;《Kubernetes微服务实战》记录&lt;/h1&gt;
&lt;h2 id=&#34;面向开发人员的-kubernetes-简介&#34;&gt;面向开发人员的 Kubernetes 简介&lt;/h2&gt;
&lt;h3 id=&#34;部分核心概念&#34;&gt;部分核心概念&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Node：Node 是 Kubernetes 集群中的一个工作单元，表示集群中的一台物理机或虚拟机。Node 的作用是为运行容器化应用提供计算资源，一个 Node 可以运行多个 Pod。Node 分为：
&lt;ul&gt;
&lt;li&gt;Master Node：负责集群的控制平面，管理所有工作节点。&lt;/li&gt;
&lt;li&gt;Worker Node：运行实际的应用程序工作负载，实际上就是 Pod。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Pod：Pod 是 Kubernetes 中最小的可部署单位，表示一个或多个容器的集合。有以下特性：
&lt;ul&gt;
&lt;li&gt;Pod 内的容器共享一个 IP 地址，可以通过 &lt;code&gt;localhost&lt;/code&gt; 相互通信。&lt;/li&gt;
&lt;li&gt;Pod 内的容器可以共享挂载的存储卷（Volume）。&lt;/li&gt;
&lt;li&gt;Pod 通常包含运行同一应用程序组件的容器，如主应用程序容器、日志采集容器等。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Namespace：用于逻辑上隔离资源。可以在同一集群中运行多个项目或团队的工作负载。&lt;/li&gt;
&lt;li&gt;Service：用于将一组 Pod 的访问暴露给外部或集群内部的其他 Pod。&lt;/li&gt;
&lt;li&gt;Deployment：用于声明和管理 Pod 的期望状态，例如副本数、滚动更新等。&lt;/li&gt;
&lt;li&gt;Volume：提供持久化存储，允许 Pod 重启后数据仍然保留。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;kubernetes-架构&#34;&gt;Kubernetes 架构&lt;/h3&gt;
&lt;p&gt;每个集群都有一个控制平面和数据平面，数据平面由多个节点组成，控制平面将在这些节点上部署并运行 Pod（容器组），监控变更并做出响应。&lt;/p&gt;
&lt;p&gt;控制平面包含以下组件：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;API 服务器。&lt;/li&gt;
&lt;li&gt;etcd 存储。&lt;/li&gt;
&lt;li&gt;调度器：kube 调度器负责将 Pod 调度到工作节点。&lt;/li&gt;
&lt;li&gt;控制器管理器：kube 控制器管理器是包含多个控制器的单个进程，这些控制器监控着集群事件和对集群的更改做出响应。
&lt;ul&gt;
&lt;li&gt;节点控制器：负责在节点出现故障时进行通知和响应。&lt;/li&gt;
&lt;li&gt;副本控制器：确保每个副本集（replica set）或副本控制器对象中有正确数量的 Pod 。&lt;/li&gt;
&lt;li&gt;端点控制器：为每个服务分配一个列出该服务的 Pod 的端点对象。&lt;/li&gt;
&lt;li&gt;服务账户和令牌控制器：使用默认服务账户和响应的 API 访问令牌对新的命名空间进行初始化。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;数据平面是集群中将容器化工作负载转为 Pod 运行的节点的集合。&lt;/p&gt;</description>
    </item>
    <item>
      <title>minikube：Ubuntu部署本地集群踩坑</title>
      <link>http://localhost:1313/posts/dailydev/minikubeubuntu%E9%83%A8%E7%BD%B2%E6%9C%AC%E5%9C%B0%E9%9B%86%E7%BE%A4%E8%B8%A9%E5%9D%91/</link>
      <pubDate>Sat, 25 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/dailydev/minikubeubuntu%E9%83%A8%E7%BD%B2%E6%9C%AC%E5%9C%B0%E9%9B%86%E7%BE%A4%E8%B8%A9%E5%9D%91/</guid>
      <description>&lt;h1 id=&#34;minikubeubuntu-部署本地集群踩坑&#34;&gt;minikube：Ubuntu 部署本地集群踩坑&lt;/h1&gt;
&lt;h2 id=&#34;官方安装教程&#34;&gt;官方安装教程&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://minikube.sigs.k8s.io/docs/start/?arch=%2Flinux%2Fx86-64%2Fstable%2Fbinary+download&#34;&gt;minikube start | minikube&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;再次感叹 homebrew 的伟大，一行命令就安装、后续也没有问题。&lt;/p&gt;
&lt;h2 id=&#34;仪表盘&#34;&gt;仪表盘&lt;/h2&gt;
&lt;p&gt;使用 &lt;code&gt;minikube dashboard&lt;/code&gt; 启动仪表盘。如果在服务器上启动、本地访问，就运行类似于的下面命令：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-1&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-1&#34;&gt;1&lt;/a&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;kubectl proxy --address&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;0.0.0.0&amp;#39;&lt;/span&gt; --disable-filter&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;true&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;然后把 http://127.0.0.1:46749/api/v1/namespaces/kubernetes-dashboard/services/http:kubernetes-dashboard:/proxy/ 这样的 URL 改为 http://ServerIP:8001/api/v1/namespaces/kubernetes-dashboard/services/http:kubernetes-dashboard:/proxy/ ，就可以外网直接访问了（注意服务器开端口）。&lt;/p&gt;
&lt;h2 id=&#34;helm-安装&#34;&gt;Helm 安装&lt;/h2&gt;
&lt;p&gt;直接使用 snap 安装，方便快捷：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-1-1&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-1-1&#34;&gt;1&lt;/a&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo snap install helm --classic
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;kubectl-安装&#34;&gt;kubectl 安装&lt;/h2&gt;
&lt;p&gt;snap 上大分：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-2-1&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-2-1&#34;&gt;1&lt;/a&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo snap install kubectl --classic
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;安装可能遇到的问题的解决方案&#34;&gt;安装可能遇到的问题的解决方案&lt;/h2&gt;
&lt;h3 id=&#34;the-docker-driver-should-not-be-used-with-root-privileges&#34;&gt;The &amp;ldquo;docker&amp;rdquo; driver should not be used with root privileges&lt;/h3&gt;
&lt;p&gt;使用命令 &lt;code&gt;minikube start&lt;/code&gt; 启动，参数 &lt;code&gt;driver&lt;/code&gt; 默认为 &lt;code&gt;docker&lt;/code&gt; 。如果以 root 用户运行该命令会出现如标题所示的错误，下面是解决方法：&lt;/p&gt;</description>
    </item>
    <item>
      <title>《云原生开发实践》记录</title>
      <link>http://localhost:1313/posts/dailydev/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BC%80%E5%8F%91%E5%AE%9E%E8%B7%B5%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Wed, 22 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/dailydev/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BC%80%E5%8F%91%E5%AE%9E%E8%B7%B5%E8%AE%B0%E5%BD%95/</guid>
      <description>&lt;h1 id=&#34;云原生开发实践记录&#34;&gt;《云原生开发实践》记录&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;本书会包含大量的实践内容，现阶段应着重看理论内容、实践内容暂且忽略，实践内容在理论补充完毕后用到哪块补哪块。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;容器化&#34;&gt;容器化&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;DOCKERFILE 的多阶段构建在部署阶段很有用，可以大幅减少镜像的体积。&lt;/li&gt;
&lt;li&gt;Docker 可以自建网络，这样就可以把很多容器纳入到同一个网络下，实现容器间按容器名访问对方。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;容器编排&#34;&gt;容器编排&lt;/h2&gt;
&lt;p&gt;对于一个中大型的应用，会有很多的容器组件。而有些容器如Redis、RabbitMQ、Kafka等需要紧密的配合，这时候就需要用到容器编排。&lt;/p&gt;
&lt;p&gt;Docker Compose 组件用于实现本地单个节点上的容器编排，它会从 &lt;code&gt;docker-compose.yaml&lt;/code&gt; 文件中读取所需的全部容器的定义，然后运行 &lt;code&gt;docker-compose up&lt;/code&gt; 命令启动容器编排。Docker Swarm 可以管理多个节点上的容器，即管理 Docker 集群。&lt;/p&gt;
&lt;h2 id=&#34;云原生软件生产流程&#34;&gt;云原生软件生产流程&lt;/h2&gt;
&lt;p&gt;云计算的能力：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;弱化了传统 IT 硬件概念，革命性地降低了企业在基础设施上的建设成本。&lt;/li&gt;
&lt;li&gt;实现了弹性获取计算资源，用户可以按需使用。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;云计算的成熟时云原生发展的基石，使云原生的许多概念得以落地。云原生应用一般有以下特点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在应用的设计和开发阶段就为部署到云上做适配。&lt;/li&gt;
&lt;li&gt;应用由多个松耦合的小模块构成而不是一个庞大的单体项目，即微服务架构。&lt;/li&gt;
&lt;li&gt;通过容器来交付和发布应用，应用代码中会加入容器化需要的文件。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;和传统的软件生产方式相比，云原生的优势主要在塔提高了应用发布和运维时的效率，显著降低了运维的复杂性。&lt;/p&gt;
&lt;h2 id=&#34;云原生基础设施&#34;&gt;云原生基础设施&lt;/h2&gt;
&lt;h3 id=&#34;kubernetes&#34;&gt;Kubernetes&lt;/h3&gt;
&lt;p&gt;Kubernetes 是开源的容器编排平台，支持集群环境下部署和管理容器化应用。目前已经是容器编排领域的事实标准，成为云原生的操作系统。Kubernetes 也叫 K8s ，8指中间的8个字母。K8s 2013年由 Google 开源，相比于 Docker Swarm K8s 提供更加复杂强大的功能。&lt;/p&gt;
&lt;p&gt;K8s 集群中包含两种节点，一种是 Control Plane 节点（master 节点），另一种是 worker 节点。K8s 中的容器运行在 Pod 中，Pod 运行在 Node 中。每个集群默认至少有一个 Pod ，否则 Pod 无法调度和运行。Control Plane 是 K8s 的容器编排层，通过它提供的 API ，可以定义和部署容器及管理容器的整个生命周期。Control Plane 有以下组件：&lt;/p&gt;</description>
    </item>
    <item>
      <title>《Go微服务实战》记录</title>
      <link>http://localhost:1313/posts/dailydev/go%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E6%88%98%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Sat, 18 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/dailydev/go%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E6%88%98%E8%AE%B0%E5%BD%95/</guid>
      <description>&lt;h1 id=&#34;go微服务实战记录&#34;&gt;《Go微服务实战》记录&lt;/h1&gt;
&lt;p&gt;本书包含很多的 Go 基础和部分进阶内容，这里只选取对现阶段有帮助的内容，毕竟 Go 已经入门过一遍了。&lt;/p&gt;
&lt;h2 id=&#34;go-基础&#34;&gt;Go 基础&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;关于指针，如果涉及到修改变量本身就使用指针作为函数输入变量等，典型的如单例模式下的变量都是指针。反之如果不修改变量本身，就直接使用复制变量作为函数输入变量等，函数返回值自然也是某个新的变量。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;关于 Go 中的循环，请看 code：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-1&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-1&#34;&gt; 1&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-2&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-2&#34;&gt; 2&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-3&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-3&#34;&gt; 3&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-4&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-4&#34;&gt; 4&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-5&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-5&#34;&gt; 5&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-6&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-6&#34;&gt; 6&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-7&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-7&#34;&gt; 7&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-8&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-8&#34;&gt; 8&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-9&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-9&#34;&gt; 9&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-10&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-10&#34;&gt;10&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-11&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-11&#34;&gt;11&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-12&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-12&#34;&gt;12&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-13&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-13&#34;&gt;13&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-14&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-14&#34;&gt;14&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-15&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-15&#34;&gt;15&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-16&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-16&#34;&gt;16&lt;/a&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;package&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;main&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;main&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;o&#34;&gt;...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;// 最标准的循环
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;o&#34;&gt;...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;// 就是没有显式跳出条件的 while
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nx&#34;&gt;arr&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;v&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;range&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;arr&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;o&#34;&gt;...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;// 这里的 range 是关键字，用法有些类似于 Python 中的 enumerate 函数
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Go 的垃圾回收策略使用的三色标记法，具体内容会单独进行学习。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;字符串与复合数据类型&#34;&gt;字符串与复合数据类型&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;关于字符串的相关操作，见代码：&lt;/p&gt;</description>
    </item>
    <item>
      <title>《PostgreSQL指南》记录</title>
      <link>http://localhost:1313/posts/dailydev/postgresql%E6%8C%87%E5%8D%97%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Sun, 22 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/dailydev/postgresql%E6%8C%87%E5%8D%97%E8%AE%B0%E5%BD%95/</guid>
      <description>&lt;h1 id=&#34;postgresql指南记录&#34;&gt;《PostgreSQL指南》记录&lt;/h1&gt;
&lt;h2 id=&#34;why-choose-postgresql-or-not-mysql-&#34;&gt;Why choose PostgreSQL, or not MySQL ?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;SQL 标准支持更好：PostgreSQL 对 SQL 标准的支持更加全面，而 MySQL 在某些情况下依赖非标准实现（如分组函数的行为）。&lt;/li&gt;
&lt;li&gt;高级功能更强：
&lt;ul&gt;
&lt;li&gt;JOSNB 的性能更优：PostgreSQL 的 JSONB 数据类型支持更高效的索引和操作，而 MySQL 的 JSON 功能较为有限。&lt;/li&gt;
&lt;li&gt;复杂查询：支持递归查询、窗口函数等复杂功能，而 MySQL 在这些方面功能较弱或支持有限。&lt;/li&gt;
&lt;li&gt;并行查询：PostgreSQL 提供原生的并行查询能力，能够充分利用多核 CPU，而 MySQL 直到 8.0 版本才有一定程度的改进。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;扩展性更好：
&lt;ul&gt;
&lt;li&gt;PostgreSQL 支持自定义数据类型、函数和插件，更适合需要扩展或复杂业务逻辑的项目。&lt;/li&gt;
&lt;li&gt;PostGIS 插件使其在地理信息领域表现出色，而 MySQL 的 GIS 功能相对简单。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;更高的性能和灵活性：
&lt;ul&gt;
&lt;li&gt;支持多种索引类型（如 GIN、GiST、BRIN 等），适合高性能全文搜索、地理查询等场景。&lt;/li&gt;
&lt;li&gt;支持更复杂的查询优化器策略，适合复杂查询和数据分析。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;更可靠的数据一致性：
&lt;ul&gt;
&lt;li&gt;PostgreSQL 的 MVCC 机制更成熟，避免了常见的锁争用问题。&lt;/li&gt;
&lt;li&gt;MySQL 的 MVCC 在某些情况下（如高并发）性能欠佳，容易导致死锁。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;PostgreSQL 适用于有复杂数据分析需求、地理信息系统、高并发和大数据量等应用场景，相比于 MySQL 的应用场景更复杂。&lt;/p&gt;
&lt;h2 id=&#34;数据库集簇数据库和数据表&#34;&gt;数据库集簇、数据库和数据表&lt;/h2&gt;
&lt;h3 id=&#34;数据库集簇的逻辑结构&#34;&gt;数据库集簇的逻辑结构&lt;/h3&gt;
&lt;p&gt;数据库集簇是一组数据库的集合，由一个 PostgreSQL 服务器管理。而数据库是数据对象的集合，数据库对象用于存储或引用数据的数据结构。&lt;/p&gt;
&lt;p&gt;在 PosgreSQL 中，所有的数据库对象都通过相应的对象标识符（oid）进行管理，这些标识都是无符号 4 字节整型。&lt;/p&gt;</description>
    </item>
    <item>
      <title>《高效使用Redis》记录</title>
      <link>http://localhost:1313/posts/dailydev/%E9%AB%98%E6%95%88%E4%BD%BF%E7%94%A8redis%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Thu, 05 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/dailydev/%E9%AB%98%E6%95%88%E4%BD%BF%E7%94%A8redis%E8%AE%B0%E5%BD%95/</guid>
      <description>&lt;h1 id=&#34;高效使用redis记录&#34;&gt;《高效使用Redis》记录&lt;/h1&gt;
&lt;h2 id=&#34;基础数据结构解析&#34;&gt;基础数据结构解析&lt;/h2&gt;
&lt;h3 id=&#34;对象&#34;&gt;对象&lt;/h3&gt;
&lt;p&gt;Redis中的 RedisObject 的 c 定义：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-1&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-1&#34;&gt;1&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-2&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-2&#34;&gt;2&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-3&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-3&#34;&gt;3&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-4&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-4&#34;&gt;4&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-5&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-5&#34;&gt;5&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-6&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-6&#34;&gt;6&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-7&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-7&#34;&gt;7&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-8&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-8&#34;&gt;8&lt;/a&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#define LRU_BITS 24
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;typedef&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;redisObject&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;kt&#34;&gt;unsigned&lt;/span&gt; &lt;span class=&#34;nl&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;// 数据类型
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;  &lt;span class=&#34;kt&#34;&gt;unsigned&lt;/span&gt; &lt;span class=&#34;nl&#34;&gt;encoding&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;// 底层数据结构
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;  &lt;span class=&#34;kt&#34;&gt;unsigned&lt;/span&gt; &lt;span class=&#34;nl&#34;&gt;lru&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;LRU_BITS&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;// 缓存淘汰时使用
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;  &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;refcount&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;// 引用计数
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;  &lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ptr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;// 指向实际存储位置
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;robj&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;RedisObject 是 Redis 中数据结构的一个抽象，用它来存储所有的 key-value 数据。&lt;/p&gt;
&lt;p&gt;下面是结构体中各个属性的。说明：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;type：用来表示对象类型；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;encoding：表示当前对象底层存储所采用的数据结构，如int、字典、压缩列表、跳跃表等等；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;lru：用于在配置文件中通过 maxmemory-policy 配置已用内存到最大内存限制时的缓存淘汰策略。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;以 GET 命令为例，简单看看 Redis 中的 LRU 实现。使用 GET 后，会执行这段代码更新对象的 lru 属性：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-1-1&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-1-1&#34;&gt;1&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-1-2&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-1-2&#34;&gt;2&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-1-3&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-1-3&#34;&gt;3&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-1-4&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-1-4&#34;&gt;4&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-1-5&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-1-5&#34;&gt;5&lt;/a&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;server&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;maxmemory_policy&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;MAXMEMORY_FLAG_LRU&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;uodateLFU&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;val&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;val&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lru&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;LRU_CLOCK&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;LRU_CLOCK 用于获取当前时间，但并不是实时获取。Redis 每 1s 执行系统调用来获取精确时间，然后存储在全局变量 server.lruclock 中，LRU_CLOCK 只是获取该缓存时间。updateLFU 用于更新对象的上次访问时间和访问次数。&lt;/p&gt;</description>
    </item>
    <item>
      <title>《gRPC与云原生应用开发》记录</title>
      <link>http://localhost:1313/posts/dailydev/grpc%E4%B8%8E%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Sat, 30 Nov 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/dailydev/grpc%E4%B8%8E%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E8%AE%B0%E5%BD%95/</guid>
      <description>&lt;h1 id=&#34;grpc与云原生应用开发记录&#34;&gt;《gRPC与云原生应用开发》记录&lt;/h1&gt;
&lt;h2 id=&#34;grpc-入门&#34;&gt;gRPC 入门&lt;/h2&gt;
&lt;h3 id=&#34;grpc-的定义&#34;&gt;gRPC 的定义&lt;/h3&gt;
&lt;p&gt;gRPC 是一项进程间通信技术，可以用来连接、调用、操作和调试分布式异构应用程序。&lt;/p&gt;
&lt;p&gt;开发 gRPC 应用程序时，要先定义服务接口：消费者消费信息的方式、消费者能够远程调用的方法以及调用方法所使用的参数和消息格式等。在服务定义中使用的语言叫作接口定义语言（IDL）。&lt;/p&gt;
&lt;p&gt;下面是使用 protocol buffers 作为 IDL 来定义服务接口：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;服务定义&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-1&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-1&#34;&gt; 1&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-2&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-2&#34;&gt; 2&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-3&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-3&#34;&gt; 3&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-4&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-4&#34;&gt; 4&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-5&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-5&#34;&gt; 5&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-6&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-6&#34;&gt; 6&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-7&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-7&#34;&gt; 7&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-8&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-8&#34;&gt; 8&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-9&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-9&#34;&gt; 9&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-10&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-10&#34;&gt;10&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-11&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-11&#34;&gt;11&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-12&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-12&#34;&gt;12&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-13&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-13&#34;&gt;13&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-14&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-14&#34;&gt;14&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-15&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-15&#34;&gt;15&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-16&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-16&#34;&gt;16&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-17&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-17&#34;&gt;17&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-18&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-18&#34;&gt;18&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-19&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-19&#34;&gt;19&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-20&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-20&#34;&gt;20&lt;/a&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-protobuf&#34; data-lang=&#34;protobuf&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// ProductInfo.proto
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;syntax&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;proto3&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kn&#34;&gt;package&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;ecommerce&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;// 防止协议消息类型之间发生命名冲突
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;// 定义服务接口
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;service&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ProductInfo&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;k&#34;&gt;rpc&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;addProduct&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Product&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;returns&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ProductID&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;k&#34;&gt;rpc&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;getProduct&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ProductID&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;returns&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Product&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;// 定义消息格式
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;message&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Product&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;description&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;message&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;ProductID&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;value&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;上面定义完成之后，就使用 protocol buffers 编译器 protoc 生成服务器端和客户端代码。&lt;/p&gt;</description>
    </item>
    <item>
      <title>《深入RabbitMQ》记录</title>
      <link>http://localhost:1313/posts/dailydev/%E6%B7%B1%E5%85%A5rabbitmq%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Thu, 28 Nov 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/dailydev/%E6%B7%B1%E5%85%A5rabbitmq%E8%AE%B0%E5%BD%95/</guid>
      <description>&lt;h1 id=&#34;深入rabbitmq记录&#34;&gt;《深入RabbitMQ》记录&lt;/h1&gt;
&lt;h2 id=&#34;rabbitmq-基础&#34;&gt;RabbitMQ 基础&lt;/h2&gt;
&lt;h3 id=&#34;amqp-协议&#34;&gt;AMQP 协议&lt;/h3&gt;
&lt;p&gt;AMQP，即高级消息队列协议（Advanced Meesage Queuing Protocal）。它定义了一个 AMQ 应该有以下三部分：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;交换器：一个接收器接收发送到 MQ 中的消息并决定把它们投递到何处；&lt;/li&gt;
&lt;li&gt;队列：存储接收到的消息；&lt;/li&gt;
&lt;li&gt;绑定：定义队列和交换器之间的关系。在 RabbitMQ 中，绑定或者叫绑定键即告知一个叫交换器应该将消息投递到哪些队列中。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;使用-amq-协议与-rabbit-进行交互&#34;&gt;使用 AMQ 协议与 Rabbit 进行交互&lt;/h2&gt;
&lt;h3 id=&#34;amqp-帧类型&#34;&gt;AMQP 帧类型&lt;/h3&gt;
&lt;p&gt;AMQP 规定了五种类型的帧：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;协议头帧：用于连接到 RabbitMQ，仅使用一次；&lt;/li&gt;
&lt;li&gt;方法帧：携带发送到 RabbitMQ 或从 RabbitMQ 接收到的 RPC 请求或响应；&lt;/li&gt;
&lt;li&gt;内容头帧：包含一条消息的大小和属性；&lt;/li&gt;
&lt;li&gt;消息体帧：包含消息的内容；&lt;/li&gt;
&lt;li&gt;心跳帧：确保连接，一种校验机制。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;将消息编组成帧&#34;&gt;将消息编组成帧&lt;/h3&gt;
&lt;p&gt;首先是方法帧、内容头帧，这两种帧比较好理解。&lt;/p&gt;
&lt;p&gt;而消息体帧会根据消息体的大小切分成一到多个消息体帧。&lt;/p&gt;
&lt;p&gt;要发送消息，首先发送的是方法帧，之后是内容帧，最后是若干个消息体帧。&lt;/p&gt;
&lt;h3 id=&#34;帧结构&#34;&gt;帧结构&lt;/h3&gt;
&lt;p&gt;方法帧携带构建 RPC 请求所需的类、方法和参数。&lt;/p&gt;
&lt;p&gt;内容头帧包含了消息的大小和其他对消息起描述作用的属性。&lt;/p&gt;
&lt;p&gt;消息体帧可以传输很多类型的数据，可以是二进制、文本，也可以是二进制化的图片和序列化后的json、xml。&lt;/p&gt;
&lt;h3 id=&#34;使用协议&#34;&gt;使用协议&lt;/h3&gt;
&lt;p&gt;包含下面一个基本流程：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;声明交换器&lt;/li&gt;
&lt;li&gt;声明队列&lt;/li&gt;
&lt;li&gt;绑定队列到交换器&lt;/li&gt;
&lt;li&gt;发布消息到 RabbitMQ&lt;/li&gt;
&lt;li&gt;从 RabbitMQ 消费消息&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;消息属性详解&#34;&gt;消息属性详解&lt;/h2&gt;
&lt;h3 id=&#34;使用-content-type-创建显式的消息契约&#34;&gt;使用 content-type 创建显式的消息契约&lt;/h3&gt;
&lt;p&gt;在不同的语言的消费者框架中，框架可以自动的根据 content-type 类型将其反序列化为该语言中的数据结构。&lt;/p&gt;
&lt;h3 id=&#34;使用-gzip-和-content-encoding-压缩消息大小&#34;&gt;使用 gzip 和 content-encoding 压缩消息大小&lt;/h3&gt;
&lt;p&gt;通过指定 content-encoding 属性可以在消息体上应用特殊的编码。&lt;/p&gt;</description>
    </item>
    <item>
      <title>华为云部署踩坑</title>
      <link>http://localhost:1313/posts/dailydev/%E5%8D%8E%E4%B8%BA%E4%BA%91%E9%83%A8%E7%BD%B2%E8%B8%A9%E5%9D%91/</link>
      <pubDate>Tue, 05 Nov 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/dailydev/%E5%8D%8E%E4%B8%BA%E4%BA%91%E9%83%A8%E7%BD%B2%E8%B8%A9%E5%9D%91/</guid>
      <description>&lt;h2 id=&#34;华为云部署踩坑&#34;&gt;华为云部署踩坑&lt;/h2&gt;
&lt;h3 id=&#34;docker-国内镜像源截止到2024111&#34;&gt;Docker 国内镜像源（截止到2024.11.1）&lt;/h3&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;DockerHub 镜像仓库&lt;/th&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;是否正常&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;hub.xdark.top&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;正常&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;hub.littlediary.cn&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;正常&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;dockerpull.org&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;新增&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;hub.crdz.gq&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;正常&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;docker.1panel.live&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;正常&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;docker.unsee.tech&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;新增&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;docker.m.daocloud.io&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;正常&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;docker.kejilion.pro&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;正常&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;registry.dockermirror.com&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;正常&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;hub.rat.dev&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;正常&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;dhub.kubesre.xyz&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;正常&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;docker.nastool.de&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;正常&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;docker.hpcloud.cloud&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;失效&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;docker.hlyun.org&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;失效&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;doublezonline.cloud&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;失效&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;docker.chenby.cn&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;失效&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;ginger20240704.asia&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;失效&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;lynn520.xyz&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;失效&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;hub.docker-ttc.xyz&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;失效&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;noohub.ru&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;失效&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;docker.nat.tf&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;失效&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;dockerproxy.cn&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;失效&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;freeno.xyz&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;失效&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;docker.registry.cyou&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;失效&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;hub.yuzuha.cc&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;失效&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;docker-cf.registry.cyou&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;失效&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;docker.mrxn.net&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;失效&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;dockerproxy.github.io&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;失效&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;docker.wget.at&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;失效&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;atomhub.openatom.cn&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;失效&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;ccr.ccs.tencentyun.com&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;失效&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;dockerproxy.com&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;失效&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;dislabaiot.xyz&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;失效&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;dockerpull.com&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;失效&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;hub.firefly.store&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;失效&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;配置方式1临时使用&#34;&gt;配置方式1：临时使用&lt;/h4&gt;
&lt;p&gt;直接使用，直接拿镜像&lt;a href=&#34;https://cloud.tencent.com/act/pro/domain-sales?from_column=20065&amp;amp;from=20065&#34;&gt;域名&lt;/a&gt;拼接上官方镜像名，例如要拉去镜像&lt;code&gt;istio/distroless&lt;/code&gt;，可以用下面写法（不要带 &lt;code&gt;https://&lt;/code&gt;）&lt;/p&gt;</description>
    </item>
    <item>
      <title>《计组KG》课题开发过程（三）</title>
      <link>http://localhost:1313/posts/dailydev/%E8%AE%A1%E7%BB%84kg%E8%AF%BE%E9%A2%98%E5%BC%80%E5%8F%91%E8%BF%87%E7%A8%8B%E4%B8%89/</link>
      <pubDate>Mon, 04 Nov 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/dailydev/%E8%AE%A1%E7%BB%84kg%E8%AF%BE%E9%A2%98%E5%BC%80%E5%8F%91%E8%BF%87%E7%A8%8B%E4%B8%89/</guid>
      <description>&lt;h2 id=&#34;牢骚&#34;&gt;牢骚&lt;/h2&gt;
&lt;p&gt;时隔一个多月才完成了基本的可视化系统的搭建，中间有着各种各样的原因：Vue3第一次用、Django-Ninja不熟悉等等再加上一些闲杂原因就一直拖到了现在，效率多少有点堪忧。&lt;/p&gt;
&lt;p&gt;总之不算怎么说，也算是曲折的完成了原定计划，下面将从后端、前端的技术选择、功能介绍、成品展示等几个章节大致的讲述下。&lt;/p&gt;
&lt;h2 id=&#34;后端&#34;&gt;后端&lt;/h2&gt;
&lt;h3 id=&#34;项目地址&#34;&gt;项目地址&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/KurongTohsaka/PCCKGVisualization/tree/main&#34;&gt;KurongTohsaka/PCCKGVisualization&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;技术栈&#34;&gt;技术栈&lt;/h3&gt;
&lt;p&gt;Web 框架自然是选相对擅长且好用的 Django ，但是 Django 本身使用起来又过于繁重，不太适合开发Restful类型的接口，所以一般会搭配着 Django REST Framework (DRF) 使用。但是这一次我打算尝试一个新的 Django 扩展，它是 FastAPI 的 Django 版：Django-Ninja 。&lt;/p&gt;
&lt;p&gt;Web 框架订好了以后，就该选数据库了。既然是存储图数据，那肯定是 Neo4j 。而网站数据就使用简单的 Sqlite 吧，主要就是省事。&lt;/p&gt;
&lt;h3 id=&#34;功能与接口&#34;&gt;功能与接口&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;下面的所有接口的最上级请求路径：&lt;code&gt;pcc_kg_vs&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;功能主要分为两部分：认证和可视化。&lt;/p&gt;
&lt;p&gt;首先是认证，包含以下基本功能：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;用户认证：用户登陆、注册、登出&lt;/li&gt;
&lt;li&gt;API 鉴权：token 验证&lt;/li&gt;
&lt;li&gt;CSRF 验证：CSRF token 验证&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下面是简易的接口标准：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;登陆&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;先检查该用户是否已注册，若注册则从数据库中根据信息查询到用户，然后登陆该用户。若未注册则登陆失败&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-1&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-1&#34;&gt; 1&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-2&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-2&#34;&gt; 2&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-3&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-3&#34;&gt; 3&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-4&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-4&#34;&gt; 4&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-5&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-5&#34;&gt; 5&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-6&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-6&#34;&gt; 6&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-7&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-7&#34;&gt; 7&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-8&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-8&#34;&gt; 8&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-9&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-9&#34;&gt; 9&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-10&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-10&#34;&gt;10&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-11&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-11&#34;&gt;11&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-12&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-12&#34;&gt;12&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-13&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-13&#34;&gt;13&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-14&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-14&#34;&gt;14&lt;/a&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &amp;#34;method&amp;#34;: &amp;#34;POST&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &amp;#34;path&amp;#34;: &amp;#34;/login&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &amp;#34;params&amp;#34;: {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;username&amp;#34;: &amp;#34;&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;password&amp;#34;: &amp;#34;&amp;#34;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  },
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &amp;#34;return&amp;#34;: {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;successful&amp;#34;: bool,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;code&amp;#34;: int,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;token&amp;#34;: str,  //登陆令牌
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#39;info&amp;#39;: str
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  }
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;登出 HTTPBearer&lt;/p&gt;</description>
    </item>
    <item>
      <title>MAC上用docker配置neo4j以及apoc扩展的过程</title>
      <link>http://localhost:1313/posts/dailydev/%E9%85%8D%E7%BD%AEnep4j%E8%BF%87%E7%A8%8B/</link>
      <pubDate>Tue, 22 Oct 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/dailydev/%E9%85%8D%E7%BD%AEnep4j%E8%BF%87%E7%A8%8B/</guid>
      <description>&lt;h2 id=&#34;拉取-neo4j-docker-image&#34;&gt;拉取 neo4j Docker image&lt;/h2&gt;
&lt;p&gt;在 MAC 上用的 Docker Desktop，确实很方便操作。&lt;/p&gt;
&lt;p&gt;直接在 Image Tab 页搜 Neo4j 就有一个官方 image，我选的 5.24.1版本，pull 下来。&lt;/p&gt;
&lt;p&gt;这里之所以要选择一个特定的版本，原因是之后要启用的 apoc 扩展需要用对应 neo4j 版本的 jar 包。&lt;/p&gt;
&lt;h2 id=&#34;配置容器&#34;&gt;配置容器&lt;/h2&gt;
&lt;p&gt;因为用的 Docker Desktop，很多没必要的步骤都可以直接忽略。配置好转发端口、挂载位置后，就启动容器。&lt;/p&gt;
&lt;p&gt;Neo4j 容器启动后默认直接运行，登陆 Web 管理界面配置后用户名密码后就完成了基本配置。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Docker 真 tm 好用（&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;配置-apoc&#34;&gt;配置 apoc&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;这里需要注意一点，neo4j 5.x 之后的版本中，apoc 本身的相关配置需要写在 &lt;code&gt;neo4j/conf/apoc.conf&lt;/code&gt; 里，而不是 &lt;code&gt;neo4j/conf/neo4j.conf&lt;/code&gt; 中，不然在启动服务时会报错！！！&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;首先是 apoc 的下载地址：&lt;a href=&#34;http://doc.we-yun.com:1008/doc/neo4j-apoc/&#34;&gt;Index of /doc/neo4j-apoc/&lt;/a&gt; 。&lt;/p&gt;
&lt;p&gt;下载好后，把它放进 &lt;code&gt;neo4j/plugins&lt;/code&gt;，并改名为 &lt;code&gt;apoc.jar&lt;/code&gt; &lt;strong&gt;（啥名都行，这里是方面后面改配置）&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;接下来修改 &lt;code&gt;neo4j/conf/neo4j.conf&lt;/code&gt; ，修改以下两行并取消该行注释：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-1&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-1&#34;&gt;1&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-2&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-2&#34;&gt;2&lt;/a&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-gdscript3&#34; data-lang=&#34;gdscript3&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;dbms&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;security&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;procedures&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;unrestricted&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;apoc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.*&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;dbms&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;security&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;procedures&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;allowlist&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;apoc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;coll&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.*&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;apoc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;load&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.*&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;最后修改 &lt;code&gt;neo4j/conf/apoc.conf&lt;/code&gt; ：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-1-1&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-1-1&#34;&gt;1&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-1-2&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-1-2&#34;&gt;2&lt;/a&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-gdscript3&#34; data-lang=&#34;gdscript3&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;apoc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;import&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;true&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;apoc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;export&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;true&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;到这里就配置完所有的了，重启服务即可。&lt;/p&gt;</description>
    </item>
    <item>
      <title>《Distantly-Supervised Joint Extraction with Noise-Robust Learning》笔记</title>
      <link>http://localhost:1313/posts/papernotes/distantly-supervised_joint_extraction_with_noise-robust_learning/</link>
      <pubDate>Sat, 05 Oct 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/papernotes/distantly-supervised_joint_extraction_with_noise-robust_learning/</guid>
      <description>&lt;h2 id=&#34;link&#34;&gt;Link&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2310.04994#:~:text=We%20propose%20DENRL,%20a%20generalizable%20framework%20that%201&#34;&gt;https://arxiv.org/abs/2310.04994#:~:text=We%20propose%20DENRL,%20a%20generalizable%20framework%20that%201&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Accepted by ACL 2024.&lt;/p&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;联合抽取&lt;/strong&gt;旨在使用单一模型检测实体及其关系，这是自动知识库构建中的关键步骤。为了廉价地获取大量标注的联合训练数据，提出了&lt;strong&gt;远程监督（Distantly Supervise，DS）&lt;/strong&gt;，通过将知识库（Knowledge Base，KB）与未标注的语料库对齐，自动生成训练数据。假设如果一个实体对在 KB 中有关系，则包含该对的所有句子都表达相应的关系。&lt;/p&gt;
&lt;p&gt;然而，DS 带来了大量的&lt;strong&gt;噪声标签&lt;/strong&gt;，显著降低了联合抽取模型的性能。此外，由于开放域 KB 中实体的模糊性和覆盖范围有限，DS 还会生成噪声和不完整的实体标签。在某些情况下，DS 可能导致 KB 中包含超过30%的噪声实例，使得学习有用特征变得不可能。&lt;/p&gt;
&lt;p&gt;处理这些噪声标签的先前研究要么考虑弱标注的实体，即远程监督的命名实体识别（NER），要么考虑噪声关系标签，即远程监督的关系抽取（RE），它们专注于设计新颖的手工制作关系特征、神经架构和标注方案以提高关系抽取性能。此外，使用大型语言模型（LLMs）的上下文学习（ICL）也很流行。然而，它们资源需求高，对提示设计敏感，可能在处理复杂任务时表现不佳。&lt;/p&gt;
&lt;p&gt;为了廉价地减轻两种噪声源，我们提出了 &lt;strong&gt;DENRL&lt;/strong&gt; （&lt;strong&gt;D&lt;/strong&gt;istantly-supervised joint &lt;strong&gt;E&lt;/strong&gt;xtraction with &lt;strong&gt;N&lt;/strong&gt;oise-&lt;strong&gt;R&lt;/strong&gt;obust &lt;strong&gt;L&lt;/strong&gt;earning）。DENRL 假设&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可靠的关系标签，其关系模式显著表明实体对之间的关系，应该由模型解释；&lt;/li&gt;
&lt;li&gt;可靠的关系标签也隐含地表明相应实体对的可靠实体标签。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;具体来说，DENRL应用词袋正则化（BR）引导模型关注解释正确关系标签的显著关系模式，并使用基于本体的逻辑融合（OLF）通过概率软逻辑（PSL）教授底层实体关系依赖性。这两种信息源被整合形成噪声鲁棒损失，正则化标注模型从具有正确实体和关系标签的实例中学习。接下来，如果学习到的模型能够清晰地定位关系模式并理解候选实例的实体关系逻辑，它们将被选择用于后续的自适应学习。我们进一步采样包含已识别模式中对应头实体或尾实体的负实例以减少实体噪声。我们迭代学习一个可解释的模型并选择高质量实例。这两个步骤相互强化——更可解释的模型有助于选择更高质量的子集，反之亦然。&lt;/p&gt;
&lt;h2 id=&#34;joint-extraction-architecture&#34;&gt;Joint Extraction Architecture&lt;/h2&gt;
&lt;h3 id=&#34;tagging-scheme&#34;&gt;Tagging Scheme&lt;/h3&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/PaperNotes/Distantly-Supervised_Joint_Extraction_with_Noise-Robust_Learning/img1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/PaperNotes/Distantly-Supervised_Joint_Extraction_with_Noise-Robust_Learning/img2.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;为了同时抽取实体（提及和类型）和关系，我们为每个起始位置 $p$ 标注四元组 ${e_1, tag_1, e_2, r_e}$，并定义 “BIO” 标记来编码位置。对于一个 $T$ 个 token 的句子，我们根据不同的起始位置标注 $T$ 个不同的标记序列。&lt;/p&gt;
&lt;p&gt;对于每个标记序列，如果 $p$ 是一个实体的起始位置（该序列是一个实例），则在 $p$ 处标注实体类型，并用关系类型标注与 $p$ 处实体有关系的其他实体。其余的令牌标注为 “O”（Outside），表示它们不对应头实体。这样，每个标记序列将生成一个关系四元组。&lt;/p&gt;
&lt;p&gt;我们将包含至少一个关系的实例定义为正实例，没有关系的实例定义为负实例。“BIO”（Begin, Inside, Outside）标记用于指示每个实体中令牌的位置信息，以便同时提取多词实体和关系类型。注意，我们不需要尾实体类型，因为每个实体都会被查询，我们可以从 T 标记序列中获得所有实体类型及其关系。&lt;/p&gt;</description>
    </item>
    <item>
      <title>《Summarization as Indirect Supervision for Relation Extraction》笔记</title>
      <link>http://localhost:1313/posts/papernotes/summarization_as_indirect_supervision_for_relation_extraction/</link>
      <pubDate>Sun, 29 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/papernotes/summarization_as_indirect_supervision_for_relation_extraction/</guid>
      <description>&lt;h2 id=&#34;link&#34;&gt;Link&lt;/h2&gt;
&lt;p&gt;[&lt;a href=&#34;https://arxiv.org/abs/2205.09837v2&#34;&gt;2205.09837v2] Summarization as Indirect Supervision for Relation Extraction (arxiv.org)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Accepted EMNLP 2022.&lt;/p&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;
&lt;p&gt;关系抽取（RE）旨在从文本中提取实体之间的关系。例如，给定句子“Steve Jobs 是 Apple 的创始人”，RE 模型会识别出“创立”这一关系。RE 是自然语言理解的重要任务，也是构建知识库的关键步骤。先进的 RE 模型对于对话系统、叙事预测和问答等知识驱动的下游任务至关重要。&lt;/p&gt;
&lt;p&gt;现有的 RE 模型通常依赖于带有昂贵注释的训练数据，这限制了它们的应用。为了应对这一问题，本文提出了一种新的方法——&lt;strong&gt;SURE（Summarization as Relation Extraction）&lt;/strong&gt;，将 RE 转化为摘要任务，通过间接监督来提高 RE 的精度和资源效率。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/PaperNotes/Summarization_as_Indirect_Supervision_for_Relation_Extraction/img1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;图1展示了 SURE 的结构。具体来说，SURE 通过关系和句子转换技术将 RE 转化为摘要任务，并应用约束推理进行关系预测。我们采用实体信息口语化技术，突出包含实体信息的句子上下文，并将关系口语化为模板式的简短摘要。这样，转换后的RE输入和输出自然适合摘要模型。然后，我们通过在转换后的RE数据上进行微调，将摘要模型适配于RE任务。在推理过程中，设计了一种 Trie 评分技术来推断关系。通过这种方式，SURE 充分利用了摘要的间接监督，即使在资源匮乏的情况下也能获得精确的RE模型。&lt;/p&gt;
&lt;p&gt;这项工作的贡献有两个方面。首先，据我们所知，这是首次研究利用摘要的间接监督进行RE。由于摘要的目标与 RE 自然对齐，它允许在不完全依赖直接任务注释的情况下训练出精确的 RE 模型，并在资源匮乏的情况下表现出色。其次，我们研究了有效桥接摘要和 RE 任务形式的输入转换技术，以及进一步增强基于摘要的RE推理的约束技术。我们的贡献通过在三个广泛使用的句子级 RE 数据集 TACRED、TACREV 和 SemEval 以及 TACRED 的三个低资源设置上的实验得到验证。我们观察到，SURE 在低资源设置下（使用10%的 TACRED 训练数据）优于各种基线。SURE 还在 TACRED 和 TACREV上 分别以75.1%和83.5%的 micro-F1 得分达到了SOTA 性能。我们还进行了全面的消融研究，展示了摘要的间接监督的有效性以及 SURE 输入转换的最佳选项。&lt;/p&gt;</description>
    </item>
    <item>
      <title>《Modular Self-Supervision for Document-Level Relation Extraction》笔记</title>
      <link>http://localhost:1313/posts/papernotes/modular_self-supervision_for_document-level_relation_extraction/</link>
      <pubDate>Sat, 28 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/papernotes/modular_self-supervision_for_document-level_relation_extraction/</guid>
      <description>&lt;h2 id=&#34;link&#34;&gt;Link&lt;/h2&gt;
&lt;p&gt;[&lt;a href=&#34;https://arxiv.org/abs/2109.05362&#34;&gt;2109.05362] Modular Self-Supervision for Document-Level Relation Extraction (arxiv.org)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Accepted at EMNLP 2021&lt;/p&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;
&lt;p&gt;信息抽取的先前工作通常集中在句子内的二元关系。然而，实际应用往往需要跨大段文本提取复杂关系。这在生物医学等高价值领域尤为重要，因为获取最新发现的高召回率至关重要。例如，图1显示了一个三元（药物、基因、突变）关系，表明具有 MAP2K1 突变 K57T 的肿瘤对 cobimetinib 敏感，但这些实体从未在同一段落中同时出现。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/PaperNotes/Modular_Self-Supervision_for_Document-Level_Relation_Extraction/img1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;先前的工作都将文档级关系抽取视为一个单一的整体问题，这在推理和学习上都带来了重大挑战。尽管最近取得了一些进展，但在使用最先进的神经架构（如LSTM 和 transformer）建模长文本范围时仍存在显著挑战。此外，直接监督稀缺，任务特定的自监督（如距离监督）在应用于短文本范围之外时变得极其嘈杂。&lt;/p&gt;
&lt;p&gt;在本文中，我们通过将文档级关系抽取分解为局部关系检测和全局推理来探索一种替代范式。具体来说，我们使用 Davidsonian 语义表示 $n$ 元关系，并结合段落级关系分类和使用全局推理规则（例如，参数解析的传递性）的篇章级参数解析。每个组件问题都存在于短文本范围内，其相应的自监督错误率要低得多。我们的方法借鉴了模块化神经网络和神经逻辑编程的灵感，将复杂任务分解为局部神经学习和全局结构化集成。然而，我们不是从端到端的直接监督中学习，而是承认组件问题的模块化自监督（Modular Self-Supervision），这更容易获得。&lt;/p&gt;
&lt;p&gt;这种模块化方法不仅使我们能够处理长文本，还能扩展到所有先前方法无法覆盖的跨段落关系。我们在精准肿瘤学的生物医学机器阅读中进行了全面评估，其中跨段落关系尤为普遍。我们的方法在最具挑战性的关系中表现尤为突出，这些关系的参数从未在段落中同时出现，其F1分数比之前的最先进方法（如多尺度学习（和图神经网络高出20多个百分点。&lt;/p&gt;
&lt;h2 id=&#34;document-level-relation-extraction&#34;&gt;Document-Level Relation Extraction&lt;/h2&gt;
&lt;p&gt;设 $E,R,D$ 分别代表实体、关系、文档，那在图2中的 $R$ 为精准癌症药物反应，实体 $E_1,E_2,E_3$​ 分别药物 cobimetinib、基因 MAP2K1 和突变 K57T。这个关系跨越多个段落和几十个句子。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/PaperNotes/Modular_Self-Supervision_for_Document-Level_Relation_Extraction/img2.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;用新戴维森语义表示 n 元关系抽取：
&lt;/p&gt;
$$
R_D(E_1, \cdots, E_n) \equiv \exists T \in D \exists r. [R_T(r) \land A_1(r, E_1) \land \cdots \land A_n(r, E_n)]
$$&lt;p&gt;
其中，$T$ 为文档 $D$ 中的片段，$r$ 为引入的事件变量以表示 $R$​ 。&lt;/p&gt;</description>
    </item>
    <item>
      <title>《Separating Retention from Extraction in the Evaluation of End-to-end Relation Extraction》笔记</title>
      <link>http://localhost:1313/posts/papernotes/separating_retention_from_extraction/</link>
      <pubDate>Fri, 27 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/papernotes/separating_retention_from_extraction/</guid>
      <description>&lt;h2 id=&#34;link&#34;&gt;Link&lt;/h2&gt;
&lt;p&gt;[&lt;a href=&#34;https://arxiv.org/abs/2109.12008v1&#34;&gt;2109.12008v1] Separating Retention from Extraction in the Evaluation of End-to-end Relation Extraction (arxiv.org)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Accepted at EMNLP 2021&lt;/p&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;
&lt;p&gt;信息抽取（Information Extraction, IE）旨在将文本中表达的信息转换为预定义的结构化知识格式。这个总体目标被分解为更容易自动执行和评估的子任务。因此，命名实体识别（Named Entity Recognition, NER）和关系抽取（Relation Extraction, RE）是两个关键的 IE 任务。传统上，这些任务是通过流水线方式执行的。也可以采用联合方式处理，以建模它们的相互依赖性，减少错误传播并获得更现实的评估设置。&lt;/p&gt;
&lt;p&gt;随着 NLP 领域的总体趋势，最近在实体和关系抽取基准测试中报告的定量改进至少部分归因于使用了越来越大的预训练语言模型（Language Models, LMs），如 BERT 来获得上下文词表示。同时，人们意识到需要新的评估协议，以更好地理解所获得的神经网络模型的优缺点，而不仅仅是对一个保留测试集上的单一整体指标。&lt;/p&gt;
&lt;p&gt;特别是，对未见数据的泛化是评估深度神经网络的关键因素。在涉及提取提及的IE任务中，这一点尤为重要：小范围的词语可能会同时出现在评估和训练数据集中。已证明这种词汇重叠与NER中神经网络的性能相关。对于流水线 RE，神经模型过度依赖候选参数的类型或其上下文中存在的特定触发词。&lt;/p&gt;
&lt;p&gt;在端到端关系抽取中，我们可以预期这些 NER 和 RE 会结合在一起。在这项工作中，我们认为当前的评估基准不仅衡量了从文本中提取信息的能力，还衡量了模型在训练期间简单保留标记的（头、谓词、尾）三元组的能力。当模型在训练期间看到的句子上进行评估时，很难区分这两种行为中的哪一种占主导地位。&lt;/p&gt;
&lt;p&gt;然而，我们可以假设模型可以简单地检索先前看到的信息，像一个被压缩的知识库一样，通过相关查询进行探测。因此，在包含过多已见三元组的示例上进行测试可能会高估模型的泛化能力。&lt;/p&gt;
&lt;p&gt;即使没有标记数据，LMs也能够学习一些单词之间的关系，可以通过填空句子进行探测，其中一个参数被掩盖。&lt;/p&gt;
&lt;h2 id=&#34;datasets-and-models&#34;&gt;Datasets and Models&lt;/h2&gt;
&lt;p&gt;数据集选用了 CoNLL04、ACE05、SciERC。&lt;/p&gt;
&lt;p&gt;模型选用了三个模型：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PURE：Pipeline 模型&lt;/li&gt;
&lt;li&gt;SpERT：Joint 模型&lt;/li&gt;
&lt;li&gt;Two are better than one（TABTO）：Joint 模型&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;partitioning-by-lexical-overlap基于词汇重叠的划分&#34;&gt;Partitioning by Lexical Overlap（基于词汇重叠的划分）&lt;/h2&gt;
&lt;p&gt;我们根据与训练集的词汇重叠情况对测试集中的实体提及进行划分。我们区分了已见和未见的提及，并将这种划分扩展到关系上。&lt;/p&gt;
&lt;p&gt;我们实现了一个简单的保留启发式方法（Retention Heuristic，启发式方法），将训练集中确切存在的实体提及或关系标记为其多数标签。我们在表1中报告了 NER 和 RE 的 Micro-avg. 精度、召回率和 F1 分数。&lt;/p&gt;</description>
    </item>
    <item>
      <title>《Better Few-Shot Relation Extraction with Label Prompt Dropout》笔记</title>
      <link>http://localhost:1313/posts/papernotes/better_few-shot_relation_extraction_with_label_prompt_dropout/</link>
      <pubDate>Sun, 22 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/papernotes/better_few-shot_relation_extraction_with_label_prompt_dropout/</guid>
      <description>&lt;h2 id=&#34;link&#34;&gt;Link&lt;/h2&gt;
&lt;p&gt;[&lt;a href=&#34;https://arxiv.org/abs/2210.13733&#34;&gt;2210.13733] Better Few-Shot Relation Extraction with Label Prompt Dropout (arxiv.org)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Accepted EMNLP 2022.&lt;/p&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;
&lt;p&gt;在这项工作中，我们提出了一种称为标签提示丢弃（&lt;strong&gt;L&lt;/strong&gt;abel &lt;strong&gt;P&lt;/strong&gt;rompt &lt;strong&gt;D&lt;/strong&gt;ropout, LPD）的新方法。我们直接将文本标签和上下文句子连接在一起，并将它们一起输入到 Transformer Encoder 中。文本标签作为标签提示，通过自注意力机制引导和规范 Transformer Encoder 输出标签感知的关系表示。在训练过程中，我们随机丢弃提示标记，使模型必须学会在有和没有关系描述的情况下工作。实验表明，我们的方法在两个标准的FSRE数据集上取得了显著的改进。我们进行了广泛的消融研究，以证明我们方法的有效性。此外，我们强调了先前研究工作评估设置中的一个潜在问题，即预训练数据中包含的关系类型实际上与测试集中的关系类型重叠。我们认为这对于少样本学习来说可能不是一个理想的设置，并表明现有工作的性能提升可能部分归因于这种“知识泄漏”问题。我们建议过滤掉预训练数据中所有重叠的关系类型，并进行更严格的少样本评估。总之，我们做出了以下贡献：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;我们提出了 LPD，一种新的标签提示丢弃方法，使 FSRE 中的文本标签得到了更好的利用。这种简单的设计显著优于以前使用复杂网络结构将文本标签和上下文句子融合的方法。&lt;/li&gt;
&lt;li&gt;我们识别了文献中先前实验设置的局限性，并提出了一个更严格的FSRE评估设置。对于这两种设置，我们都显示出比以前的最先进方法更强的改进。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;related-work&#34;&gt;Related Work&lt;/h2&gt;
&lt;h3 id=&#34;few-shot-relation-extraction&#34;&gt;Few-Shot Relation Extraction&lt;/h3&gt;
&lt;h3 id=&#34;prompt-based-fine-tuning&#34;&gt;Prompt-Based Fine-Tuning&lt;/h3&gt;
&lt;p&gt;基于提示的模型在小样本和零样本学习中表现出色。这一研究方向的模型尝试将下游微调任务与预训练的掩码语言建模目标对齐，以更好地利用预训练语言模型的潜在知识。&lt;/p&gt;
&lt;p&gt;然而，与许多其他自然语言处理任务（如二元情感分析中的“正面/负面”）的标签语义直观不同，关系抽取中的关系类型可能非常复杂，通常需要较长的句子来描述。例如，FewRel 中的关系 P2094 被描述为“由监管机构进行的官方分类，主体（事件、团队、参与者或设备）符合纳入标准”。基于提示的模型在这种情况下会遇到困难，因为它们需要固定的模板（例如，提示模板中的 [MASK] 令牌数量必须固定）。以前的方法不得不依赖手动设计的提示模板，并使用关系名称而不是关系描述。&lt;/p&gt;
&lt;p&gt;为了解决这个问题，我们提出直接使用整个关系描述作为提示，而不使用任何掩码令牌。在传统的基于提示的模型中，提示用于创建自然描述，以便模型可以在 [MASK] 位置进行更好的预测，而本研究中使用的标签提示通过自然描述来帮助规范模型输出更好的类别表示。&lt;/p&gt;
&lt;h2 id=&#34;approach&#34;&gt;Approach&lt;/h2&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/PaperNotes/Better_Few-Shot_Relation_Extraction_with_Label_Prompt_Dropout/img1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;h3 id=&#34;training-with-label-prompt-dropout&#34;&gt;Training with Label Prompt Dropout&lt;/h3&gt;
&lt;p&gt;对于每个支持实例，我们直接将关系描述和上下文句子用“:”连接起来。例如，句子“北京举办了2022年冬季奥运会”将变成“事件地点: 北京举办了2022年冬季奥运会。” 这个想法是创建一个自然的实例，其中定义首先给出，然后是例子。关系描述和冒号作为标签提示，引导 Transformer Encoder 输出一个标签感知的关系表示。为了防止模型完全依赖标签提示而忽略上下文句子，标签提示会以 $α_{train}$ 的概率随机丢弃。例如，上图中的支持实例“十进制数最早在印度发展起来”保持其初始形式，因为其标签提示被丢弃了。对于查询实例，我们直接输入句子而不带任何标签提示。这是因为查询集本质上与测试集相同，我们不应假设可以访问真实知识。随后，使用特殊实体标记来标记头部和尾部，并在句子的前后添加特殊的分类和分隔标记，例如“[CLS] 事件地点: [E1] 北京 [/E1] 举办了 [E2] 2022年冬季奥运会 [/E2]。” 解析后的句子然后被送入Transformer Encoder。&lt;/p&gt;</description>
    </item>
    <item>
      <title>《Making Pre-trained Language Models Better Continual Few-Shot Relation Extractors》笔记</title>
      <link>http://localhost:1313/posts/papernotes/making_pre-trained_language_models_better_continual_few-shot_relation_extractors/</link>
      <pubDate>Fri, 20 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/papernotes/making_pre-trained_language_models_better_continual_few-shot_relation_extractors/</guid>
      <description>&lt;h2 id=&#34;link&#34;&gt;Link&lt;/h2&gt;
&lt;p&gt;[&lt;a href=&#34;https://arxiv.org/abs/2402.15713&#34;&gt;2402.15713] Making Pre-trained Language Models Better Continual Few-Shot Relation Extractors (arxiv.org)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Accepted COLING 2024&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;COLING: CCF B&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;
&lt;p&gt;关系抽取是自然语言处理领域中的一个基本且重要的任务，旨在从句子或文档中提取实体之间的潜在关系。传统的 RE 方法在大量标注样本上训练模型，然后在具有相同标签空间的数据上进行测试。然而，在现实生活中，新关系不断涌现，这些模型在适应新关系时可能会出现显著的性能下降。此外，这些模型严重依赖于大量标注数据，这需要大量时间和精力来收集。&lt;/p&gt;
&lt;p&gt;因此，提出了&lt;strong&gt;持续少样本关系抽取（Continual Few-shot Relation Extraction, CFRE）&lt;/strong&gt;，其目标是在有限的标注数据约束下，持续学习新关系的同时保留先前学习的关系知识。这一实际任务带来了两个重大挑战：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;灾难性遗忘&lt;/strong&gt;：模型在学习新任务时突然忘记从前任务中获得的知识。最新研究指出，即使在大型语言模型中也存在灾难性遗忘问题，这使得这一问题值得研究。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;过拟合&lt;/strong&gt;：模型在训练数据上表现异常好，但由于拟合噪声或无关模式，无法有效泛化到未见数据，这在训练数据稀少的低资源场景中更为明显。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;总结一下，我们的主要贡献包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;我们利用提示学习来探索预训练语言模型（PLM）的隐含能力，并提出了 &lt;strong&gt;C&lt;/strong&gt;ontrastive &lt;strong&gt;P&lt;/strong&gt;rompt &lt;strong&gt;L&lt;/strong&gt;earning framework (CPL) 框架，将其与一种新的基于边际的对比学习目标（CFRL）结合起来，同时缓解灾难性遗忘和过拟合问题。&lt;/li&gt;
&lt;li&gt;我们通过利用大型语言模型（LLM）的力量引入了一种记忆增强策略，以提升较小的 PLM。这种策略使用精心设计的提示来指导 ChatGPT 生成样本，从而更好地对抗过拟合。&lt;/li&gt;
&lt;li&gt;在两个 RE 基准上的大量实验表明，我们的方法优于最先进的模型，证明了缓解灾难性遗忘和过拟合的有效性。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;related-work&#34;&gt;Related Work&lt;/h2&gt;
&lt;h3 id=&#34;continual-learning&#34;&gt;Continual Learning&lt;/h3&gt;
&lt;p&gt;持续学习（Continual Learning, CL）旨在从一系列任务中不断学习新知识，同时避免遗忘旧知识。CL的主要挑战是灾难性遗忘。&lt;/p&gt;
&lt;p&gt;现有的CL方法分为三类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;正则化方法&lt;/strong&gt;：使用额外的约束来限制参数更新，使模型能够记住更多旧知识。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;动态架构方法&lt;/strong&gt;：动态扩展模型架构，以在任务序列不断出现时存储新知识。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;基于记忆的方法&lt;/strong&gt;：存储当前任务的一些典型样本，并在学习任务序列后重放记忆以复习旧知识。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在这些方法中，基于记忆的方法在自然语言处理（NLP）任务中最为有效。然而，新任务的数据并不总是充足的，而且获取高质量数据往往既昂贵又耗时。我们也采用基于记忆的策略，但我们更注重如何更好地利用预训练语言模型（PLMs）来解决 CFRE。&lt;/p&gt;
&lt;h3 id=&#34;prompt-learning&#34;&gt;Prompt Learning&lt;/h3&gt;
&lt;p&gt;提示学习随着GPT-3系列的诞生而出现，并在自然语言处理任务中取得了显著的性能，尤其是在小样本场景中。它通过添加提示词将下游任务重新表述为预训练任务，并引导预训练语言模型（PLMs）理解各种任务。之前的提示学习方法可以分为三类：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;硬提示&lt;/strong&gt;：在句子中添加手工制作的提示词，并将其转换为掩码语言建模问题。尽管有效，但它需要针对不同任务的复杂专家知识，这既繁琐又耗时。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;软提示&lt;/strong&gt;：在句子中添加可连续训练的向量，这些向量可以被模型自动学习。然而，在没有任何先验专家知识的情况下，模型并不总能学到合适的提示，尤其是在低资源场景中。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;混合提示&lt;/strong&gt;：结合不可调的硬提示和可调的软提示，使模型能够在少量人工干预下轻松学习合适的模板。它被验证为最有效的方法。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;我们专注于少样本设置，并采用混合提示来帮助预训练语言模型（PLMs）缓解灾难性遗忘和过拟合问题。&lt;/p&gt;
&lt;h2 id=&#34;method&#34;&gt;Method&lt;/h2&gt;
&lt;h3 id=&#34;framework-overview&#34;&gt;Framework Overview&lt;/h3&gt;
&lt;p&gt;整个 CPL 框架有三个模块：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Prompt Representation，Contrastive Learning，Memory Augmentation&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/PaperNotes/Making_Pre-trained_Language_Models_Better_Continual_Few-Shot_Relation_Extractors/img1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;</description>
    </item>
    <item>
      <title>《Efficient Information Extraction in Few-Shot Relation Classification through Contrastive Representation Learning》笔记</title>
      <link>http://localhost:1313/posts/papernotes/efficient_information_extraction_in_few-shot_relation_classification_through_contrastive_representation_learning/</link>
      <pubDate>Thu, 19 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/papernotes/efficient_information_extraction_in_few-shot_relation_classification_through_contrastive_representation_learning/</guid>
      <description>&lt;h2 id=&#34;link&#34;&gt;Link&lt;/h2&gt;
&lt;p&gt;[&lt;a href=&#34;https://arxiv.org/abs/2403.16543&#34;&gt;2403.16543] Efficient Information Extraction in Few-Shot Relation Classification through Contrastive Representation Learning (arxiv.org)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Accepted NAACL 2024.&lt;/p&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;
&lt;p&gt;关系分类（Relation Classification, RC）是关系抽取中的一个重要子任务，主要关注在给定文本上下文中识别实体对之间的关系类型。为了实现这一目标，RC 模型必须从句子中提取丰富的信息，包括上下文线索、实体属性和关系特征。虽然语言模型在提取文本表示方面重要，但它们在句子表示中的向量空间使用并不理想。为了改进这一点，最近的研究通过各种技术增强了句子表示。&lt;/p&gt;
&lt;p&gt;关系抽取在许多关系类型上面临数据有限的挑战，并且数据获取成本不成比例。为了解决这一挑战，通过小样本 RC 训练模型以快速适应新关系类型，仅使用少量标记示例。&lt;/p&gt;
&lt;p&gt;由于区分各种关系类型的内在复杂性，RC 应用通常将实体标记令牌的表示作为句子表示。最近的工作在少样本 RC 中使用对比学习以获得更具辨别力的表示。此外，研究表明，通过提示使用 [MASK] 令牌表示句子可以改善句子表示。&lt;/p&gt;
&lt;p&gt;本文贡献如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;新方法&lt;/strong&gt;：我们引入了一种使用对比学习对齐多重表示的方法，用于小样本关系分类。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;适应性&lt;/strong&gt;：我们的方法能够适应各种资源限制，并扩展到包括关系描述在内的额外信息源。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;资源效率&lt;/strong&gt;：我们强调了该方法的资源效率，提升了在低资源环境下的性能。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;实体标记：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;实体标记技术通过在输入句子中添加标记来指示文本中的实体。例如，句子“他在2006年世界杯上为墨西哥效力”可以被标记为“他在[E1S]2006年世界杯[E1E]上为[E2S]墨西哥[E2E]效力”。&lt;/li&gt;
&lt;li&gt;在 BERT 编码器中，句子的表示是通过连接实体开始标记的表示来构建的。这种方法增强了模型对实体及其关系的理解。&lt;/li&gt;
&lt;li&gt;这种技术有助于模型更好地捕捉句子中的上下文线索、实体属性和关系特征，从而提高关系分类的准确性。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;对比学习：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对比学习是一种用于增强模型表示能力的方法，特别是在少样本关系分类任务中。&lt;/li&gt;
&lt;li&gt;对比学习的主要目标是使相似的样本在表示空间中更接近，而使不相似的样本更远离。&lt;/li&gt;
&lt;li&gt;在训练过程中，对比学习会创建正样本对（相似样本）和负样本对（不相似样本），并通过优化模型使正样本对的表示更接近，负样本对的表示更远。而表现在损失函数中，对比学习的损失函数旨在最大化同一输入句子不同表示之间的相似性，同时最小化不同输入句子表示之间的相似性。&lt;/li&gt;
&lt;li&gt;在少样本关系分类中，对比学习通过对齐多个句子表示（如[CLS]标记、[MASK]标记和实体标记）来提取补充的判别信息，从而提高模型在低资源环境中的表现。&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;approach&#34;&gt;Approach&lt;/h2&gt;
&lt;p&gt;方法一览：&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/PaperNotes/Efficient_Information_Extraction_in_Few-Shot_Relation_Classification_through_Contrastive_Representation_Learning/img1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;h3 id=&#34;sentence-representations&#34;&gt;Sentence Representations&lt;/h3&gt;
&lt;p&gt;使用了&lt;strong&gt;平均池化&lt;/strong&gt;从BERT编码器生成各种句子表示。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通过平均 token 表示来计算句子表示。同时，BERT-Base 编码器预训练期间使用 [CLS] 标记作为句子表示，捕捉整个输入序列的信息。实体标记技术通过在文本中标记实体来增强输入句子。这将输入增强为 $x = [x_0, …, [E1S], x_i, [E1E], …, x_n]$ 。句子表示通过连接实体开始标记表示 [E1S] 和 [E2S] 构建。&lt;/li&gt;
&lt;li&gt;在 Prompt 方法中，RC 任务被重新表述为掩码语言建模问题。使用模板 T，每个输入被转换为包含至少一个 [MASK] 标记的 $x_{prompt} = T(x)$ 。这个掩码标记表示关系标签，并从上下文中预测，例如 $\hat x = [MASK]: x$​ 。&lt;/li&gt;
&lt;li&gt;使用 dropout 掩码生成增强句子表示的方法。由于实体标记表示不适用于关系描述，我们使用提示和[CLS]表示，并使用不同的dropout掩码。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Prompt-Mask Method&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>《Entity Concept-enhanced Few-shot Relation Extraction》笔记</title>
      <link>http://localhost:1313/posts/papernotes/entity_concept-enhanced_few-shot_relation_extraction/</link>
      <pubDate>Wed, 18 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/papernotes/entity_concept-enhanced_few-shot_relation_extraction/</guid>
      <description>&lt;h2 id=&#34;link&#34;&gt;Link&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2106.02401&#34;&gt;2106.02401 (arxiv.org)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Accepted ACL 2021。&lt;/p&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;
&lt;p&gt;小样本关系抽取（FSRE）大致可以分为两类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;仅使用纯文本数据，不包含外部信息。如：Siamese、Prototypical、BERT-PAIR&lt;/li&gt;
&lt;li&gt;引入外部信息，以补偿 FSRE 的信息不足，如：TD-Proto&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;虽然引入文本描述的知识可以为 FSRE 提供外部信息并实现最先进的性能，但 TD-Proto 仅为每个实体引入一个 Wikidata 中的文本描述。然而，这可能会因为实体和文本描述之间的不匹配而导致性能下降。此外，由于每个实体的文本描述通常较长，提取长文本描述中最有用的信息并不容易。&lt;/p&gt;
&lt;p&gt;与长文本描述相比，概念是对实体的直观和简洁的描述，可以从概念数据库（如 YAGO3、ConceptNet 和 Concept Graph 等）中轻松获得。此外，概念比每个实体的具体文本描述更抽象，这是对 FSRE 场景中有限信息的理想补充。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/PaperNotes/Entity_Concept-enhanced_Few-shot_Relation_Extraction/img1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;为了应对上述挑战，我们提出了一种新的实体概念增强的少样本关系抽取方案（&lt;strong&gt;CONCEPT&lt;/strong&gt;-enhanced &lt;strong&gt;FE&lt;/strong&gt;w-shot &lt;strong&gt;R&lt;/strong&gt;elation &lt;strong&gt;E&lt;/strong&gt;xtraction，&lt;strong&gt;ConceptFERE&lt;/strong&gt;），该方案引入实体概念以提供有效的关系预测线索。首先，如上表所示，一个实体可能有多个来自不同方面或层次的概念，只有一个概念可能对最终的关系分类有价值。因此，我们设计了一个概念-句子注意力模块，通过比较句子和每个概念的语义相似性来选择最合适的概念。其次，由于句子嵌入和预训练的概念嵌入不是在同一语义空间中学习的，我们采用自注意力机制对句子和选定概念进行词级语义融合，以进行最终的关系分类。&lt;/p&gt;
&lt;h2 id=&#34;model&#34;&gt;Model&lt;/h2&gt;
&lt;p&gt;下图为 ConceptFERE 的结构。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/PaperNotes/Entity_Concept-enhanced_Few-shot_Relation_Extraction/img2.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;h3 id=&#34;system-overview&#34;&gt;System Overview&lt;/h3&gt;
&lt;p&gt;Sentence Representation Module 使用 BERT 作为 Encoder 来获取 Sentence Embedding，Concept Representation Module 使用 skip-grim 在 Wikipedia 文本和概念图上学习概念的表示，得到 Concept Embedding 。Relation Classifier 采用全连接层实现。&lt;/p&gt;
&lt;h3 id=&#34;concept-sentence-attention-module&#34;&gt;Concept-Sentence Attention Module&lt;/h3&gt;
&lt;p&gt;直观上，需要更多关注与句子语义相关度高的概念，这些概念可以为关系抽取提供更有效的线索。&lt;/p&gt;
&lt;p&gt;首先，由于预训练的 Sentence Embedding $v_s$ 和 Concept Embedding  $v_c$ 不是在同一语义空间中学习的，因此不能直接比较语义相似度。所以通过将 $v_c$ 和 $v_s$ 乘以投影矩阵 $P$ 来进行语义转换，以在同一语义空间中获得它们的表示 $v_cP$ 和 $v_sP$ ，其中 $P$ 可以通过全连接网络学习。其次，通过计算句子和每个实体概念之间的语义相似度，得到 $v_c$ 和 $v_s$ 的点积作为相似度 $sim_{cs}$ 。最后，为了从计算的相似度值中选择合适的概念，我们设计了 01-GATE 。相似度值通过 Softmax 函数归一化。如果 $sim_{cs}$ 小于设定的阈值 $α$，01-GATE 将为相应概念的注意力分数分配 0，该概念将在后续的关系分类中被排除。我们选择注意力分数为 1 的合适概念，作为参与关系预测的有效线索。&lt;/p&gt;</description>
    </item>
    <item>
      <title>RAPL: A Relation-Aware Prototype Learning Approach for Few-Shot Document-Level Relation Extraction</title>
      <link>http://localhost:1313/posts/papernotes/rapl/</link>
      <pubDate>Tue, 17 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/papernotes/rapl/</guid>
      <description>&lt;h2 id=&#34;link&#34;&gt;Link&lt;/h2&gt;
&lt;p&gt;[&lt;a href=&#34;https://arxiv.org/abs/2310.15743&#34;&gt;2310.15743] RAPL: A Relation-Aware Prototype Learning Approach for Few-Shot Document-Level Relation Extraction (arxiv.org)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Accepted EMNLP 2023.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;EMNLP：CCF B&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;related-works&#34;&gt;Related Works&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;这一部分内容本来是在论文的最后面，但是考虑到这篇论文也算是打开了新世界的大门，所以把这个放在最前面。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;关系抽取（Relation Extraction，RE）大致可以分为三种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;语句级 RE（Sentence-Level RE）&lt;/strong&gt;：早期的研究主要集中在预测单个句子内两个实体之间的关系。各种基于模式和神经网络的方法在句子级关系抽取上取得了令人满意的结果。然而，句子级关系抽取在抽取范围和规模上有显著的局限性。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;可以说是早期的 RE 大多是这一类别。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;文档级 RE  （Document-Level RE，DocRE）&lt;/strong&gt;：现有的大多数文档级关系抽取研究都基于数据驱动的监督场景，通常分为基于图和基于序列的方法。基于图的方法通常通过图结构抽象文档，并使用图神经网络进行推理。基于序列的方法则使用仅包含变压器的架构来编码长距离的上下文依赖关系。这两类方法在文档级关系抽取中都取得了令人印象深刻的结果。然而，这些方法对大规模标注文档的依赖使得它们难以适应低资源场景。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;小样本文档级 RE （Few-Shot Document-Level RE，FSDLRE）&lt;/strong&gt;：为了应对现实世界文档级关系抽取场景中普遍存在的数据稀缺问题，&lt;a href=&#34;https://aclanthology.org/2022.naacl-main.421/&#34;&gt;Popovic等&lt;/a&gt;将文档级关系抽取任务形式化为小样本学习任务。为了完成这一任务，他们提出了多种基于度量的模型，这些模型建立在最先进的监督文档级关系抽取方法和少样本句子级关系抽取方法的基础上，旨在解决不同任务设置的问题。有效的基于度量的少样本文档级关系抽取方法的每个类别的原型应该准确捕捉相应的关系语义。然而，由于现有方法的粗粒度关系原型学习策略和”一刀切”的 NOTA 原型学习策略，这对现有方法来说是一个挑战。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;术语解释：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;原型学习（Prototype-Based Learning）是一种通过存储一组代表性样本（原型）来进行分类、回归或聚类的学习方法。原型学习的主要步骤包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;选择原型&lt;/strong&gt;：从训练数据中选择一组代表性的样本作为原型。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;计算距离&lt;/strong&gt;：使用距离度量（如欧氏距离、曼哈顿距离等）来确定测试样本与原型之间的相似性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;分类或聚类&lt;/strong&gt;：将测试样本分配给最接近的原型，从而确定其所属的类别或簇。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;NOTA Prototype&lt;/strong&gt; 在本文中指的是 &lt;strong&gt;“None-Of-The-Above”&lt;/strong&gt; 原型，用于处理那些不属于任何目标关系类型的实体对。以下是其主要特点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;任务特定&lt;/strong&gt;：每个任务生成特定的 NOTA 原型，以更好地捕捉该任务中的 NOTA 语义。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;基础原型&lt;/strong&gt;：引入一组可学习的基础 NOTA 原型，这些原型需要在每个任务中进一步修正。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;支持实例选择&lt;/strong&gt;：从支持文档中选择 NOTA 实例，并将其与基础NOTA原型融合，生成最终的任务特定NOTA 原型。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;语义捕捉&lt;/strong&gt;：通过这种方法，NOTA 原型不仅包含了元学习的通用知识，还能捕捉每个任务中的特定NOTA 语义。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;
&lt;p&gt;FSDLRE 任务的简单描述：&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/PaperNotes/RAPL/img1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;</description>
    </item>
    <item>
      <title>《计组KG》课题开发过程（二）</title>
      <link>http://localhost:1313/posts/dailydev/%E8%AE%A1%E7%BB%84kg%E8%AF%BE%E9%A2%98%E5%BC%80%E5%8F%91%E8%BF%87%E7%A8%8B%E4%BA%8C/</link>
      <pubDate>Sat, 14 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/dailydev/%E8%AE%A1%E7%BB%84kg%E8%AF%BE%E9%A2%98%E5%BC%80%E5%8F%91%E8%BF%87%E7%A8%8B%E4%BA%8C/</guid>
      <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;自从上次记录已经过去了一个月，整个课题进展不大。原因一个是暑期有点摆，另一个是关系抽取确实比较繁琐。不管怎么说，来记录下吧。&lt;/p&gt;
&lt;h2 id=&#34;ner-数据集下的模型训练&#34;&gt;NER 数据集下的模型训练&lt;/h2&gt;
&lt;p&gt;首先需要声明的是该阶段的模型不参与于最后 KG 的构建，目的仅仅是跑通模型训练、验证的过程，为后续阶段提供便利。&lt;/p&gt;
&lt;h3 id=&#34;ner-数据集&#34;&gt;NER 数据集&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;该部分信息在完成 RE 部分后可能会发生些微变动，仅作参考，后续会做调整。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;共标记5147条中文语句，实体共标注1472个。&lt;/p&gt;
&lt;p&gt;下面是各个标签下的数量统计：&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;&lt;strong&gt;Label&lt;/strong&gt;&lt;/th&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;&lt;strong&gt;Count&lt;/strong&gt;&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;TECH&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;388&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;COMP&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;382&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;STOR&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;170&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;DATA&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;133&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;INST&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;105&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;ARCH&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;71&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;IO&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;61&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;PERF&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;54&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;PROG&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;52&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;CORP&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;17&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;ALG&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;16&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;PROT&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;15&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;PER&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;4&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;GRP&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;4&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;模型选择&#34;&gt;模型选择&lt;/h3&gt;
&lt;p&gt;模型有两大类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;传统深度学习方法
&lt;ul&gt;
&lt;li&gt;CNN-CRF&lt;/li&gt;
&lt;li&gt;BiLSTM-CRF&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;BERT 系预训练模型，输出层为 CRF 或 MLP+Softmax
&lt;ul&gt;
&lt;li&gt;BERT：BERT 是一个双向 Transformer 模型，通过掩码语言模型（Masked Language Model, MLM）和下一句预测（Next Sentence Prediction, NSP）任务进行预训练&lt;/li&gt;
&lt;li&gt;RoBERTa：RoBERTa 是对 BERT 的优化版本，移除了 NSP 任务，并采用了动态掩码策略&lt;/li&gt;
&lt;li&gt;ALBERT：ALBERT 是 BERT 的轻量级版本，通过参数共享和嵌入参数因子化来减少模型大小&lt;/li&gt;
&lt;li&gt;XLM-RoBERTa：XLM-RoBERTa 是针对多语言的预训练模型，基于 RoBERTa 和 XLM 的结合&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这里选择的是 XLM-RoBERTa，预训练模型选择的是 &lt;a href=&#34;https://huggingface.co/FacebookAI/xlm-roberta-large-finetuned-conll03-english&#34;&gt;FacebookAI/xlm-roberta-large-finetuned-conll03-english · Hugging Face&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>《计组KG》课题开发番外：关系抽取的思考过程</title>
      <link>http://localhost:1313/posts/dailydev/%E8%AE%A1%E7%BB%84kg%E8%AF%BE%E9%A2%98%E5%BC%80%E5%8F%91%E7%95%AA%E5%A4%96%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E7%9A%84%E6%80%9D%E8%80%83%E8%BF%87%E7%A8%8B/</link>
      <pubDate>Sat, 24 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/dailydev/%E8%AE%A1%E7%BB%84kg%E8%AF%BE%E9%A2%98%E5%BC%80%E5%8F%91%E7%95%AA%E5%A4%96%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E7%9A%84%E6%80%9D%E8%80%83%E8%BF%87%E7%A8%8B/</guid>
      <description>&lt;h2 id=&#34;现状&#34;&gt;现状&lt;/h2&gt;
&lt;p&gt;目前课题进行到了关系抽取这一步。在看完之前的RE综述后，我决定整一个 Joint 的 NER+RE 模型。目前已经完成了 NER 的标注工作，下一步工作自然就是 RE 的标注。但是 RE 的标注要比 NER 要困难的多，一个是对于关系的定义依赖于实体类型、句子词性等多种复杂要素，二是手工标注势必工作量巨大。所以 RE 的标注有什么解决方法呢？&lt;/p&gt;
&lt;p&gt;我决定把整个思考过程记录下来，方便复盘。&lt;/p&gt;
&lt;h2 id=&#34;相关开源库&#34;&gt;相关开源库&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/thunlp/OpenNRE&#34;&gt;thunlp/OpenNRE：用于神经关系提取 （NRE） 的开源包 (github.com)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/SapienzaNLP/relik?tab=readme-ov-file&#34;&gt;SapienzaNLP/relik：检索、读取和 LinK：学术预算上的快速准确的实体链接和关系提取 （ACL 2024） (github.com)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/huggingface/setfit&#34;&gt;huggingface/setfit：使用句子转换器进行高效的少样本学习 (github.com)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/EleutherAI/lm-evaluation-harness&#34;&gt;EleutherAI/lm-evaluation-harness：一种用于语言模型小样本评估的框架。 (github.com)&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;关系抽取的可能方案&#34;&gt;关系抽取的可能方案&lt;/h2&gt;
&lt;p&gt;首先能想到的两种常见方案：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用 RE 预训练模型预标注：和 NER 的标注工作流程一致，但是中文 RE 预训练模型很难找&lt;/li&gt;
&lt;li&gt;远程监督：使用已有的知识库或实体关系词典，对大规模文本进行远程监督标注。但是不适合当前课题的小规模数据集，而且没有现成的大量 RE 标注数据&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以上两种方案中只有预训练模型的预标注还算可行，那有没有什么方法可以加速这一过程？可以看看下面的两种方法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;半监督学习：结合少量人工标注数据和大量未标注数据，通过半监督学习的方法训练模型&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;few-shot 小样本学习：使用少量人工标注的数据对few-shot模型进行训练，以提高模型在少样本情况下的泛化能力&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这两种方案值得单独进行介绍。&lt;/p&gt;
&lt;h3 id=&#34;半监督学习&#34;&gt;半监督学习&lt;/h3&gt;
&lt;p&gt;半监督学习（Semi-Supervised Learning）是一种结合了监督学习和无监督学习的机器学习方法。它利用少量的标记数据和大量的未标记数据来训练模型，从而提高模型的泛化能力和性能。&lt;/p&gt;
&lt;p&gt;半监督学习的样本标注依赖假设，以下是部分常见假设：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;平滑性假设：如果两个数据点在高密度区域中且距离很近，那么它们的输出也应该相似&lt;/li&gt;
&lt;li&gt;聚类假设：如果数据点形成簇，那么同一簇中的数据点应该属于同一类&lt;/li&gt;
&lt;li&gt;流形假设：高维数据通常位于低维流形上，同一流形上的数据点具有相同的标签&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;常用的方法有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一致性正则化：假设对未标记数据加入小扰动后，其分类结果不应改变&lt;/li&gt;
&lt;li&gt;伪标签：使用已标记数据训练初始模型，然后用该模型对未标记数据进行预测，生成伪标签，再将这些伪标签数据加入训练集中进行再训练&lt;/li&gt;
&lt;li&gt;生成式模型：利用生成模型（如GANs）从数据分布中生成样本，并将这些样本用于训练分类器&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;优势：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;利用未标注数据，提高模型的泛化能力和性能&lt;/li&gt;
&lt;li&gt;较低标注成本&lt;/li&gt;
&lt;li&gt;适应性强，可以应用于多种任务&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;缺点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;依赖数据假设：半监督学习通常假设未标记数据和标记数据在特征空间中具有相似性，这在实际应用中并不总是成立。如果这些假设不成立，可能会导致模型性能下降&lt;/li&gt;
&lt;li&gt;标签传播误差&lt;/li&gt;
&lt;li&gt;数据不平衡问题&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我曾经在 kaggle 比赛中使用过半监督学习中的伪标签方法，只从工程实现的角度看比较容易，但是模型性能不一定有提升。&lt;/p&gt;</description>
    </item>
    <item>
      <title>BPE算法</title>
      <link>http://localhost:1313/posts/nlp/bpe/</link>
      <pubDate>Sat, 17 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/nlp/bpe/</guid>
      <description>&lt;h2 id=&#34;基本概念&#34;&gt;基本概念&lt;/h2&gt;
&lt;p&gt;Byte-Pair Encoding (BPE) 是一种常用于自然语言处理（NLP）的分词算法。BPE最初是一种数据压缩算法，由Philip Gage在1994年提出。在NLP中，BPE被用来将文本分割成子词（subword）单元，这样可以在处理未见过的单词时更有效。&lt;/p&gt;
&lt;h2 id=&#34;工作原理&#34;&gt;工作原理&lt;/h2&gt;
&lt;p&gt;BPE的核心思想是通过多次迭代，将最常见的字符对（或子词对）合并成一个新的符号，直到词汇表达到预定的大小。具体步骤如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;初始化词汇表&lt;/strong&gt;：将所有单个字符作为初始词汇表。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;统计频率&lt;/strong&gt;：统计所有相邻字符对的出现频率。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;合并字符对&lt;/strong&gt;：找到出现频率最高的字符对，并将其合并成一个新的符号。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;更新词汇表&lt;/strong&gt;：将新的符号加入词汇表，并更新文本中的所有相应字符对。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;重复步骤2-4&lt;/strong&gt;：直到词汇表达到预定大小。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;例子&#34;&gt;例子&lt;/h2&gt;
&lt;p&gt;假设我们有一个简单的文本：“banana banana”. 初始词汇表为：{b, a, n, }. 具体步骤如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;初始化&lt;/strong&gt;：词汇表为 {b, a, n, }。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;统计频率&lt;/strong&gt;：统计相邻字符对的频率，如 “ba” 出现2次，“an” 出现2次，“na” 出现2次。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;合并字符对&lt;/strong&gt;：选择频率最高的字符对 “an”，将其合并成一个新符号 “an”。更新后的文本为 “b an an a b an an a”。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;更新词汇表&lt;/strong&gt;：词汇表更新为 {b, a, n, an}。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;重复步骤2-4&lt;/strong&gt;：继续统计频率并合并，直到词汇表达到预定大小。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;byte-level-bpe&#34;&gt;Byte-Level BPE&lt;/h2&gt;
&lt;p&gt;在处理多语言文本时，BPE的一个问题是字符集可能会非常大。为了解决这个问题，可以使用Byte-Level BPE。Byte-Level BPE将每个字节视为一个字符，这样基础字符集的大小固定为256（即所有可能的字节值）。&lt;/p&gt;
&lt;h2 id=&#34;优缺点&#34;&gt;优缺点&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;优点&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;处理未见过的单词&lt;/strong&gt;：通过将单词分割成子词，可以更好地处理未见过的单词&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;词汇表大小可控&lt;/strong&gt;：可以通过设置预定大小来控制词汇表的大小&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;缺点&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;语义信息丢失&lt;/strong&gt;：在某些情况下，分割后的子词可能会丢失部分语义信息&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;计算复杂度&lt;/strong&gt;：多次迭代合并字符对的过程可能会增加计算复杂度&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Lecture 10: Pretrained Model</title>
      <link>http://localhost:1313/posts/cs224n/lesson_10/</link>
      <pubDate>Fri, 16 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/cs224n/lesson_10/</guid>
      <description>第十讲：预训练模型</description>
    </item>
    <item>
      <title>《实体关系抽取方法研究综述》笔记</title>
      <link>http://localhost:1313/posts/papernotes/%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E6%96%B9%E6%B3%95%E7%A0%94%E7%A9%B6%E7%BB%BC%E8%BF%B0_%E6%9D%8E%E5%86%AC%E6%A2%85/</link>
      <pubDate>Wed, 14 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/papernotes/%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E6%96%B9%E6%B3%95%E7%A0%94%E7%A9%B6%E7%BB%BC%E8%BF%B0_%E6%9D%8E%E5%86%AC%E6%A2%85/</guid>
      <description>&lt;h2 id=&#34;关系抽取-relation-extraction&#34;&gt;关系抽取 Relation Extraction&lt;/h2&gt;
&lt;p&gt;定义：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通常将实体间的关系形式化地描述为关系三元组 $\{E_1,R,E_2\}$ ，其中 $E$ 为实体类型，$R$ 为关系描述类型。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;关系抽取与命名实体识别、关系触发词识别构成一个端到端任务的框架：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;命名实体识别 Name Entity Recognition：是指识别文本中具有特定意义的实体，主要包括人名、地名、机构名、专有名词等；&lt;/li&gt;
&lt;li&gt;关系触发词识别 Relation trigger word identification：是指对触发实体关系的词进行分类，识别出是触发词还是非触发词，判定抽取出的关系是正类还是负类。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;关系抽取是一个文本分类问题，相比于情感分类等任物，其具有以下特点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;领域众多，关系模型构建复杂。由于限定了关系类别，可采用基于规则、词典以及本体的方法，也可采用传统机器学习的有监督、半监督以及无监督方法，深度学习的有监督、远程监督方法。这类方法的模型构建难度相对于开放领域难度较低，但是移植性和扩展性较差。而针对开放领域的关系抽取，由于关系类型多样且不确定，可以采用无监督和远程监督等方法&lt;/li&gt;
&lt;li&gt;数据来源广泛，主要有结构化、半结构化、无结构3类。针对表格文档、数据库数据等结构化数据，方法众多，现通常采用深度学习相关的方法等；针对纯文本的无结构数据，由于无法预料全部关系类型，一般采用以聚类为核心的无监督方法等；而针对维基百科、百度百科等半结构化数据，通常采用半监督和远程监督方法等&lt;/li&gt;
&lt;li&gt;关系种类繁多复杂，噪音数据无法避免。实体之间的关系多样，有一种或多种关系，早期方法主要针对一种关系（忽略重叠关系）进行抽取，这类方法忽略了实体间的多种关系，对实体间的潜在关系难以处理。近年来，图结构逐渐应用于关系抽取领域，为关系重叠和实体重叠提供了新思路。而针对噪音数据，有人发现少量对抗样本会避免模型过拟合，提出使用对抗训练提高模型的性能&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;评价指标用 Precision、Recall、F1.&lt;/p&gt;
&lt;h2 id=&#34;基于深度学习的关系抽取方法&#34;&gt;基于深度学习的关系抽取方法&lt;/h2&gt;
&lt;h3 id=&#34;监督学习pipeline&#34;&gt;监督学习：Pipeline&lt;/h3&gt;
&lt;p&gt;常见的模型有CNN、RNN、LSTM/BiLSTM、GCN（图神经网络）、混合抽取（模型融合）。&lt;/p&gt;
&lt;h3 id=&#34;监督学习joint&#34;&gt;监督学习：Joint&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;基于共享参数的方法：命名实体识别和关系抽取通过共享编码层在训练过程中产生的共享参数相互依赖，最终训练得到最佳的全局参数。因此，基于共享参数方法有效地改善了流水线方法中存在的错误累积传播问题和忽视2个子任务间关系依赖的问题，提高模型的鲁棒性&lt;/li&gt;
&lt;li&gt;基于序列标注的方法：由于基于共性参数的方法容易产生信息冗余，因此可以将命名实体识别和实体关系抽取融合成一个序列标注问题，可以同时识别出实体和关系。该方法利用一个端到端的神经网络模型抽取出实体之间的关系三元组，减少了无效实体对模型的影响，提高了关系抽取的召回率和准确率&lt;/li&gt;
&lt;li&gt;基于图结构的方法：针对前2种方法无法解决的实体重叠、关系重叠问题，基于图结构的方法能有效得解决&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;远程监督学习&#34;&gt;远程监督学习&lt;/h3&gt;
&lt;p&gt;远程监督学习（Distant Supervision）是一种基于外部知识的监督学习方法，主要用于自动标注大规模文本数据，以训练关系抽取模型。其核心思想是利用已知的关系图谱（如知识图谱）来标注文本数据。例如，如果两个实体在知识图谱中存在关系，那么包含这两个实体的句子就可以被认为是该关系的正例。&lt;/p&gt;
&lt;p&gt;远程监督的实体关系抽取方法极大地减少了对人工的依赖，可以自动地抽取大量的实体对，从而扩大了知识库的规模。&lt;/p&gt;
&lt;p&gt;然而这类方法在数据标注过程会带来2个问题：噪音数据和抽取特征的误差传播。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;基于远程监督的基本假设，海量数据的实体对的关系会被错误标记，从而产生了噪音数据&lt;/li&gt;
&lt;li&gt;由于利用自然语言处理工具抽取的特征也存在一定的误差，会引起特征的传播误差和错误积累&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;bert&#34;&gt;BERT&lt;/h3&gt;
&lt;h2 id=&#34;基于开放领域的关系抽取方法&#34;&gt;基于开放领域的关系抽取方法&lt;/h2&gt;
&lt;p&gt;由于传统关系抽取基于特定领域、特定关系进行抽取，导致关系抽取这一任务耗时耗力，成本极高，同时不利于扩展语料类型。近年来，针对开放领域的实体关系抽取方法逐渐受到人们的广泛关注。由于互联网不断发展，开放语料的规模不断扩大，并且包含的关系类型愈加复杂，研究者直接面向大多未经人工标注的开放语料进行关系抽取，有利于促进实体关系抽取的发展，而且具有更大的实际意义。&lt;/p&gt;
&lt;p&gt;开放领域关系抽取的方法是信息抽取领域的新的研究方向。该关系抽取方法主要分为半监督和无监督2种，并结合语形特征和语义特征自动地在大规模非限定类型的语料库中进行关系抽取。开放领域关系抽取的方法无需事先人为制定关系类型，减轻了人工标注的负担，而由此设计的系统可移植性较强，极大地促进关系抽取的发展。&lt;/p&gt;
&lt;p&gt;开放领域的关系抽取方法主要有3个流程：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;深层解析小规模的语料集，自动抽取实体间关系三元组，利用朴素贝叶斯分类器训练已标注可信和不可信的关系三元组构建关系表示模型；&lt;/li&gt;
&lt;li&gt;利用关系抽取模型并输入词性、序列等特征等数据，在训练好的分类器上进行大量网络文献的关系抽取，获取候选关系三元组；&lt;/li&gt;
&lt;li&gt;合并候选三元组，通过统计的方法计算各个关系三元组的可信度，并建立索引。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;本文链接&#34;&gt;本文链接&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://crad.ict.ac.cn/fileJSJYJYFZ/journal/article/jsjyjyfz/HTML/2020-7-1424.shtml&#34;&gt;实体关系抽取方法研究综述 (ict.ac.cn)&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>😺 Is All You Need——Transformer补充</title>
      <link>http://localhost:1313/posts/nlp/attention-is-all-you-need/</link>
      <pubDate>Wed, 14 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/nlp/attention-is-all-you-need/</guid>
      <description>&lt;h2 id=&#34;关于本文动机&#34;&gt;关于本文动机&lt;/h2&gt;
&lt;p&gt;Transformer主要内容请见 &lt;a href=&#34;https://kurongtohsaka.github.io/posts/cs224n/lesson_9/&#34;&gt;Lecture 9: Transformer | KurongBlog (kurongtohsaka.github.io)&lt;/a&gt;，对 Transformer 已经进行比较详细的介绍和讲解了，但还是有一些细节问题不好在该篇文章提及，所以单开一篇讨论。&lt;/p&gt;
&lt;h2 id=&#34;qkv-的理解&#34;&gt;Q，K，V 的理解&lt;/h2&gt;
&lt;p&gt;假设我们想让所有的词都与第一个词 $v_1$ 相似，我们可以让 $v_1$ 作为查询。 然后，将该查询与句子中所有词进行点积，这里的词就是键。 所以查询和键的组合给了我们权重，接着再将这些权重与作为值的所有单词相乘。&lt;/p&gt;
&lt;p&gt;通过下面的公式可以理解这个过程，并理解查询、键、值分别代表什么意思：
&lt;/p&gt;
$$
softmax(QK)=W \\
WV=Y
$$&lt;p&gt;
一种比较感性的理解：想要得到某个 $V$ 对应的某个可能的相似信息需要先 $Q$ 这个 $V$ 的 $K$ ，$QK$ 得到注意力分数，之后经过 softmax 平滑后得到概率 $W $，然后 $WV$ 后得到最终的相似信息 $Y$ 。&lt;/p&gt;
&lt;h2 id=&#34;attention-机制&#34;&gt;Attention 机制&lt;/h2&gt;
&lt;p&gt;在数据库中，如果我们想通过查询 $q$ 和键 $k_i$ 检索某个值 $v_i$ 。注意力与这种数据库取值技术类似，但是以概率的方式进行的。&lt;/p&gt;
$$
attention(q,k,v)=\sum_isimilarity(q,k_i)v_i
$$&lt;ul&gt;
&lt;li&gt;注意力机制测量查询 $q$ 和每个键值 $k_i$ 之间的相似性。&lt;/li&gt;
&lt;li&gt;返回每个键值的权重代表这种相似性。&lt;/li&gt;
&lt;li&gt;最后，返回所有值的加权组合作为输出。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;mask-掩码&#34;&gt;Mask 掩码&lt;/h2&gt;
&lt;p&gt;在机器翻译或文本生成任务中，我们经常需要预测下一个单词出现的概率，这类任务我们一次只能看到一个单词。此时注意力只能放在下一个词上，不能放在第二个词或后面的词上。简而言之，注意力不能有非平凡的超对角线分量。&lt;/p&gt;
&lt;p&gt;我们可以通过添加掩码矩阵来修正注意力，以消除神经网络对未来的了解。&lt;/p&gt;
&lt;h2 id=&#34;multi-head-attention-多头注意力机制&#34;&gt;Multi-head Attention 多头注意力机制&lt;/h2&gt;
&lt;p&gt;“小美长得很漂亮而且人还很好” 。这里“人”这个词，在语法上与“小美”和“好”这些词存在某种意义或关联。这句话中“人”这个词需要理解为“人品”，说的是小美的人品很好。仅仅使用一个注意力机制可能无法正确识别这三个词之间的关联，这种情况下，使用多个注意力可以更好地表示与“人”相关的词。这减少了注意力寻找所有重要词的负担，增加找到更多相关词的机会。&lt;/p&gt;
&lt;h2 id=&#34;位置编码&#34;&gt;位置编码&lt;/h2&gt;
&lt;p&gt;在任何句子中，单词一个接一个地出现都蕴含着重要意义。如果句子中的单词乱七八糟，那么这句话很可能没有意义。但是当 Transformer 加载句子时，它不会按顺序加载，而是并行加载。由于 Transformer 架构在并行加载时不包括单词的顺序，因此我们必须明确定义单词在句子中的位置。这有助于 Transformer 理解句子词与词之间的位置。这就是位置嵌入派上用场的地方。位置嵌入是一种定义单词位置的向量编码。在进入注意力网络之前，将此位置嵌入添加到输入嵌入中。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Lecture 9: Transformer</title>
      <link>http://localhost:1313/posts/cs224n/lesson_9/</link>
      <pubDate>Tue, 13 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/cs224n/lesson_9/</guid>
      <description>第九讲：Transformer</description>
    </item>
    <item>
      <title>8.06-8.11：一周总结</title>
      <link>http://localhost:1313/posts/weeklyworking/2024_08_06-2024_08_11/</link>
      <pubDate>Sun, 11 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/weeklyworking/2024_08_06-2024_08_11/</guid>
      <description>&lt;h2 id=&#34;本周工作&#34;&gt;本周工作&lt;/h2&gt;
&lt;p&gt;本周工作是从8月10号vpn重置之后才开始进行的，所以内容有点少&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;完成了第一版训练、验证代码&lt;/li&gt;
&lt;li&gt;调试第一个模型，修复各种bug&lt;/li&gt;
&lt;li&gt;学习 Transformer 相关内容&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;课题下周改进&#34;&gt;课题下周改进&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;先快速训练出几个模型出来，选出一个最好的模型&lt;/li&gt;
&lt;li&gt;进行第二次及多次迭代训练，更新词典&lt;/li&gt;
&lt;li&gt;关系抽取看相关文献&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;本周反思&#34;&gt;本周反思&lt;/h2&gt;
&lt;p&gt;本周算是玩爽了，课题下周尽快开展关系抽取的调研工作。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Encoder-Decoder 架构</title>
      <link>http://localhost:1313/posts/nlp/encoder-decoder/</link>
      <pubDate>Sun, 11 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/nlp/encoder-decoder/</guid>
      <description>&lt;h2 id=&#34;原理&#34;&gt;原理&lt;/h2&gt;
&lt;p&gt;Encoder-Decoder架构通常由两个主要部分组成：编码器（Encoder）和解码器（Decoder）。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;编码器（Encoder）&lt;/strong&gt;：编码器的任务是将输入序列（如一句话）转换为一个固定长度的上下文向量（context vector）。这个过程通常通过递归神经网络（RNN）、长短期记忆网络（LSTM）或门控循环单元（GRU）来实现。编码器逐步读取输入序列的每个元素，并将其信息压缩到上下文向量中。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;解码器（Decoder）&lt;/strong&gt;：解码器接收编码器生成的上下文向量，并将其转换为输出序列。解码器同样可以使用RNN、LSTM或GRU。解码器在生成每个输出元素时，会考虑上下文向量以及之前生成的输出元素。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;作用&#34;&gt;作用&lt;/h2&gt;
&lt;p&gt;Encoder-Decoder架构主要用于处理需要将一个序列转换为另一个序列的任务，例如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;机器翻译&lt;/strong&gt;：将一种语言的句子翻译成另一种语言。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;文本摘要&lt;/strong&gt;：将长文本压缩成简短摘要。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;对话系统&lt;/strong&gt;：生成对用户输入的响应。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;近年来，基于Transformer的Encoder-Decoder架构（如BERT、GPT、T5等）因其更好的性能和并行计算能力，逐渐取代了传统的RNN架构。&lt;/p&gt;
&lt;h2 id=&#34;优缺点&#34;&gt;优缺点&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;优点&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;灵活性&lt;/strong&gt;：可以处理不同长度的输入和输出序列。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;强大的表示能力&lt;/strong&gt;：能够捕捉输入序列中的复杂模式和关系。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;缺点&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;长距离依赖问题&lt;/strong&gt;：传统RNN在处理长序列时可能会遗忘早期的信息。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;计算复杂度高&lt;/strong&gt;：训练和推理过程需要大量计算资源。&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    <item>
      <title>残差连接</title>
      <link>http://localhost:1313/posts/nlp/%E6%AE%8B%E5%B7%AE%E8%BF%9E%E6%8E%A5/</link>
      <pubDate>Sun, 11 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/nlp/%E6%AE%8B%E5%B7%AE%E8%BF%9E%E6%8E%A5/</guid>
      <description>&lt;h2 id=&#34;原理&#34;&gt;原理&lt;/h2&gt;
&lt;p&gt;残差连接（Residual Connection）最早由何凯明等人在2015年提出的 ResNet 中引入。ResNet 通过引入残差块，使得网络可以扩展到更深的层数，并在 ImageNet 比赛中取得了显著的成功。&lt;/p&gt;
&lt;p&gt;残差连接的核心思想是引入跳跃连接，将输入信号直接传递到网络的后续层，从而构建了一条捷径路径。这种结构允许网络学习输入和输出之间的残差，而不是直接学习输出。&lt;/p&gt;
&lt;p&gt;残差连接可以表示为：
&lt;/p&gt;
$$
y=F(x)+x
$$&lt;p&gt;
其中，$x$ 表示输入，$F(x)$ 表示经过非线性变换后的输出。&lt;/p&gt;
&lt;h2 id=&#34;作用&#34;&gt;作用&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;解决梯度消失和梯度爆炸问题&lt;/li&gt;
&lt;li&gt;提高训练效率&lt;/li&gt;
&lt;li&gt;增强模型的泛化性能&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;例子&#34;&gt;例子&lt;/h2&gt;
&lt;p&gt;下图是 Transformer 论文中的模型结构图。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/NLP/img14.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;可以看到在每一个 Attention Layer 中都有一个 &lt;code&gt;Add&lt;/code&gt; ，原输入和 Multi-head 变换后的输出做了一个简单的相加操作，而这就是所谓的残差连接。&lt;/p&gt;</description>
    </item>
    <item>
      <title>《基于MRC的设备故障命名实体识别方法》笔记</title>
      <link>http://localhost:1313/posts/papernotes/%E5%9F%BA%E4%BA%8Emrc%E7%9A%84%E8%AE%BE%E5%A4%87%E6%95%85%E9%9A%9C%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E6%96%B9%E6%B3%95_%E5%BE%90%E9%B9%8F/</link>
      <pubDate>Tue, 06 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/papernotes/%E5%9F%BA%E4%BA%8Emrc%E7%9A%84%E8%AE%BE%E5%A4%87%E6%95%85%E9%9A%9C%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E6%96%B9%E6%B3%95_%E5%BE%90%E9%B9%8F/</guid>
      <description>&lt;h2 id=&#34;mrc&#34;&gt;MRC&lt;/h2&gt;
&lt;p&gt;本论文关于设备故障领域的NER任务，将 NER 的序列标注问题重构为 MRC 问题。&lt;/p&gt;
&lt;p&gt;MRC（Machine Reading Comprehension）机器阅读理解，与文生成和机器翻译任务类似。本论文使用该方法，根堆每个实体类型，设计了相应地自然语言形式的查询，通过上下文的查询来定位并提取实体。例如，针对故障代码 the machine suffers from error[#10482] 的命名实体识别，被形式化为 “文本中提到了哪种故障代码 ” 。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;人话：先通过某个文生成/机器翻译模型将错误代码转化为中文，然后通过预定的错误代码进行映射&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;本文的主要工作如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;将 NER 任务转化为 MRC 问题，采用自然语言查询来实现命名实体的识别。&lt;/li&gt;
&lt;li&gt;通过在查询中集成预设的命名实体类别信息，克服传统方法中实体类别语义信息缺少的限制，提升命名实体识别的准确性。&lt;/li&gt;
&lt;li&gt;结合设备故障数据集的构建，开展相关的实 验对比，并进行定量分析，证明了本文方法的有效性。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;模型结构&#34;&gt;模型结构&lt;/h2&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/PaperNotes/%e5%9f%ba%e4%ba%8eMRC%e7%9a%84%e8%ae%be%e5%a4%87%e6%95%85%e9%9a%9c%e5%91%bd%e5%90%8d%e5%ae%9e%e4%bd%93%e8%af%86%e5%88%ab%e6%96%b9%e6%b3%95_%e5%be%90%e9%b9%8f/img1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;编码层为 ALBERT&lt;/li&gt;
&lt;li&gt;特征提取为 BiLSTM&lt;/li&gt;
&lt;li&gt;分类器为两个sigmoid，分别预测实体的起始索引、结束索引&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;数据集&#34;&gt;数据集&lt;/h2&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/PaperNotes/%e5%9f%ba%e4%ba%8eMRC%e7%9a%84%e8%ae%be%e5%a4%87%e6%95%85%e9%9a%9c%e5%91%bd%e5%90%8d%e5%ae%9e%e4%bd%93%e8%af%86%e5%88%ab%e6%96%b9%e6%b3%95_%e5%be%90%e9%b9%8f/img2.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;h2 id=&#34;对比试验&#34;&gt;对比试验&lt;/h2&gt;
&lt;p&gt;模型为以下几类：&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/PaperNotes/%e5%9f%ba%e4%ba%8eMRC%e7%9a%84%e8%ae%be%e5%a4%87%e6%95%85%e9%9a%9c%e5%91%bd%e5%90%8d%e5%ae%9e%e4%bd%93%e8%af%86%e5%88%ab%e6%96%b9%e6%b3%95_%e5%be%90%e9%b9%8f/img4.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;结果：&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/PaperNotes/%e5%9f%ba%e4%ba%8eMRC%e7%9a%84%e8%ae%be%e5%a4%87%e6%95%85%e9%9a%9c%e5%91%bd%e5%90%8d%e5%ae%9e%e4%bd%93%e8%af%86%e5%88%ab%e6%96%b9%e6%b3%95_%e5%be%90%e9%b9%8f/img3.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;h2 id=&#34;消融实验&#34;&gt;消融实验&lt;/h2&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/PaperNotes/%e5%9f%ba%e4%ba%8eMRC%e7%9a%84%e8%ae%be%e5%a4%87%e6%95%85%e9%9a%9c%e5%91%bd%e5%90%8d%e5%ae%9e%e4%bd%93%e8%af%86%e5%88%ab%e6%96%b9%e6%b3%95_%e5%be%90%e9%b9%8f/img5.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;</description>
    </item>
    <item>
      <title>7.29-8.04：一周总结</title>
      <link>http://localhost:1313/posts/weeklyworking/2024_07_29-2024_08_04/</link>
      <pubDate>Tue, 06 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/weeklyworking/2024_07_29-2024_08_04/</guid>
      <description>&lt;h2 id=&#34;本周任务&#34;&gt;本周任务&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;改进了数据集的标注格式，并更新了词典&lt;/li&gt;
&lt;li&gt;完成 BERT 系、BiLSTM-CRF、CNN-CRF 等模型代码&lt;/li&gt;
&lt;li&gt;第一版训练、验证代码进度50%，但是 vpn 流量过期，需要等到10号以后才能继续训练😅&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;课题下周改进&#34;&gt;课题下周改进&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;完成第一版训练、验证代码&lt;/li&gt;
&lt;li&gt;改进现有模型结构，尽可能地从微调 BERT 的过时手段中走出&lt;/li&gt;
&lt;li&gt;记录实验数据&lt;/li&gt;
&lt;li&gt;继续 cs224n、Transformer 论文学习&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;本周反思&#34;&gt;本周反思&lt;/h2&gt;
&lt;p&gt;本周实在是有太多事，课题进展有限，预计下周会有一定进展。&lt;/p&gt;</description>
    </item>
    <item>
      <title>《计组KG》课题开发过程（一）</title>
      <link>http://localhost:1313/posts/dailydev/%E8%AE%A1%E7%BB%84kg%E8%AF%BE%E9%A2%98%E5%BC%80%E5%8F%91%E8%BF%87%E7%A8%8B%E4%B8%80/</link>
      <pubDate>Thu, 01 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/dailydev/%E8%AE%A1%E7%BB%84kg%E8%AF%BE%E9%A2%98%E5%BC%80%E5%8F%91%E8%BF%87%E7%A8%8B%E4%B8%80/</guid>
      <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;开发该课题也有一个月了，整个过程并不是很顺利，很多细节部分如果没有得到及时梳理，对以后的研究和论文写作也有坏处。基于以上和其他原因，遂决定分阶段进行记录。&lt;/p&gt;
&lt;h2 id=&#34;数据集&#34;&gt;数据集&lt;/h2&gt;
&lt;p&gt;深度学习项目的良好开端就是有一个优良标注的数据集。而由于本课题起源于一个极小领域下，导致数据集必须完全自建。所有工作由我一人进行，工作量不可避免的大。所以必须尽可能的减少工作量，尽量实现在课题的中后期的所有标注工作都由程序自动化解决。&lt;/p&gt;
&lt;p&gt;计组数据集的构建分为了以下几个过程：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;计组数据集来源&lt;/li&gt;
&lt;li&gt;数据预处理&lt;/li&gt;
&lt;li&gt;数据集的预标注&lt;/li&gt;
&lt;li&gt;基于词典的多次迭代标注&lt;/li&gt;
&lt;li&gt;数据集格式的转换&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;接下来对每一个部分进行详述。&lt;/p&gt;
&lt;h3 id=&#34;计组数据集来源&#34;&gt;计组数据集来源&lt;/h3&gt;
&lt;p&gt;目前数据的来源如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;计算机组成原理第6版 (白中英)，pdf 转 txt&lt;/li&gt;
&lt;li&gt;计算机组成原理第6版 (白中英) 课件，ppt 转 txt&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;数据预处理&#34;&gt;数据预处理&lt;/h3&gt;
&lt;p&gt;以下是大概的预处理过程：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;将所有的文本合并到一个文件，方便后续操作；&lt;/li&gt;
&lt;li&gt;手工去掉一些与课题无关的文本和小部分错误内容；&lt;/li&gt;
&lt;li&gt;去掉所有的空白字符（空格、换行符、制表符等）；&lt;/li&gt;
&lt;li&gt;去掉所有的特殊字符（数字、半角符号、特殊字符）；&lt;/li&gt;
&lt;li&gt;以中文句号进行分割，分别以整句、分词的形式输出到 json 文件中。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;处理结果：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-1&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-1&#34;&gt;1&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-2&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-2&#34;&gt;2&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-3&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-3&#34;&gt;3&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-4&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-4&#34;&gt;4&lt;/a&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// 整句
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;#34;0&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;\u8ba1\u7b97\u673a\u7cfb\u7edf\u4e0d\u540c\u4e8e\u4e00\u822c\u7684\u7535\u5b50\u8bbe\u5907\uff0c\u5b83\u662f\u4e00\u4e2a\u7531\u786c\u4ef6\u3001\u8f6f\u4ef6\u7ec4\u6210\u7684\u590d\u6742\u7684\u81ea\u52a8\u5316\u8bbe\u5907&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-1-1&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-1-1&#34;&gt;1&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-1-2&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-1-2&#34;&gt;2&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-1-3&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-1-3&#34;&gt;3&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-1-4&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-1-4&#34;&gt;4&lt;/a&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// 分词
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;#34;0&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;\u8ba1&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;\u7b97&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;\u673a&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;\u7cfb&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;\u7edf&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;\u4e0d&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;\u540c&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;\u4e8e&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;\u4e00&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;\u822c&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;\u7684&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;\u7535&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;\u5b50&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;\u8bbe&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;\u5907&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;\uff0c&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;\u5b83&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;\u662f&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;\u4e00&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;\u4e2a&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;\u7531&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;\u786c&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;\u4ef6&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;\u3001&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;\u8f6f&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;\u4ef6&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;\u7ec4&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;\u6210&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;\u7684&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;\u590d&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;\u6742&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;\u7684&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;\u81ea&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;\u52a8&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;\u5316&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;\u8bbe&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;\u5907&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;数据集的预标注&#34;&gt;数据集的预标注&lt;/h3&gt;
&lt;p&gt;以上所有数据处理完后，共得到5632条文本。如果要自己一条条的标注，真就是整一个月啥也别干，所以还是要用比较省力的方式进行标注。我选择用一个在中文语料集上训练过的预训练模型进行第一轮标注，也就是预标注。&lt;/p&gt;
&lt;p&gt;我选择了 &lt;a href=&#34;https://modelscope.cn/models/iic/nlp_raner_named-entity-recognition_chinese-large-generic&#34;&gt;RaNER命名实体识别-中文-通用领域-large&lt;/a&gt; 作为预标注阶段的预训练模型。该模型的标签如下：&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;实体类型&lt;/th&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;英文名&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;公司名&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;CORP&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;创作名&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;CW&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;其他组织名&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;GRP&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;地名&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;LOC&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;人名&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;PER&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;消费品&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;PROD&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;为什么要选择这个模型呢？我当时认为有以下几点可以考虑：&lt;/p&gt;</description>
    </item>
    <item>
      <title>《基于预训练模型的医药说明书实体抽取方法研究》笔记</title>
      <link>http://localhost:1313/posts/papernotes/%E5%9F%BA%E4%BA%8E%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8C%BB%E8%8D%AF%E8%AF%B4%E6%98%8E%E4%B9%A6%E5%AE%9E%E4%BD%93%E6%8A%BD%E5%8F%96%E6%96%B9%E6%B3%95%E7%A0%94%E7%A9%B6_%E9%99%88%E4%BB%B2%E6%B0%B8/</link>
      <pubDate>Sun, 28 Jul 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/papernotes/%E5%9F%BA%E4%BA%8E%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8C%BB%E8%8D%AF%E8%AF%B4%E6%98%8E%E4%B9%A6%E5%AE%9E%E4%BD%93%E6%8A%BD%E5%8F%96%E6%96%B9%E6%B3%95%E7%A0%94%E7%A9%B6_%E9%99%88%E4%BB%B2%E6%B0%B8/</guid>
      <description>&lt;h2 id=&#34;基于预训练模型的部分标签命名实体识别模型&#34;&gt;基于预训练模型的部分标签命名实体识别模型&lt;/h2&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/PaperNotes/%e5%9f%ba%e4%ba%8e%e9%a2%84%e8%ae%ad%e7%bb%83%e6%a8%a1%e5%9e%8b%e7%9a%84%e5%8c%bb%e8%8d%af%e8%af%b4%e6%98%8e%e4%b9%a6%e5%ae%9e%e4%bd%93%e6%8a%bd%e5%8f%96%e6%96%b9%e6%b3%95%e7%a0%94%e7%a9%b6_%e9%99%88%e4%bb%b2%e6%b0%b8/img1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;对于输入的药品说明书文本先利用少量样本微调的预训练模型进行实体抽取，如上图所示，“云南白药成分：三七、麝香、草乌等”通过预训练模型识别出 “麝香”和“草乌”两个“成分”类型的实体。由于受标注样本数量限制，预训练模型经少量样本微调后，其召回率不高，如例子中“云南白药”“三七”两个实体未能识别，但把预训练模型识别出的部分实体及该实体的类型标签作为一种提示信息输入到后面的部分标签模型，这将有助于部分标签模型进行实体抽取任务。&lt;/p&gt;
&lt;p&gt;部分标签模型采用平面格结构对输入文本及预训练语言模型识别的部分实体进行整合，整合信息包括字符或实体词 token、标签 tag、头部位置标记 head 和尾部位置标记 tail。部分标签模型使用 Transformer 建模平面格结构的编码输入，通过 Transformer 的自注意力机制使字符可以与潜在实体词直接交互。最后将 Transformer 提取特征表示，输入到 CRF层预测实体标签。&lt;/p&gt;
&lt;h2 id=&#34;训练策略&#34;&gt;训练策略&lt;/h2&gt;
&lt;p&gt;对整体模型训练分两阶段：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;利用少量完全标注的语料对预训练模型进行微调，再对这些完全标注语料采用标注样本实体掩盖（mask）策略进行样本数据增广，使用增广后的样本数据集对部分标签模型进行训练；&lt;/li&gt;
&lt;li&gt;预训练模型和部分标签模型进行联合训练。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;对比实验&#34;&gt;对比实验&lt;/h2&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/PaperNotes/%e5%9f%ba%e4%ba%8e%e9%a2%84%e8%ae%ad%e7%bb%83%e6%a8%a1%e5%9e%8b%e7%9a%84%e5%8c%bb%e8%8d%af%e8%af%b4%e6%98%8e%e4%b9%a6%e5%ae%9e%e4%bd%93%e6%8a%bd%e5%8f%96%e6%96%b9%e6%b3%95%e7%a0%94%e7%a9%b6_%e9%99%88%e4%bb%b2%e6%b0%b8/img1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;尽管 BERT- BILSTMCRF 模型在医疗、政务等领域的命名实体识别得到广泛应用 ，但由于采用 LSTM 神经网络提取字符特征，其效果明显低于 FLAT 和本文模型，而 FLAT、 MECT4CNER 以及本文模型都采用 Transformer 网络提取特征。&lt;/p&gt;
&lt;p&gt;MECT4CNER 是在 FLAT 的基础上结合汉字结构信息与词典信息设计的模型，但本次实验表明 MECT4CNER 应用于药品说明书命名实体识别时， 汉字结构信息未能对提高模型性能带来更多增益， 反而降低了召回率，使得 F1 值比 FLAT 模型更低。 本文模型对 FLAT 模型所提出的平面格结构进行了扩展，增加的标签信息能对提升模型性能带来增益， 从而 F1值取得了较优的效果。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;FLAT模型是为中文命名实体识别设计的，它将复杂的字词格结构转换为平坦的结构。每个跨度对应于原始格中的一个字符或潜在词及其位置。FLAT利用Transformer的强大功能和精心设计的位置编码，能够充分利用格信息，并具有出色的并行能力。实验表明，FLAT在性能和效率上都优于其他基于词典的模型。&lt;/p&gt;
&lt;p&gt;MECT4CNER模型结合了字词格和部首流，不仅具有FLAT的词边界和语义学习能力，还增加了汉字部首的结构信息。通过融合汉字的结构特征，MECT能够更好地捕捉汉字的语义信息，从而提高中文NER的性能。&lt;/p&gt;
&lt;/blockquote&gt;</description>
    </item>
    <item>
      <title>7.22-7.28：一周总结</title>
      <link>http://localhost:1313/posts/weeklyworking/2024_07_22-2024_07_28/</link>
      <pubDate>Sun, 28 Jul 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/weeklyworking/2024_07_22-2024_07_28/</guid>
      <description>&lt;h2 id=&#34;本周任务&#34;&gt;本周任务&lt;/h2&gt;
&lt;p&gt;本周主要还是做计组知识图谱课题。以下为本周具体进度：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;把数据集分割为了训练集、验证集、测试集，对训练集以随机抽样进行进一步分割，以减小工作量&lt;/li&gt;
&lt;li&gt;第一次标注采用预标注，之后用词典不断迭代标注&lt;/li&gt;
&lt;li&gt;完成了第一份训练集1000条和验证集、测试集的标注，总共2000余条语料，用新标签PCC 标注&lt;/li&gt;
&lt;li&gt;用 Adaseq 训练模型，但是遇到了诸多问题，尚未解决&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;课题下周改进&#34;&gt;课题下周改进&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;PCC 标签过于笼统，下周对标签进一步细化，并去除少部分无用标签&lt;/li&gt;
&lt;li&gt;弃用 Adaseq ，国产的玩意是真不如 Transformers 好用&lt;/li&gt;
&lt;li&gt;找一个新的预训练模型进行训练（其实已经找到了）&lt;/li&gt;
&lt;li&gt;多模型对比训练&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以上修改标签预计最少3天，用 Transformers 训练最少2天，多模型能做多少算多少&lt;/p&gt;
&lt;h2 id=&#34;本周反思&#34;&gt;本周反思&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;每一步的数据尽可能的量化并记录，方便日后发论文&lt;/li&gt;
&lt;li&gt;对课题各个工作部分理解浅显，应当在阅读部分文献后再进行&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    <item>
      <title>《中文命名实体识别研究综述》笔记</title>
      <link>http://localhost:1313/posts/papernotes/%E4%B8%AD%E6%96%87%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E7%A0%94%E7%A9%B6%E7%BB%BC%E8%BF%B0_%E8%B5%B5%E7%BB%A7%E8%B4%B5/</link>
      <pubDate>Sat, 27 Jul 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/papernotes/%E4%B8%AD%E6%96%87%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E7%A0%94%E7%A9%B6%E7%BB%BC%E8%BF%B0_%E8%B5%B5%E7%BB%A7%E8%B4%B5/</guid>
      <description>&lt;h2 id=&#34;中文ner的难点&#34;&gt;中文NER的难点&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;词边界模糊。中文没有像英文等语言一样使用空格或其他分隔符来表示词边界，这种特点导致中文命名实体识别面临着边界歧义和识别困难的问题。例如，“计算机科学与技术系”中“计算机科学与技术”是一个 复合词，边界不明确。&lt;/li&gt;
&lt;li&gt;语义多样化。中文存在大量多义词，一个词汇可能会被用于不同的上下文中表示不同的含义。&lt;/li&gt;
&lt;li&gt;形态特征模糊。在英语中，一些指定类型的实体的第一个字母通常是大写的，例如指定人员或地点的名称。这种信息是识别一些命名实体的位置和边界的明确特征。在中文命名实体识别中缺乏汉语形态的显式特征，增加了识别的难度。&lt;/li&gt;
&lt;li&gt;中文语料库内容较少。命名实体识别需要大量 的标注数据来训练模型，但中文标注数据数量及质量有限，导致命名实体识别模型的训练更为困难。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;cner数据集&#34;&gt;CNER数据集&lt;/h2&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/PaperNotes/%e4%b8%ad%e6%96%87%e5%91%bd%e5%90%8d%e5%ae%9e%e4%bd%93%e8%af%86%e5%88%ab%e7%a0%94%e7%a9%b6%e7%bb%bc%e8%bf%b0_%e8%b5%b5%e7%bb%a7%e8%b4%b5/img1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;h2 id=&#34;cner标注方式性能指标&#34;&gt;CNER标注方式、性能指标&lt;/h2&gt;
&lt;p&gt;BIO标注、 BMES标注以及BIOSE标注方案。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/PaperNotes/%e4%b8%ad%e6%96%87%e5%91%bd%e5%90%8d%e5%ae%9e%e4%bd%93%e8%af%86%e5%88%ab%e7%a0%94%e7%a9%b6%e7%bb%bc%e8%bf%b0_%e8%b5%b5%e7%bb%a7%e8%b4%b5/img2.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;性能指标和NER一样，Precision、Recall、Accuracy、F1-score 是常用指标。&lt;/p&gt;
&lt;h2 id=&#34;近几年的cner模型构成&#34;&gt;近几年的CNER模型构成&lt;/h2&gt;
&lt;h3 id=&#34;嵌入层&#34;&gt;嵌入层&lt;/h3&gt;
&lt;h4 id=&#34;基于字符的模型&#34;&gt;基于字符的模型&lt;/h4&gt;
&lt;p&gt;基于字符的模型将单词表示为字符序列的方法，它通过输入文本的字符级别表示，不需要明确的词边界信息，可以更好地处理CNER中的边界模糊问题。为解决相邻字符之间强联系的问题，Zhang 等人[40] 提出一种新的动态嵌入方法，该方法使用注意力机制来 组合嵌入层中的字符和单词向量特征。基于字符的模型存在不能携带语义信息、难以处理歧义词的缺点[42] 。&lt;/p&gt;
&lt;h4 id=&#34;基于词的模型&#34;&gt;基于词的模型&lt;/h4&gt;
&lt;p&gt;基于词的模型是将中文数据集的文本以词语的形 式作为输入，借助分词系统[43] 对数据集进行分词。基于词的模型可以捕捉到词与词之间的语义关系，在处理一些长词汇的实体时具有良好的效果。基于词的模型存在分词错误和在处理不规则的词以及新词时比较困难的缺点。Ma等人[45] 使用双向 LSTM、CNN 和 CRF 的组合，提出一种 中性网络结构，自动从单词和字符级别的表示中获益， 实现了端到端的 NER。&lt;/p&gt;
&lt;h4 id=&#34;混合模型&#34;&gt;混合模型&lt;/h4&gt;
&lt;p&gt;混合模型是将基于字符的模型和基于词的模型结合起来，由于基于字符的模型存在字与字之间语义提取缺失问题，基于词的模型存在分词错误的问题，同时将字符和词作为嵌入表示可以使模型具有较好的鲁棒性和识别精度。&lt;/p&gt;
&lt;p&gt;基于 Transformer 的双向编码（bidirectional encoder representations from Transformer，BERT） 模型[51] 是中文命名实体识别中最常用的预训练模型， BERT模型可以考虑整个输入句子的上下文信息，有助于提高模型对命名实体的理解和识别准确性。对于给定的字符，BERT将其字符位置嵌入、句子位置嵌入和字符嵌入作为输入连接起来，然后使用掩码语言模型[52] 对输入句子进行深度双向表示预训练，以获得强大的上下文字符嵌入。&lt;/p&gt;
&lt;h3 id=&#34;编码层&#34;&gt;编码层&lt;/h3&gt;
&lt;p&gt;编码层主要是将嵌入层输入的文本转换成一个高 维的特征向量，方便后续的分类器对文本进行分类。&lt;/p&gt;
&lt;h4 id=&#34;卷积神经网络&#34;&gt;卷积神经网络&lt;/h4&gt;
&lt;p&gt;CNN最初是为计算 机视觉研究开发的，但它已被证明可以有效地捕获具有卷积运算的 n-gram 的信息语义特征[61] 。&lt;/p&gt;
&lt;h4 id=&#34;循环神经网络&#34;&gt;循环神经网络&lt;/h4&gt;
&lt;p&gt;Quyang 等人[67] 提出一种用于 CNER 的深度学习模型，该模型采用双向 RNN-CRF 架构，使用连接的 n -gram 字符表示来捕获丰富的上下文信息。Dong 等人[37] 将双向 LSTM-CRF 神经网络用于 CNER，该网络同时利用字符级和部首级表示，是第一个研究 BiLSTM-CRF 架构中的中文部首级表示，并且在没有精心设计的功能的情况下获得更好的性能。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Lecture 8: Attention</title>
      <link>http://localhost:1313/posts/cs224n/lesson_8/</link>
      <pubDate>Sat, 27 Jul 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/cs224n/lesson_8/</guid>
      <description>第八讲：注意力机制</description>
    </item>
    <item>
      <title>Lecture 7: Machine Translation and Sequence to Sequence</title>
      <link>http://localhost:1313/posts/cs224n/lesson_7/</link>
      <pubDate>Sat, 13 Jul 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/cs224n/lesson_7/</guid>
      <description>第七讲：机器翻译与Seq2seq</description>
    </item>
    <item>
      <title>RNN速成（二）</title>
      <link>http://localhost:1313/posts/nlp/rnn%E9%80%9F%E6%88%90%E4%BA%8C/</link>
      <pubDate>Fri, 12 Jul 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/nlp/rnn%E9%80%9F%E6%88%90%E4%BA%8C/</guid>
      <description>了解RNN的两种变体</description>
    </item>
    <item>
      <title>Lecture 6: Long Short-Term Memory RNNs</title>
      <link>http://localhost:1313/posts/cs224n/lesson_6/</link>
      <pubDate>Thu, 11 Jul 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/cs224n/lesson_6/</guid>
      <description>第六讲：LSTM</description>
    </item>
    <item>
      <title>RNN速成（一）</title>
      <link>http://localhost:1313/posts/nlp/rnn/</link>
      <pubDate>Sat, 06 Jul 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/nlp/rnn/</guid>
      <description>了解RNN本体</description>
    </item>
    <item>
      <title>Lecture 5: Language Models and Recurrent Neural Network</title>
      <link>http://localhost:1313/posts/cs224n/lesson_5/</link>
      <pubDate>Fri, 05 Jul 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/cs224n/lesson_5/</guid>
      <description>第五讲：语言模型和循环神经网络</description>
    </item>
    <item>
      <title>Named Entity Recognition 相关概念与技术</title>
      <link>http://localhost:1313/posts/nlp/ner/</link>
      <pubDate>Fri, 05 Jul 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/nlp/ner/</guid>
      <description>命名实体识别快速入门</description>
    </item>
    <item>
      <title>Lecture 4: Dependency parsing</title>
      <link>http://localhost:1313/posts/cs224n/lesson_4/</link>
      <pubDate>Thu, 04 Jul 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/cs224n/lesson_4/</guid>
      <description>第四讲：依存句法分析</description>
    </item>
    <item>
      <title>Continuous Bag of Words</title>
      <link>http://localhost:1313/posts/nlp/word2vec-variants-continuous_bag_of_words/</link>
      <pubDate>Sat, 29 Jun 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/nlp/word2vec-variants-continuous_bag_of_words/</guid>
      <description>CBOW的简单认知</description>
    </item>
    <item>
      <title>Skip-gram Model</title>
      <link>http://localhost:1313/posts/nlp/word2vec-variants-skip-gram/</link>
      <pubDate>Fri, 28 Jun 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/nlp/word2vec-variants-skip-gram/</guid>
      <description>skip-gram的简单见解</description>
    </item>
    <item>
      <title>Lecture 1: Introduction and Word Vectors</title>
      <link>http://localhost:1313/posts/cs224n/lesson_1/</link>
      <pubDate>Thu, 27 Jun 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/cs224n/lesson_1/</guid>
      <description>第一讲：简介和词向量</description>
    </item>
    <item>
      <title>GoogleNet V1</title>
      <link>http://localhost:1313/posts/classicpapertranslation/googlenetv1/</link>
      <pubDate>Wed, 26 Jun 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/classicpapertranslation/googlenetv1/</guid>
      <description>&lt;h1 id=&#34;googlenet-v1&#34;&gt;GoogleNet V1&lt;/h1&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;本文作者在ImageNet大规模视觉识别挑战赛2014（ILSVRC14）上提出了一种代号为Inception的深度卷积神经网络结构，并在分类和检测上取得了新的最好结果。这个架构的主要特点是提高了网络内部计算资源的利用率。通过精心的手工设计，在增加了网络深度和广度的同时保持了计算预算不变。为了优化质量，架构的设计以赫布理论和多尺度处理直觉为基础。作者在ILSVRC14提交中应用的一个特例被称为GoogLeNet，一个22层的深度网络，其质量在分类和检测的背景下进行了评估。&lt;/p&gt;
&lt;h2 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h2&gt;
&lt;p&gt;过去三年中，由于深度学习和卷积网络的发展[10]，目标分类和检测能力得到了显著提高。一个令人鼓舞的消息是，大部分的进步不仅仅是更强大硬件、更大数据集、更大模型的结果，而主要是新的想法、算法和网络结构改进的结果。例如，ILSVRC 2014竞赛中最靠前的输入除了用于检测目的的分类数据集之外，没有使用新的数据资源。本文在ILSVRC 2014中的GoogLeNet提交实际使用的参数只有两年前Krizhevsky等人[9]获胜结构参数的1/12，而结果明显更准确。在目标检测前沿，最大的收获不是来自于越来越大的深度网络的简单应用，而是来自于深度架构和经典计算机视觉的协同，像Girshick等人[6]的R-CNN算法那样。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;另一个显著因素是随着移动和嵌入式设备的推动，算法的效率很重要——尤其是它们的电力和内存使用。值得注意的是，正是包含了这个因素的考虑才得出了本文中呈现的深度架构设计，而不是单纯的为了提高准确率&lt;/strong&gt;。对于大多数实验来说，模型被设计为在一次推断中保持15亿乘加的计算预算，所以最终它们不是单纯的学术好奇心，而是能在现实世界中应用，甚至是以合理的代价在大型数据集上使用。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;本文作者考虑到在终端设备上的应用所以才提出了Inception，这也影响了后续的Xception和MobileNet。（猜测）&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在本文中将关注一个高效的计算机视觉深度神经网络架构，代号为Inception，它的名字来自于Lin等人[12]网络论文中的Network与著名的“we need to go deeper”网络梗图[1]的结合。在本文的案例中，单词“deep”用在两个不同的含义中：首先，在某种意义上，以“Inception module”的形式引入了一种新层次的组织方式，在更直接的意义上增加了网络的深度。一般来说，可以把Inception模型看作论文[12]的逻辑顶点同时从Arora等人[2]的理论工作中受到了鼓舞和引导。这种架构的好处在ILSVRC 2014分类和检测挑战赛中通过实验得到了验证，它明显优于目前的最好水平。&lt;/p&gt;
&lt;h2 id=&#34;2-related-work&#34;&gt;2. Related Work&lt;/h2&gt;
&lt;p&gt;从LeNet-5 [10]开始，卷积神经网络（CNN）通常有一个标准结构——堆叠的卷积层（后面可以选择有对比归一化和最大池化）后面是一个或更多的全连接层。这个基本设计的变种在图像分类论文中流行，并且目前为止在MNIST，CIFAR和更著名的ImageNet分类挑战赛中[9, 21]的已经取得了最佳结果。对于更大的数据集例如ImageNet来说，最近的趋势是增加层的数目[12]和层的大小[21, 14]，同时使用dropout[7]来解决过拟合问题。&lt;/p&gt;
&lt;p&gt;尽管担心最大池化层会引起准确空间信息的损失，但与[9]相同的卷积网络结构也已经成功的应用于定位[9, 14]，目标检测[6, 14, 18, 5]和行人姿态估计[19]。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;受灵长类视觉皮层神经科学模型的启发，Serre等人[15]使用了一系列固定的不同大小的Gabor滤波器来处理多尺度。本文使用一个了类似的策略&lt;/strong&gt;。然而，与[15]的固定的2层深度模型相反，Inception结构中所有的滤波器是学习到的。此外，Inception层重复了很多次，在GoogLeNet模型中得到了一个22层的深度模型。&lt;/p&gt;
&lt;p&gt;Network-in-Network是Lin等人[12]为了增加神经网络表现能力而提出的一种方法。在他们的模型中，网络中添加了额外的1 × 1卷积层，增加了网络的深度。本文的架构中大量的使用了这个方法。&lt;strong&gt;但是，在本文的设置中，1 × 1卷积有两个目的：最关键的是，它们主要是用来作为降维模块来移除卷积瓶颈，否则将会限制网络的大小。这不仅允许了深度的增加，而且允许网络的宽度增加但没有明显的性能损失&lt;/strong&gt;。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;1×1 的卷积层的作用：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;在相同尺寸的感受野中叠加更多的卷积，能提取到更丰富的特征。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;使用1x1卷积进行降维，降低了计算复杂度。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;1×1 卷积没有识别高和宽维度上相邻元素构成的模式的功能。实际上，1×1 卷积的作用主要发生在 Channel 维上。值得注意的是，输入和输出具有相同的高和宽。输出中的每个元素来自输入中在高和宽上相同位置的元素在不同通道之间的按权重累加。假设我们将 Channel 维当作特征维，将高和宽维度上的元素当成数据样本，那么 1×1 卷积层的作用与全连接层等价。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;最后，目前最好的目标检测是Girshick等人[6]的基于区域的卷积神经网络（R-CNN）方法。R-CNN将整个检测问题分解为两个子问题：利用低层次的信号例如颜色，纹理以跨类别的方式来产生目标位置候选区域，然后用CNN分类器来识别那些位置上的对象类别。这样Two-Stage的方法利用了低层特征分割边界框的准确性，也利用了目前的CNN非常强大的分类能力。我们在我们的检测提交中采用了类似的方式，但探索增强这两个阶段，例如对于更高的目标边界框召回使用多盒[5]预测，并融合了更好的边界框候选区域分类方法。&lt;/p&gt;
&lt;h2 id=&#34;3-motivation-and-high-level-considerations&#34;&gt;3. Motivation and High Level Considerations&lt;/h2&gt;
&lt;p&gt;提高深度神经网络性能最直接的方式是增加它们的尺寸。这不仅包括增加深度——网络层次的数目——也包括它的宽度：每一层的单元数目。这是一种训练更高质量模型容易且安全的方法，尤其是在可获得大量标注的训练数据的情况下。但是这个简单方案有两个主要的缺点。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;更大的尺寸通常意味着更多的参数，这会使增大的网络更容易过拟合，尤其是在训练集的标注样本有限的情况下。这是一个主要的瓶颈，因为要获得强标注数据集费时费力且代价昂贵，经常需要专家评委在各种细粒度的视觉类别进行区分，例如图1中显示的ImageNet中的类别（甚至是1000类ILSVRC的子集）。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/ClassicPaperTranslation/GoogleNet/V1/Figure_1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;图1: ILSVRC 2014分类挑战赛的1000类中两个不同的类别。区分这些类别需要领域知识。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;均匀增加网络尺寸的另一个缺点是计算资源使用的显著增加。例如，在一个深度视觉网络中，如果两个卷积层相连，它们的滤波器数目的任何均匀增加都会引起计算量以平方增加。如果增加的能力使用时效率低下（例如，如果大多数权重结束时接近于0），那么会浪费大量的计算能力。由于计算预算总是有限的，计算资源的有效分布更偏向于尺寸无差别的增加，即使主要目标是增加性能的质量。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;解决这两个问题的一个基本的方式就是引入稀疏性并将全连接层替换为稀疏的全连接层，甚至是卷积层&lt;/strong&gt;。除了模仿生物系统之外，由于Arora等人[2]的开创性工作，这也具有更坚固的理论基础优势。他们的主要成果说明如果数据集的概率分布可以通过一个大型稀疏的深度神经网络表示，则最优的网络拓扑结构可以通过分析前一层激活的相关性统计和聚类高度相关的神经元来一层层的构建。虽然严格的数学证明需要在很强的条件下，但事实上这个声明与著名的赫布理论产生共鸣：神经元一起激发，一起连接。实践表明，基础概念甚至适用于不严格的条件下。&lt;/p&gt;
&lt;p&gt;遗憾的是，当碰到在非均匀的稀疏数据结构上进行数值计算时，以现在的计算架构效率会非常低下。即使算法运算的数量减少100倍，查询和缓存丢失上的开销仍占主导地位：切换到稀疏矩阵可能是不可行的。随着稳定提升和高度调整的数值库的应用，差距仍在进一步扩大，数值库要求极度快速密集的矩阵乘法，利用底层的CPU或GPU硬件[16, 9]的微小细节。非均匀的稀疏模型也要求更多的复杂工程和计算基础结构。目前大多数面向视觉的机器学习系统通过采用卷积的优点来利用空域的稀疏性。然而，卷积被实现为对上一层块的密集连接的集合。为了打破对称性，提高学习水平，从论文[11]开始，ConvNets习惯上在特征维度使用随机的稀疏连接表，然而为了进一步优化并行计算，论文[9]中趋向于变回全连接。目前最新的计算机视觉架构有统一的结构。更多的滤波器和更大的批大小要求密集计算的有效使用。&lt;/p&gt;
&lt;p&gt;这提出了下一个中间步骤是否有希望的问题：一个架构能利用滤波器水平的稀疏性，正如理论所认为的那样，但能通过利用密集矩阵计算来利用目前的硬件。稀疏矩阵乘法的大量文献（例如[3]）认为对于稀疏矩阵乘法，将稀疏矩阵聚类为相对密集的子矩阵会有更佳的性能。在不久的将来会利用类似的方法来进行非均匀深度学习架构的自动构建，这样的想法似乎并不牵强。&lt;/p&gt;
&lt;p&gt;Inception架构开始作为案例研究，用于评估一个复杂网络拓扑构建算法的假设输出，该算法试图近似[2]中所示的视觉网络的稀疏结构，并通过密集的、容易获得的组件来覆盖假设结果。尽管是一个非常投机的事情，但与基于[12]的参考网络相比，早期可以观测到适度的收益。随着一点点调整加宽差距，作为[6]和[5]的基础网络，Inception被证明在定位上下文和目标检测中尤其有用。有趣的是，虽然大多数最初的架构选择已被质疑并分离开进行全面测试，但结果证明它们是局部最优的。然而必须谨慎：尽管Inception架构在计算机上领域取得成功，但这是否可以归因于构建其架构的指导原则仍是有疑问的。确保这一点将需要更彻底的分析和验证。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/ClassicPaperTranslation/GoogleNet/V1/Figure_4.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;</description>
    </item>
    <item>
      <title>GoogleNet V2</title>
      <link>http://localhost:1313/posts/classicpapertranslation/googlenetv2/</link>
      <pubDate>Wed, 26 Jun 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/classicpapertranslation/googlenetv2/</guid>
      <description>&lt;h1 id=&#34;googlenet-v2&#34;&gt;GoogLeNet V2&lt;/h1&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;训练深度神经网络的复杂性在于，每层输入的分布在训练过程中会发生变化，因为前面的层的参数会发生变化。通过要求较低的学习率和仔细的参数初始化减慢了训练，并且使具有饱和非线性的模型训练起来非常困难。本文将这种现象称为&lt;em&gt;内部协变量转移&lt;/em&gt;，并通过标准化层输入来解决这个问题。本文力图使标准化成为模型架构的一部分，并为&lt;em&gt;每个训练小批量数据&lt;/em&gt;执行标准化。批标准化使我们能够使用更高的学习率，并且不用太注意初始化。它也作为一个正则化项，在某些情况下不需要Dropout。将批量标准化应用到最先进的图像分类模型上，批标准化在取得相同的精度的情况下，减少了14倍的训练步骤，并以显著的差距击败了原始模型。使用批标准化网络的组合，我们改进了在ImageNet分类上公布的最佳结果：达到了&lt;code&gt;4.9％ top-5&lt;/code&gt;的验证误差（和&lt;code&gt;4.8％&lt;/code&gt;测试误差），超过了人类评估者的准确性。&lt;/p&gt;
&lt;h2 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h2&gt;
&lt;p&gt;随机梯度下降（SGD）已经被证明是训练深度网络的有效方式，并且已经使用诸如动量（Sutskever等，2013）和Adagrad（Duchi等人，2011）等SGD变种取得了最先进的性能。SGD优化网络参数$\Theta$，以最小化损失
&lt;/p&gt;
$$
\Theta = arg \ min_{\Theta}\frac{1}{N} \sum_{i=1}^{N}ℓ(x_i,\Theta)
$$&lt;p&gt;
$x_1...N$是训练数据集。使用SGD，训练将逐步进行，在每一步中，我们考虑一个大小为$m$的小批量数据$x_1...m$。通过计算$\frac{1}{m}\sum^m_{i=1}\frac{∂ℓ(xi,Θ)}{∂Θ}$，使用小批量数据来近似损失函数关于参数的梯度。使用小批量样本，而不是一次一个样本，在一些方面是有帮助的。&lt;strong&gt;首先，小批量数据的梯度损失是训练集上的梯度估计，其质量随着批量增加而改善。第二，由于现代计算平台提供的并行性，对一个批次的计算比单个样本计算$m$次效率更高&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;虽然随机梯度是简单有效的，但它需要仔细调整模型的超参数，特别是优化中使用的学习速率以及模型参数的初始值。训练的复杂性在于每层的输入受到前面所有层的参数的影响——因此当网络变得更深时，网络参数的微小变化就会被放大。&lt;/p&gt;
&lt;p&gt;层输入的分布变化是一个问题，因为这些层需要不断适应新的分布。当学习系统的输入分布发生变化时，据说会经历&lt;em&gt;协变量转移&lt;/em&gt;（Shimodaira，2000）。这通常是通过域适应（Jiang，2008）来处理的。然而，协变量转移的概念可以扩展到整个学习系统之外，应用到学习系统的一部分，例如子网络或一层。考虑网络计算
&lt;/p&gt;
$$
ℓ=F_2(F_1(u,Θ_1),Θ_2)
$$&lt;p&gt;
$F_1$和$F_2$是任意变换，学习参数$Θ_1$，$Θ_2$以便最小化损失$ℓ$。学习$Θ_2$可以看作输入$x=F_1(u,Θ_1)$送入到子网络
&lt;/p&gt;
$$
ℓ=F_2(x,Θ_2)
$$&lt;p&gt;
例如，梯度下降步骤
&lt;/p&gt;
$$
Θ_2←Θ_2−\frac{α}{m}\sum_{i=1}^{m}\frac{∂F_2(x_i,Θ_2)}{∂Θ_2}
$$&lt;p&gt;
（对于批大小$m$和学习率$α$）与输入为$x$的单独网络$F_2$完全等价。&lt;strong&gt;因此，输入分布特性使训练更有效——例如训练数据和测试数据之间有相同的分布——也适用于训练子网络&lt;/strong&gt;。因此$x$的分布在时间上保持固定是有利的。然后，$Θ_2$不必重新调整来补偿x分布的变化。&lt;/p&gt;
&lt;p&gt;子网络输入的固定分布对于子网络外的层也有积极的影响。考虑一个激活函数为$g(x)=\frac{1}{1+exp(−x)}$的层，$u$是层输入，权重矩阵$W$和偏置向量$b$是要学习的层参数，$g(x)=\frac{1}{1+exp(−x)}$。随着$|x|$的增加，$g′(x)$趋向于0。这意味着对于$x=Wu+b$的所有维度，除了那些具有小的绝对值之外，流向$u$的梯度将会消失，模型将缓慢的进行训练。然而，由于$x$受$W,b$和下面所有层的参数的影响，训练期间那些参数的改变可能会将$x$的许多维度移动到非线性的饱和状态并减慢收敛。这个影响随着网络深度的增加而放大。在实践中，饱和问题和由此产生的梯度消失通常通过使用修正线性单元(Nair &amp;amp; Hinton, 2010)$ ReLU(x)=max(x,0)$，仔细的初始化(Bengio &amp;amp; Glorot, 2010; Saxe et al., 2013)和小的学习率来解决。&lt;strong&gt;然而，如果我们能保证非线性输入的分布在网络训练时保持更稳定，那么优化器将不太可能陷入饱和状态，训练将加速&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;本文把训练过程中深度网络内部结点的分布变化称为&lt;em&gt;内部协变量转移&lt;/em&gt;，消除它可以保证更快的训练&lt;/strong&gt;。我们提出了一种新的机制，我们称为为&lt;em&gt;批标准化&lt;/em&gt;，它是减少内部协变量转移的一个步骤，这样做可以显著加速深度神经网络的训练。&lt;strong&gt;它通过标准化步骤来实现，标准化步骤修正了层输入的均值和方差。批标准化减少了梯度对参数或它们的初始值尺度上的依赖，对通过网络的梯度流动有益。这允许我们使用更高的学习率而没有发散的风险。此外，批标准化使模型正则化并减少了对Dropout(Srivastava et al., 2014)的需求。最后，批标准化通过阻止网络陷入饱和模式让使用饱和非线性成为可能&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;在4.2小节，本文将批标准化应用到性能最好的ImageNet分类网络上，并且表明可以使用仅7％的训练步骤来匹配其性能，并且可以进一步超过其准确性一大截。通过使用批标准化训练的网络的集合，最终取得了top-5错误率，其改进了ImageNet分类上已知的最佳结果。&lt;/p&gt;
&lt;h2 id=&#34;2-towards-reducing-internal-covariate-shift&#34;&gt;2. Towards Reducing Internal Covariate Shift&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;由于训练过程中网络参数的变化，本文将&lt;em&gt;内部协变量转移&lt;/em&gt;定义为网络激活分布的变化&lt;/strong&gt;。为了改善训练，以寻求减少内部协变量转移。随着训练的进行，通过固定层输入$x$的分布，期望提高训练速度。众所周知(LeCun et al., 1998b; Wiesler &amp;amp; Ney, 2011)如果对网络的输入进行白化，网络训练将会收敛的更快——即输入线性变换为具有零均值和单位方差，并去相关。当每一层观察下面的层产生的输入时，实现每一层输入进行相同的白化将是有利的。通过白化每一层的输入，将采取措施实现输入的固定分布，消除内部协变量转移的不良影响。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;白化，whitening。&lt;/p&gt;
&lt;p&gt;白化的目的是去除输入数据的冗余信息。假设训练数据是图像，由于图像中相邻像素之间具有很强的相关性，所以用于训练时输入是冗余的。而白化的目的就是降低输入的冗余性。&lt;/p&gt;
&lt;p&gt;输入数据集$X$，经过白化处理后，新的数据$X&#39;$满足两个性质：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;特征之间相关性较低；&lt;/li&gt;
&lt;li&gt;所有特征具有相同的方差。&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;本文考虑在每个训练步骤或在某些间隔来白化激活值，通过直接修改网络或根据网络激活值来更改优化方法的参数(Wiesler et al., 2014; Raiko et al., 2012; Povey et al., 2014; Desjardins &amp;amp; Kavukcuoglu)。然而，如果这些修改分散在优化步骤中，那么梯度下降步骤可能会试图以要求标准化进行更新的方式来更新参数，这会降低梯度下降步骤的影响。例如，考虑一个层，其输入$u$加上学习到的偏置$b$，通过减去在训练集上计算的激活值的均值对结果进行归一化：$\hat x=x−E[x]$，$x=u+b$，$X=x_1...N$是训练集上$x$值的集合，$E[x]=\frac{1}{N}\sum^N_{i=1}x_i$。如果梯度下降步骤忽略了$E[x]$对$b$的依赖，那它将更新$b←b+Δb$，其中$Δb∝−∂ℓ/∂\hat x$。然后$u+(b+Δb)−E[u+(b+Δb)]=u+b−E[u+b]$。因此，结合$b$的更新和接下来标准化中的改变会导致层的输出没有变化，从而导致损失没有变化。随着训练的继续，$b$将无限增长而损失保持不变。如果标准化不仅中心化而且缩放了激活值，问题会变得更糟糕。&lt;strong&gt;在最初的实验中已经观察到了这一点，当标准化参数在梯度下降步骤之外计算时，模型会爆炸。&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Inception V3</title>
      <link>http://localhost:1313/posts/classicpapertranslation/inceptionv3/</link>
      <pubDate>Wed, 26 Jun 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/classicpapertranslation/inceptionv3/</guid>
      <description>&lt;h1 id=&#34;inception-v3&#34;&gt;Inception V3&lt;/h1&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;对许多任务而言，卷积网络是目前最新的计算机视觉解决方案的核心。从2014年开始，深度卷积网络开始变成主流，在各种基准数据集上都取得了实质性成果。对于大多数任务而言，虽然增加的模型大小和计算成本都趋向于转化为直接的质量收益（只要提供足够的标注数据去训练），但计算效率和低参数计数仍是各种应用场景的限制因素，例如移动视觉和大数据场景。目前，我们正在探索增大网络的方法，目标是通过适当的分解卷积和积极的正则化来尽可能地有效利用增加的计算。我们在ILSVRC 2012分类挑战赛的验证集上评估了我们的方法，结果证明我们的方法超过了目前最先进的方法并取得了实质性收益：对于单一框架评估错误率为：&lt;code&gt;21.2% top-1&lt;/code&gt;和&lt;code&gt;5.6% top-5&lt;/code&gt;，使用的网络计算代价为每次推断需要进行50亿次乘加运算并使用不到2500万的参数。通过四个模型组合和多次评估，我们报告了&lt;code&gt;3.5% top-5&lt;/code&gt;和&lt;code&gt;17.3% top-1&lt;/code&gt;的错误率。&lt;/p&gt;
&lt;h2 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h2&gt;
&lt;p&gt;从2012年Krizhevsky等人[9]赢得了ImageNet竞赛[16]起，他们的网络“AlexNet”已经成功了应用到了许多计算机视觉任务中，例如目标检测[5]，分割[12]，行人姿势评估[22]，视频分类[8]，目标跟踪[23]和超分辨率[3]。&lt;/p&gt;
&lt;p&gt;这些成功推动了一个新研究领域，这个领域主要专注于寻找更高效运行的卷积神经网络。从2014年开始，通过利用更深更宽的网络，网络架构的质量得到了明显改善。VGGNet[18]和GoogLeNet[20]在2014 ILSVRC [16]分类挑战上取得了类似的高性能。一个有趣的发现是在分类性能上的收益趋向于转换成各种应用领域上的显著质量收益。这意味着深度卷积架构上的架构改进可以用来改善大多数越来越多地依赖于高质量、可学习视觉特征的其它计算机视觉任务的性能。网络质量的改善也导致了卷积网络在新领域的应用，在AlexNet特征不能与手工精心设计的解决方案竞争的情况下，例如，检测时的候选区域生成[4]。&lt;/p&gt;
&lt;p&gt;尽管VGGNet[18]具有架构简洁的强有力特性，但它的成本很高：评估网络需要大量的计算。另一方面，GoogLeNet[20]的Inception架构也被设计为在内存和计算预算严格限制的情况下也能表现良好。例如，GoogleNet只使用了500万参数，与其前身AlexNet相比减少了12倍，AlexNet使用了6000万参数。此外，VGGNet使用了比AlexNet大约多3倍的参数。&lt;/p&gt;
&lt;p&gt;Inception的计算成本也远低于VGGNet或其更高性能的后继者[6]。这使得可以在大数据场景中[17]，[13]，在大量数据需要以合理成本处理的情况下或在内存或计算能力固有地受限情况下，利用Inception网络变得可行，例如在移动视觉设定中。通过应用针对内存使用的专门解决方案[2]，[15]或通过计算技巧优化某些操作的执行[10]，可以减轻部分这些问题。但是这些方法增加了额外的复杂性。此外，这些方法也可以应用于优化Inception架构，再次扩大效率差距。&lt;/p&gt;
&lt;p&gt;然而，Inception架构的复杂性使得更难以对网络进行更改。如果单纯地放大架构，大部分的计算收益可能会立即丢失。此外，[20]并没有提供关于导致GoogLeNet架构的各种设计决策的贡献因素的明确描述。这使得它更难以在适应新用例的同时保持其效率。例如，如果认为有必要增加一些Inception模型的能力，将滤波器组大小的数量加倍的简单变换将导致计算成本和参数数量增加4倍。这在许多实际情况下可能会被证明是禁止或不合理的，尤其是在相关收益适中的情况下。在本文中，我们从描述一些一般原则和优化思想开始，对于以有效的方式扩展卷积网络来说，这被证实是有用的。虽然我们的原则不局限于Inception类型的网络，但是在这种情况下，它们更容易观察，因为Inception类型构建块的通用结构足够灵活，可以自然地合并这些约束。这通过大量使用降维和Inception模块的并行结构来实现，这允许减轻结构变化对邻近组件的影响。但是，对于这样做需要谨慎，因为应该遵守一些指导原则来保持模型的高质量。&lt;/p&gt;
&lt;h2 id=&#34;2-general-design-principles&#34;&gt;2. General Design Principles&lt;/h2&gt;
&lt;p&gt;这里我们将介绍一些具有卷积网络的、具有各种架构选择的、基于大规模实验的设计原则。在这一点上，以下原则的效用是推测性的，另外将来的实验证据将对于评估其准确性和有效领域是必要的。然而，严重偏移这些原则往往会导致网络质量的恶化，修正检测到的这些偏差状况通常会导致改进的架构。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;避免表征瓶颈，尤其是在网络的前面&lt;/strong&gt;。前馈网络可以由从输入层到分类器或回归器的非循环图表示。这为信息流定义了一个明确的方向，对于分离输入输出的任何切口，可以访问通过切口的信息量。应该避免极端压缩的瓶颈。&lt;strong&gt;一般来说，在达到用于着手任务的最终表示之前，表示大小应该从输入到输出缓慢减小。理论上，信息内容不能仅通过表示的维度来评估，因为它丢弃了诸如相关结构的重要因素，而维度仅提供信息内容的粗略估计&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;更高维度的表示在网络中更容易局部处理。在卷积网络中增加每个图块的激活允许更多解耦的特征，所产生的网络将训练更快&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;空间聚合可以在较低维度嵌入上完成，而不会在表示能力上造成许多或任何损失&lt;/strong&gt;。例如，在执行更多展开（例如3×3）卷积之前，可以在空间聚合之前减小输入表示的维度，没有预期的严重不利影响。我们假设，如果在空间聚合上下文中使用输出，则相邻单元之间的强相关性会导致维度缩减期间的信息损失少得多。鉴于这些信号应该易于压缩，因此尺寸减小甚至会促进更快的学习。&lt;/li&gt;
&lt;li&gt;平衡网络的宽度和深度。&lt;strong&gt;通过平衡每个阶段的滤波器数量和网络的深度可以达到网络的最佳性能，增加网络的宽度和深度可以有助于更高质量的网络。然而，如果两者并行增加，则可以达到恒定计算量的最佳改进&lt;/strong&gt;。因此，计算预算应该在网络的深度和宽度之间以平衡方式进行分配。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;虽然这些原则可能是有意义的，但并不是开箱即用的直接使用它们来提高网络质量。我们的想法是仅在不明确的情况下才明智地使用它们。&lt;/p&gt;
&lt;h2 id=&#34;3-factorizing-convolutions-with-large-filter-size&#34;&gt;3. Factorizing Convolutions with Large Filter Size&lt;/h2&gt;
&lt;p&gt;GoogLeNet网络[20]的大部分初始收益来源于大量地使用降维。这可以被视为以计算有效的方式分解卷积的特例。考虑例如1×1卷积层之后接一个3×3卷积层的情况。在视觉网络中，预期相近激活的输出是高度相关的。因此，我们可以预期，它们的激活可以在聚合之前被减少，并且这应该会导致类似的富有表现力的局部表示。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/ClassicPaperTranslation/GoogleNet/V3/Figure_1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;图1。&lt;/p&gt;
&lt;p&gt;Mini网络替换5×5卷积。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在这里，我们将在各种设定中探索卷积分解的其它方法，特别是为了提高解决方案的计算效率。由于Inception网络是全卷积的，每个权重对应每个激活的一次乘法。因此，任何计算成本的降低会导致参数数量减少。这意味着，通过适当的分解，我们可以得到更多的解耦参数，从而加快训练。此外，我们可以使用计算和内存节省来增加我们网络的滤波器组的大小，同时保持我们在单个计算机上训练每个模型副本的能力。&lt;/p&gt;
&lt;h3 id=&#34;31-factorization-into-smaller-convolutions&#34;&gt;3.1. Factorization into smaller convolutions&lt;/h3&gt;
&lt;p&gt;具有较大空间滤波器（例如5×5或7×7）的卷积在计算方面往往不成比例地昂贵。例如，具有n个滤波器的5×5卷积在具有m个滤波器的网格上比具有相同数量的滤波器的3×3卷积的计算量高25/9=2.78倍。当然，5×5滤波器在更前面的层可以捕获更远的单元激活之间、信号之间的依赖关系，因此滤波器几何尺寸的减小带来了很大的表现力。然而，我们可以询问5×5卷积是否可以被具有相同输入尺寸和输出深度的参数较小的多层网络所取代。如果我们放大5×5卷积的计算图，我们看到每个输出看起来像一个小的完全连接的网络，在其输入上滑过5×5的块（见图1）。由于我们正在构建视觉网络，所以通过两层的卷积结构再次利用平移不变性来代替全连接的组件似乎是很自然的：第一层是3×3卷积，第二层是在第一层的3×3输出网格之上的一个全连接层（见图1）。通过在输入激活网格上滑动这个小网络，用两层3×3卷积来替换5×5卷积（比较图4和5）。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;该设定通过相邻块之间共享权重明显减少了参数数量&lt;/strong&gt;。为了分析预期的计算成本节省，我们将对典型的情况进行一些简单的假设：我们可以假设$n=αm$，也就是我们想通过常数$α$因子来改变激活/单元的数量。由于5×5卷积是聚合的，$α$通常比1略大（在GoogLeNet中大约是1.5）。用两个层替换5×5层，似乎可以通过两个步骤来实现扩展：在两个步骤中通过$\sqrtα$增加滤波器数量。为了简化我们的估计，通过选择$α=1$（无扩展），如果我们单纯地滑动网络而不重新使用相邻网格图块之间的计算，我们将增加计算成本。滑动该网络可以由两个3×3的卷积层表示，其重用相邻图块之间的激活。这样，我们最终得到一个计算量减少到$\frac{9+9}{25}×$的网络，通过这种分解导致了28％的相对增益。每个参数在每个单元的激活计算中只使用一次，所以参数计数具有完全相同的节约。不过，这个设置提出了两个一般性的问题：这种替换是否会导致任何表征力的丧失？如果我们的主要目标是对计算的线性部分进行分解，是不是建议在第一层保持线性激活？我们已经进行了几个控制实验（例如参见图2），并且在分解的所有阶段中使用线性激活总是逊于使用修正线性单元。我们将这个收益归因于网络可以学习的增强的空间变化，特别是如果我们对输出激活进行批标准化[7]。当对维度减小组件使用线性激活时，可以看到类似的效果。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/ClassicPaperTranslation/GoogleNet/V3/Figure_2.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;图2。&lt;/p&gt;
&lt;p&gt;两个Inception模型间几个控制实验中的一个，其中一个分解为线性层+ ReLU层，另一个使用两个ReLU层。在三亿八千六百万次运算后，在验证集上前者达到了&lt;code&gt;76.2% top-1&lt;/code&gt;准确率，后者达到了&lt;code&gt;77.2% top-1&lt;/code&gt;的准确率。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;32-spatial-factorization-into-asymmetric-convolutions&#34;&gt;3.2. Spatial Factorization into Asymmetric Convolutions&lt;/h3&gt;
&lt;p&gt;上述结果表明，大于3×3的卷积滤波器可能不是通常有用的，因为它们总是可以简化为3×3卷积层序列。我们仍然可以问这个问题，是否应该把它们分解成更小的，例如2×2的卷积。然而，&lt;strong&gt;通过使用非对称卷积，可以做出甚至比2×2更好的效果，即n×1。例如使用3×1卷积后接一个1×3卷积，相当于以与3×3卷积相同的感受野滑动两层网络&lt;/strong&gt;（参见图3）。如果输入和输出滤波器的数量相等，那么对于相同数量的输出滤波器，两层解决方案便宜33％。相比之下，将3×3卷积分解为两个2×2卷积表示仅节省了11％的计算量。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/ClassicPaperTranslation/GoogleNet/V3/Figure_3.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;图3。&lt;/p&gt;
&lt;p&gt;替换3×3卷积的Mini网络。网络的更低层由带有3个输出单元的3×1构成。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在理论上，我们可以进一步论证，可以通过1×n卷积和后面接一个n×1卷积替换任何n×n卷积，并且随着n增长，计算成本节省显著增加（见图6）。实际上，我们发现，采用这种分解在前面的层次上不能很好地工作，但是对于中等网格尺寸（在m×m特征图上，其中m范围在12到20之间），其给出了非常好的结果。在这个水平上，通过使用1×7卷积，然后是7×1卷积可以获得非常好的结果。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/ClassicPaperTranslation/GoogleNet/V3/Figure_4.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;图4。&lt;/p&gt;</description>
    </item>
    <item>
      <title>neo4j常用命令</title>
      <link>http://localhost:1313/posts/dailydev/neo4j/</link>
      <pubDate>Wed, 26 Jun 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/dailydev/neo4j/</guid>
      <description>&lt;h2 id=&#34;neo4j启动与访问&#34;&gt;neo4j启动与访问&lt;/h2&gt;
&lt;p&gt;启动neo4j&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-1&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-1&#34;&gt;1&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-2&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-2&#34;&gt;2&lt;/a&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;docker start test_neo4j
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;docker &lt;span class=&#34;nb&#34;&gt;exec&lt;/span&gt; -it test_neo4j /bin/bash
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;访问browser&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-1-1&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-1-1&#34;&gt;1&lt;/a&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;http://localhost:7474/browser/
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;访问database&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-2-1&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-2-1&#34;&gt;1&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-2-2&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-2-2&#34;&gt;2&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-2-3&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-2-3&#34;&gt;3&lt;/a&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;neo4j://localhost:7687
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;auth: neo4j
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pw: 5225400599
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;cql语法&#34;&gt;CQL语法&lt;/h2&gt;
&lt;h3 id=&#34;create-创建节点&#34;&gt;create 创建节点&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-3-1&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-3-1&#34;&gt;1&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-3-2&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-3-2&#34;&gt;2&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-3-3&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-3-3&#34;&gt;3&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-3-4&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-3-4&#34;&gt;4&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-3-5&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-3-5&#34;&gt;5&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-3-6&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-3-6&#34;&gt;6&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-3-7&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-3-7&#34;&gt;7&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-3-8&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-3-8&#34;&gt;8&lt;/a&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;CREATE (
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &amp;lt;node-name&amp;gt;:&amp;lt;label-name&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   { 	
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &amp;lt;Property1-name&amp;gt;:&amp;lt;Property1-Value&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      ........
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &amp;lt;Propertyn-name&amp;gt;:&amp;lt;Propertyn-Value&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   }
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;match-查询节点或属性&#34;&gt;match 查询节点或属性&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-4-1&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-4-1&#34;&gt; 1&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-4-2&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-4-2&#34;&gt; 2&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-4-3&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-4-3&#34;&gt; 3&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-4-4&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-4-4&#34;&gt; 4&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-4-5&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-4-5&#34;&gt; 5&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-4-6&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-4-6&#34;&gt; 6&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-4-7&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-4-7&#34;&gt; 7&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-4-8&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-4-8&#34;&gt; 8&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-4-9&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-4-9&#34;&gt; 9&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-4-10&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-4-10&#34;&gt;10&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-4-11&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-4-11&#34;&gt;11&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-4-12&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-4-12&#34;&gt;12&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-4-13&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-4-13&#34;&gt;13&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-4-14&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-4-14&#34;&gt;14&lt;/a&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;# 查询Dept下的内容
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;MATCH (dept:Dept) return dept
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;# 查询Employee标签下 id=123，name=&amp;#34;Lokesh&amp;#34;的节点
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;MATCH (p:Employee {id:123,name:&amp;#34;Lokesh&amp;#34;}) RETURN p
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;## 查询Employee标签下name=&amp;#34;Lokesh&amp;#34;的节点，使用（where命令）
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;MATCH (p:Employee)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;WHERE p.name = &amp;#34;Lokesh&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;RETURN p
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;## 返回一个table
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;MATCH (dept: Dept)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;RETURN dept.deptno,dept.dname,dept.location
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;match 要绑定return使用，而return不能单独使用。&lt;/p&gt;</description>
    </item>
    <item>
      <title>NIN</title>
      <link>http://localhost:1313/posts/classicpapertranslation/nin/</link>
      <pubDate>Wed, 26 Jun 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/classicpapertranslation/nin/</guid>
      <description>&lt;h1 id=&#34;nin&#34;&gt;NIN&lt;/h1&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;本文提出了一种新的网络结构，称为 &amp;ldquo;网络中的网络&amp;rdquo;(NIN)，以提高模型对感受野内局部图块的可辨别性。传统的卷积层使用线性滤波器和非线性激活函数来扫描输入。相反，本文建立了结构更复杂的微神经网络，以抽象出感受野内的数据。本文用MLP来实例化微神经网络，MLP是一个有效的函数近似器。通过类似CNN的方式在输入上滑动微网络来提取特征图，然后将它们送入下一层。深度NIN可以通过堆叠多个上述结构来实现。通过微网络加强局部建模，能够在分类层中利用全局平均池化的特征图，这比传统的全连接层更容易解释，也更不容易过拟合。本文在CIFAR-10和CIFAR-100上用NIN取得了最先进的分类性能，其在SVHN和MNIST数据集上也有合理的表现。&lt;/p&gt;
&lt;h2 id=&#34;1-introduction&#34;&gt;1 Introduction&lt;/h2&gt;
&lt;p&gt;卷积神经网络[1]由交替的卷积层和池化层组成。卷积层采取线性滤波器和底层感受野的内积，然后在输入的每个局部使用非线性激活函数，由此产生的输出称为特征图。&lt;/p&gt;
&lt;p&gt;CNN中的卷积滤波器是基础数据块的广义线性模型（GLM），本文认为GLM的抽象程度很低。这里所说的抽象性是指特征对同一概念的变体是不变的[2]。用一个更有力的非线性函数近似器代替GLM可以提高局部模型的抽象能力。当潜在概念的样本是线性可分离的，即概念的变体都在GLM定义的分离平面的一侧时，GLM可以实现良好的抽象程度。因此，传统的CNN隐含了潜在概念是线性可分离的假设。然而，同一概念的数据往往存在于一个非线性流形上，因此捕捉这些概念的表征通常是输入的高度非线性函数。在NIN中，GLM被一个 &amp;ldquo;微网络 &amp;ldquo;结构所取代，它是一个通用的非线性函数近似器。在这项工作中，本文选择MLP[3]作为微网络的实例，它是一个通用的函数逼近器并可通过反向传播训练的神经网络。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/ClassicPaperTranslation/NIN/Figure_1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;图1：线性卷积层和mlpconv层的比较。线性卷积层包括一个线性滤波器，而mlpconv层包括一个微型网络（本文选择mlp）。这两个层都将局部感受野映射为潜伏概念的置信度值。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;由此产生的结构，本文称之为mlpconv层，与图1中的CNN进行比较。线性卷积层和mlpconv层都将局部感受野映射到输出的特征向量上。mlpconv用MLP将输入的局部图块映射到输出特征向量，MLP由多个具有非线性激活函数的全连接层组成，它的权重在所有的局部感受区之间共享。通过在输入上滑动MLP获得特征图，其方式与CNN类似，然后被送入下一层。NIN的整体结构是多个mlpconv层的堆叠。&lt;/p&gt;
&lt;p&gt;在CNN中，本文没有采用传统的全连接层进行分类，而是通过全局平均池化层直接输出最后一个mlpconv层的特征图的空间平均值作为类别的置信度，然后将所得向量送入softmax层。在传统的CNN中，由于全连接层作为中间的黑匣子，很难解释来自目标成本层的类别级信息是如何传递回前一个卷积层的。相比之下，全局平均集合更有意义，也更容易解释，因为它强化了特征图和类别之间的对应关系，而这是通过使用微网络进行更强的局部建模实现的。此外，全连接层容易出现过拟合，并严重依赖dropout正则化[4] [5]，而全局平均池化本身就是一个结构正则化器，它天生就能防止整体结构的过拟合。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;作者认为传统的GLM在特征提取的过程中根本不能区分这些中间过程里所形成的特征元素，除非这些特征元素是线性可分的。所以，在作者的眼里，传统CNN有效的一个假设就是这些特征元素能够线性可分。&lt;/p&gt;
&lt;p&gt;例如在一个用于识别汽车图片的卷积网络模型中，靠前的卷积层会被用于提取一些粗糙的原始的特征（如：线段、棱角等）；而靠后的卷积层则会以前面的为基础提取到更为高级一些的特征（如：轮胎、车门等）。同时，在每个阶段里所形的这些特征原始都被称之为 “latent concept”，因为事实上还有很多抽像的特征我们人类是无法辨认的（它可能是有用的特征，也可能不是），所以被称为“latent”。作者认为，传统的GLM在进行每一阶段的特征提取中，根本不足以区分这些特征元素——例如某个卷积层可能提取得到了很多“轮胎”这一类的same concept，但是GLM区分不了这些非线性的特征（到底是哪一类汽车的轮胎）——所以导致最终的任务精度不那么的尽如人意。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;2-convolutional-neural-networks&#34;&gt;2 Convolutional Neural Networks&lt;/h2&gt;
&lt;p&gt;经典的卷积神经元网络[1]由交替堆叠的卷积层和空间汇集层组成。卷积层通过线性卷积滤波器再加上非线性激活函数（rectifier, sigmoid, tanh等）生成特征图。以ReLU为例，特征图可以计算如下：
&lt;/p&gt;
$$
f_{i,j,k}=max(w_k^Tx_{i,j},0).
$$&lt;p&gt;
是特征图中每个像素的索引， $x_{ij}$ 表示输入patch$(i, j)$,  $k$ 用于索引特征图的通道。&lt;/p&gt;
&lt;p&gt;当潜在概念的实例是线性可分离时，这种线性卷积足以实现抽象化。然而，实现良好抽象的表征通常是输入数据的高度非线性函数。在传统的CNN中，这一点可以通过利用一套过度完整的滤波器[6]来弥补，以覆盖潜概念的所有变化。也就是说，可以学习单个线性滤波器来检测同一概念的不同变化。然而，对一个概念有太多的过滤器会给下一层带来额外的负担，它需要考虑上一层的所有变化的组合[7]。如同在CNN中，来自高层的过滤器映射到原始输入中的更大区域。它通过结合下面一层的低级概念来生成一个更高级的概念。因此，本文认为，在将它们组合成更高层次的概念之前，对每个局部图块做一个更好的抽象是有益的。&lt;/p&gt;
&lt;p&gt;在最近的maxout网络[8]中，通过对仿生特征图（仿生特征图是不应用激活函数的线性卷积的直接结果）的最大集合来减少特征图的数量。对线性函数的最大化使得一个分片线性逼近器能够逼近任何凸函数。与进行线性分离的传统卷积层相比，maxout网络更有效力，因为它可以分离位于凸集内的概念。这一改进使maxout网络在几个基准数据集上具有最佳性能。&lt;/p&gt;
&lt;p&gt;然而，maxout网络强加了一个先验，即潜在概念的实例位于输入空间的凸集内，这并不一定成立。当潜在概念的分布更加复杂时，有必要采用一个更通用的函数近似器。所以本文试图通过引入新颖的 &amp;ldquo;网中网 &amp;ldquo;结构来实现这一点，在每个卷积层中引入一个微型网络来计算局部斑块的更抽象的特征。&lt;/p&gt;
&lt;p&gt;在以前的一些工作中已经提出在输入上滑动微网络。例如，结构化多层感知器（SMLP）[9]在输入图像的不同斑块上应用共享多层感知器；在另一项工作中，基于神经网络的过滤器被训练用于人脸检测[10]。然而，它们都是为特定的问题而设计的，并且都只包含滑动网络结构中的一个层。NIN是从一个更普遍的角度提出的，微网络被整合到CNN结构中，以寻求对各级特征的更好的抽象。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;可以先利用浅层的网络来对各个阶段里所形成的非线性特征元素进行特征表示，然后再通过卷积层来完成分类类别间线性不可分的抽象表示，以此来提高模型最后的任务精度。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;3-network-in-network&#34;&gt;3 Network In Network&lt;/h2&gt;
&lt;p&gt;本文首先强调了提出的 &amp;ldquo;网中网 &amp;ldquo;结构的关键部分：MLP卷积层和全局平均池层，分别在第3.1和第3.2节。然后，在第3.3节中详细介绍整个NIN。&lt;/p&gt;
&lt;h3 id=&#34;31-mlp-convolution-layers&#34;&gt;3.1 MLP Convolution Layers&lt;/h3&gt;
&lt;p&gt;鉴于没有关于潜在概念分布的先验，最好使用通用函数近似器对局部斑块进行特征提取，因为它能够对潜在概念的更抽象的表示进行近似。径向基网络和MLP是两个著名的通用函数近似器。本文在这项工作中选择MLP有两个原因。首先，MLP与卷积神经网络的结构兼容，它是用反向传播法训练的。第二，MLP本身可以是一个深度模型，这与特征重用的精神是一致的[2]。这种新型的层在本文中被称为mlpconv，其中MLP取代了GLM对输入进行卷积。图1说明了线性卷积层和mlpconv层的区别。mlpconv层所进行的计算如下所示：&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/ClassicPaperTranslation/NIN/formula_1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;这里$n$是MLP中的层数。MLP中使用ReLU作为激活函数。&lt;/p&gt;
&lt;p&gt;从跨通道（跨特征图）池化的角度来看，式2相当于在正常卷积层上的级联跨通道参数池化。每个池化层对输入的特征图进行加权线性重组，然后经过一个ReLU。跨通道池化后的特征图在下一层中再次进行跨通道池化。这种级联式跨渠道参数池结构允许跨渠道信息的复杂和可学习的相互作用。&lt;/p&gt;
&lt;p&gt;跨信道参数池层也相当于一个具有1x1卷积核的卷积层，这种解释可以直接理解NIN的结构。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/ClassicPaperTranslation/NIN/Figure_2.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;图2：Network In Network的整体结构。在本文中，NINs包括三个mlpconv层和一个全局平均池层的堆叠.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;与maxout层的比较：maxout网络中的maxout层在多个仿生特征图上进行max pooling[8]。maxout层的特征图的计算方法如下：
&lt;/p&gt;
$$
f_{i,j,k}=max(w_{k_m}^{T}x_{i,j}).
$$&lt;p&gt;
线性函数的Maxout形成了一个片状线性函数，能够对任何凸函数进行建模。对于一个凸函数，函数值低于特定阈值的样本形成一个凸集。因此，通过近似局部补丁的凸函数，maxout有能力为样本在凸集内的概念形成分离超平面（即$l_2$球、凸锥）。Mlpconv层与maxout层的不同之处在于，凸函数近似器被一个通用函数近似器所取代，它在模拟各种潜在概念的分布方面具有更大的能力。&lt;/p&gt;</description>
    </item>
    <item>
      <title>ResNet</title>
      <link>http://localhost:1313/posts/classicpapertranslation/resnet/</link>
      <pubDate>Wed, 26 Jun 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/classicpapertranslation/resnet/</guid>
      <description>&lt;h1 id=&#34;resnet&#34;&gt;ResNet&lt;/h1&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;更深的神经网络更难训练。我们提出了一种残差学习框架来减轻网络训练，这些网络比以前使用的网络更深。我们明确地将层变为学习关于层输入的残差函数，而不是学习未参考的函数。我们提供了全面的经验证据说明这些残差网络很容易优化，并可以显著增加深度来提高准确性。在ImageNet数据集上我们评估了深度高达152层的残差网络——比VGG[40]深8倍但仍具有较低的复杂度。这些残差网络的集合在ImageNet测试集上取得了&lt;code&gt;3.57%&lt;/code&gt;的错误率。这个结果在ILSVRC 2015分类任务上赢得了第一名。我们也在CIFAR-10上分析了100层和1000层的残差网络。&lt;/p&gt;
&lt;p&gt;对于许多视觉识别任务而言，表示的深度是至关重要的。仅由于我们非常深度的表示，我们便在COCO目标检测数据集上得到了28%的相对提高。深度残差网络是我们向ILSVRC和COCO 2015竞赛提交的基础，我们也赢得了ImageNet检测任务，ImageNet定位任务，COCO检测和COCO分割任务的第一名。&lt;/p&gt;
&lt;h2 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h2&gt;
&lt;p&gt;深度卷积神经网络[22, 21]导致了图像分类[21, 49, 39]的一系列突破。深度网络自然地将低/中/高级特征[49]和分类器以端到端多层方式进行集成，特征的“级别”可以通过堆叠层的数量（深度）来丰富。最近的证据[40, 43]显示网络深度至关重要，在具有挑战性的ImageNet数据集上领先的结果都采用了“非常深”[40]的模型，深度从16 [40]到30 [16]之间。许多其它重要的视觉识别任务[7, 11, 6, 32, 27]也从非常深的模型中得到了极大受益。&lt;/p&gt;
&lt;p&gt;在深度重要性的推动下，出现了一个问题：学些更好的网络是否像堆叠更多的层一样容易？回答这个问题的一个障碍是梯度消失/爆炸[14, 1, 8]这个众所周知的问题，它从一开始就阻碍了收敛。然而，这个问题通过标准初始化[23, 8, 36, 12]和中间标准化层[16]在很大程度上已经解决，这使得数十层的网络能通过具有反向传播的随机梯度下降（SGD）开始收敛。&lt;/p&gt;
&lt;p&gt;当更深的网络能够开始收敛时，暴露了一个退化问题：随着网络深度的增加，准确率达到饱和（这可能并不奇怪）然后迅速下降。意外的是，这种下降不是由过拟合引起的，并且在适当的深度模型上添加更多的层会导致更高的训练误差，正如[10, 41]中报告的那样，并且由我们的实验完全证实。图1显示了一个典型的例子。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/ClassicPaperTranslation/ResNet/Figure_1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;图1：20层和56层的“简单”网络在CIFAR-10上的训练误差（左）和测试误差（右）。更深的网络有更高的训练误差和测试误差。ImageNet上的类似现象如图4所示。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;退化（训练准确率）表明不是所有的系统都很容易优化。让我们考虑一个较浅的架构及其更深层次的对象，为其添加更多的层。存在通过构建得到更深层模型的解决方案：添加的层是恒等映射，其他层是从学习到的较浅模型的拷贝。 这种构造解决方案的存在表明，较深的模型不应该产生比其对应的较浅模型更高的训练误差。但是实验表明，我们目前现有的解决方案无法找到与构建的解决方案相比相对不错或更好的解决方案（或在合理的时间内无法实现）。&lt;/p&gt;
&lt;p&gt;在本文中，我们通过引入&lt;em&gt;深度残差学习&lt;/em&gt;框架解决了退化问题。我们明确地让这些层拟合残差映射，而不是希望每几个堆叠的层直接拟合期望的基础映射。形式上，将期望的基础映射表示为$H(x)$，我们将堆叠的非线性层拟合另一个映射$F(x):=H(x)−x$。原始的映射重写为$F(x)+x$。我们假设残差映射比原始的、未参考的映射更容易优化。在极端情况下，如果一个恒等映射是最优的，那么将残差置为零比通过一堆非线性层来拟合恒等映射更容易。&lt;/p&gt;
&lt;p&gt;公式$F(x)+x$可以通过带有“快捷连接”的前向神经网络（图2）来实现。快捷连接[2, 33, 48]是那些跳过一层或更多层的连接。在我们的案例中，快捷连接简单地执行恒等映射，并将其输出添加到堆叠层的输出（图2）。恒等快捷连接既不增加额外的参数也不增加计算复杂度。整个网络仍然可以由带有反向传播的SGD进行端到端的训练，并且可以使用公共库（例如，Caffe [19]）轻松实现，而无需修改求解器。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/ClassicPaperTranslation/ResNet/Figure_2.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;图2：残差学习的构建块&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我们在ImageNet[35]上进行了综合实验来显示退化问题并评估我们的方法。我们发现：1）我们极深的残差网络易于优化，但当深度增加时，对应的“简单”网络（简单堆叠层）表现出更高的训练误差；2）我们的深度残差网络可以从大大增加的深度中轻松获得准确性收益，生成的结果实质上比以前的网络更好。&lt;/p&gt;
&lt;p&gt;CIFAR-10数据集上[20]也显示出类似的现象，这表明了优化的困难以及我们的方法的影响不仅仅是针对一个特定的数据集。我们在这个数据集上展示了成功训练的超过100层的模型，并探索了超过1000层的模型。&lt;/p&gt;
&lt;p&gt;在ImageNet分类数据集[35]中，我们通过非常深的残差网络获得了很好的结果。我们的152层残差网络是ImageNet上最深的网络，同时还具有比VGG网络[40]更低的复杂性。我们的模型集合在ImageNet测试集上有&lt;code&gt;3.57% top-5&lt;/code&gt;的错误率，并在ILSVRC 2015分类比赛中获得了第一名。极深的表示在其它识别任务中也有极好的泛化性能，并带领我们在进一步赢得了第一名：包括ILSVRC &amp;amp; COCO 2015竞赛中的ImageNet检测，ImageNet定位，COCO检测和COCO分割。坚实的证据表明残差学习准则是通用的，并且我们期望它适用于其它的视觉和非视觉问题。&lt;/p&gt;
&lt;h2 id=&#34;2-related-work&#34;&gt;2. Related Work&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;残差表示&lt;/strong&gt;。在图像识别中，VLAD[18]是一种通过关于字典的残差向量进行编码的表示形式，Fisher矢量[30]可以表示为VLAD的概率版本[18]。它们都是图像检索和图像分类[4,47]中强大的浅层表示。对于矢量量化，编码残差矢量[17]被证明比编码原始矢量更有效。&lt;/p&gt;
&lt;p&gt;在低级视觉和计算机图形学中，为了求解偏微分方程（PDE），广泛使用的Multigrid方法[3]将系统重构为在多个尺度上的子问题，其中每个子问题负责较粗尺度和较细尺度的残差解。Multigrid的替代方法是层次化基础预处理[44,45]，它依赖于表示两个尺度之间残差向量的变量。已经被证明[3,44,45]这些求解器比不知道解的残差性质的标准求解器收敛得更快。这些方法表明，良好的重构或预处理可以简化优化。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;快捷连接&lt;/strong&gt;。导致快捷连接[2,33,48]的实践和理论已经被研究了很长时间。训练多层感知机（MLP）的早期实践是添加一个线性层来连接网络的输入和输出[33,48]。在[43,24]中，一些中间层直接连接到辅助分类器，用于解决梯度消失/爆炸。论文[38,37,31,46]提出了通过快捷连接实现层间响应，梯度和传播误差的方法。在[43]中，一个“inception”层由一个快捷分支和一些更深的分支组成。&lt;/p&gt;
&lt;p&gt;和我们同时进行的工作，“highway networks” [41, 42]提出了门功能[15]的快捷连接。这些门是数据相关且有参数的，与我们不具有参数的恒等快捷连接相反。当门控快捷连接“关闭”（接近零）时，高速网络中的层表示非残差函数。相反，我们的公式总是学习残差函数；我们的恒等快捷连接永远不会关闭，所有的信息总是通过，还有额外的残差函数要学习。此外，高速网络还没有证实极度增加的深度（例如，超过100个层）带来的准确性收益。&lt;/p&gt;
&lt;h2 id=&#34;3-deep-residual-learning&#34;&gt;3. Deep Residual Learning&lt;/h2&gt;
&lt;h3 id=&#34;31-residual-learning&#34;&gt;3.1. Residual Learning&lt;/h3&gt;
&lt;p&gt;我们考虑$H(x)$作为几个堆叠层（不必是整个网络）要拟合的基础映射，xx表示这些层中第一层的输入。假设多个非线性层可以渐近地近似复杂函数，它等价于假设它们可以渐近地近似残差函数，即$H(x)−x$(假设输入输出是相同维度)。因此，我们明确让这些层近似参数函数 $F(x):=H(x)−x$，而不是期望堆叠层近似$H(x)$。因此原始函数变为$F(x)+x$。尽管两种形式应该都能渐近地近似要求的函数（如假设），但学习的难易程度可能是不同的。&lt;/p&gt;
&lt;p&gt;关于退化问题的反直觉现象激发了这种重构（图1左）。正如我们在引言中讨论的那样，如果添加的层可以被构建为恒等映射，更深模型的训练误差应该不大于它对应的更浅版本。退化问题表明求解器通过多个非线性层来近似恒等映射可能有困难。通过残差学习的重构，如果恒等映射是最优的，求解器可能简单地将多个非线性连接的权重推向零来接近恒等映射。&lt;/p&gt;
&lt;p&gt;在实际情况下，恒等映射不太可能是最优的，但是我们的重构可能有助于对问题进行预处理。如果最优函数比零映射更接近于恒等映射，则求解器应该更容易找到关于恒等映射的抖动，而不是将该函数作为新函数来学习。我们通过实验（图7）显示学习的残差函数通常有更小的响应，表明恒等映射提供了合理的预处理。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/ClassicPaperTranslation/ResNet/Figure_7.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;</description>
    </item>
    <item>
      <title>SQL</title>
      <link>http://localhost:1313/posts/dailydev/mysql%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Wed, 26 Jun 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/dailydev/mysql%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</guid>
      <description>&lt;h2 id=&#34;第一章数据库基础&#34;&gt;第一章：数据库基础&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;数据库：保存有组织的数据的容器（通常是一个文件或一组文件）&lt;/p&gt;
&lt;p&gt;数据库软件（DBMS）：MySql，Oracle，MongoDB之类。人们通常用数据库来代替数据库软件的名称&lt;/p&gt;
&lt;p&gt;表（table）：某种特定类型数据的结构化清单&lt;/p&gt;
&lt;p&gt;模式：关于数据库和表的布局及特性的信息&lt;/p&gt;
&lt;p&gt;列（column）：表中的一个字段（该列由字段来唯一标识），所有表都是由一个或多个列组成的，每一列都有自己的数据类型&lt;/p&gt;
&lt;p&gt;行（row）：表中的一条数据是由行来存储的&lt;/p&gt;
&lt;p&gt;主键（primary key）：唯一标识表中每行的这个列就是主键，应该总是定义主键&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;关于主键：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;任意两行都不具有相同的主键值&lt;/li&gt;
&lt;li&gt;每个行都必须有一个主键值&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;SQL：结构化查询语言&lt;/p&gt;
&lt;h2 id=&#34;第二章mysql简介&#34;&gt;第二章：MySQL简介&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;略&lt;/p&gt;
&lt;h2 id=&#34;第三章使用mysql&#34;&gt;第三章：使用MySQL&lt;/h2&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;登录数据库&lt;/p&gt;
&lt;p&gt;默认主机名：localhost&lt;/p&gt;
&lt;p&gt;默认端口：3306&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-1&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-1&#34;&gt;1&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-2&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-2&#34;&gt;2&lt;/a&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;mysql -u root -p
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 然后输入密码&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;选择数据库&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-1-1&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-1-1&#34;&gt;1&lt;/a&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-mysql&#34; data-lang=&#34;mysql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;USE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;database_name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;了解数据库和表&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;查看所有数据库&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-2-1&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-2-1&#34;&gt;1&lt;/a&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-mysql&#34; data-lang=&#34;mysql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;SHOW&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;DATABASES&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;查看一个数据库中的所有表&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-3-1&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-3-1&#34;&gt;1&lt;/a&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-mysql&#34; data-lang=&#34;mysql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;SHOW&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kp&#34;&gt;TABLES&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;查看一个表的所有字段&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-4-1&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-4-1&#34;&gt;1&lt;/a&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-mysql&#34; data-lang=&#34;mysql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;SHOW&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;COLUMNS&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;table&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;还有一种快捷写法&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-5-1&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-5-1&#34;&gt;1&lt;/a&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-mysql&#34; data-lang=&#34;mysql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;DESCRIBE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;table&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;在返回的列表中可以看到一些建表信息，如字段名，数据类型，键类型，是否为NULL，默认值，其他类型。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;其他的show语句&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-6-1&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-6-1&#34;&gt;1&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-6-2&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-6-2&#34;&gt;2&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-6-3&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-6-3&#34;&gt;3&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-6-4&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-6-4&#34;&gt;4&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-6-5&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-6-5&#34;&gt;5&lt;/a&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-mysql&#34; data-lang=&#34;mysql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;SHOW&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;GRANTS&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;# 显示授予用户的安全权限
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;SHOW&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ERRORS&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;# 显示服务器错误
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;SHOW&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;WARNINGS&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;# 显示服务器警告信息
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;SHOW&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;STATUS&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;# 显示服务器的状态信息
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;HELP&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;SHOW&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;# 显示mysql允许的show语句
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;有一个书写规则：select这样的关键词要大写，表名、列名、数据库名要小写&lt;/p&gt;</description>
    </item>
    <item>
      <title>VGG</title>
      <link>http://localhost:1313/posts/classicpapertranslation/vgg/</link>
      <pubDate>Wed, 26 Jun 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/classicpapertranslation/vgg/</guid>
      <description>&lt;h1 id=&#34;vgg&#34;&gt;VGG&lt;/h1&gt;
&lt;h2 id=&#34;abstract&#34;&gt;ABSTRACT&lt;/h2&gt;
&lt;p&gt;本文研究了卷积网络深度在大规模的图像识别环境下对准确性的影响。主要贡献是使用非常小的（3×3）卷积滤波器架构对网络深度的增加进行了全面评估，这表明通过将深度推到16-19加权层可以实现对现有技术配置的显著改进。这些发现是ImageNet Challenge 2014提交的基础，本文作者团队在定位和分类过程中分别获得了第一名和第二名。&lt;/p&gt;
&lt;h2 id=&#34;1-introduction&#34;&gt;1 INTRODUCTION&lt;/h2&gt;
&lt;p&gt;随着ConvNets在计算机视觉领域越来越商品化，为了达到更好的准确性，已经进行了许多尝试来改进Krizhevsky等人（2012）最初的架构。例如，ILSVRC-2013（Zeiler＆Fergus，2013；Sermanet等，2014）表现最佳的提交使用了更小的感受窗口尺寸和更小的第一卷积层步长。另一条改进措施在整个图像和多个尺度上对网络进行密集地训练和测试（Sermanet等，2014；Howard，2014）。在本文中，解决了ConvNet架构设计的另一个重要方面——其深度。为此修正了架构的其它参数，并通过添加更多的卷积层来稳定地增加网络的深度，这是可行的，因为在所有层中使用非常小的（3×3）卷积滤波器。&lt;/p&gt;
&lt;p&gt;本文的其余部分组织如下。在第2节，描述了ConvNet配置。图像分类训练和评估的细节在第3节，并在第4节中在ILSVRC分类任务上对配置进行了比较。第5节总结了论文。&lt;/p&gt;
&lt;h2 id=&#34;2-convnet-configurations&#34;&gt;2 CONVNET CONFIGURATIONS&lt;/h2&gt;
&lt;p&gt;为了衡量ConvNet深度在公平环境中所带来的改进，所有的ConvNet层配置都使用相同的规则，灵感来自Ciresan等（2011）；Krizhevsky等人（2012年）。在本节中，首先描述ConvNet配置的通用设计（第2.1节），然后详细说明评估中使用的具体配置（第2.2节）。最后，网络的设计选择将在2.3节进行讨论并与现有技术进行比较。&lt;/p&gt;
&lt;h3 id=&#34;21-architecture&#34;&gt;2.1 ARCHITECTURE&lt;/h3&gt;
&lt;p&gt;在训练期间，ConvNet的输入是固定大小的224×224 RGB图像。唯一的预处理是从每个像素中减去在训练集上计算的RGB均值。图像通过若干卷积（conv.）层，选择使用感受野很小的滤波器：3×3（这是捕获图像左/右，上/下，中心特征的最小尺寸）。在其中一种配置中还使用了1×1卷积滤波器，1×1卷积可以看作输入通道的线性变换（后面是非线性）。卷积步长固定为1个像素；卷积层输入的空间填充要满足卷积之后保留空间分辨率，即3×3卷积层的填充为1个像素。空间池化由五个最大池化层进行，这些层在一些卷积层之后（不是所有的卷积层之后都是最大池化）。在2×2像素窗口上进行最大池化，步长为2。&lt;/p&gt;
&lt;p&gt;一堆卷积层（在不同架构中具有不同深度）之后是三个全连接（FC）层：前两个每个都有4096个通道，第三个执行1000维ILSVRC分类，因此包含1000个通道（一个通道对应一个类别）。最后一层是soft-max层。所有网络中全连接层的配置是相同的。&lt;/p&gt;
&lt;p&gt;所有隐藏层都配备了ReLU。可以注意到，所有网络（除了一个）都不包含LRN（Krizhevsky等，2012）：将在第4节看到，这种规范化并不能提高在ILSVRC数据集上的性能，但增加了内存消耗和计算时间。在应用的地方，LRN层的参数是（Krizhevsky等，2012）的参数。&lt;/p&gt;
&lt;h3 id=&#34;22-configurations&#34;&gt;2.2 CONFIGURATIONS&lt;/h3&gt;
&lt;p&gt;本文中评估的ConvNet配置在表1中列出，每列为一个网络。接下来将按A-E顺序来提及网络。所有配置都遵循2.1节提出的通用设计，并且仅是深度不同：从网络A中的11个加权层（8个卷积层和3个FC层）到网络E中的19个加权层（16个卷积层和3个FC层）。卷积层的宽度（通道数）相当小，从第一层中的64开始，然后在每个最大池化层之后增加2倍，直到达到512。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/ClassicPaperTranslation/VGG/Table_1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ConvNet配置（以列显示）。随着更多的层被添加，配置的深度从左（A）增加到右（E）（添加的层以粗体显示）。卷积层参数表示为“conv⟨感受野大小⟩-通道数⟩”。为了简洁起见，不显示ReLU激活功能。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在表2中，包含了每个配置的参数数量。尽管深度很大，但网络中权重数量并不大于具有更大卷积层宽度和感受野的较浅网络中的权重数量（144M的权重在（Sermanet等人，2014）中）。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/ClassicPaperTranslation/VGG/Table_2.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;表2：参数数量（百万级别）&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;23-discussion&#34;&gt;2.3 DISCUSSION&lt;/h3&gt;
&lt;p&gt;本文的ConvNet配置与ILSVRC-2012（Krizhevsky等，2012）和ILSVRC-2013比赛（Zeiler＆Fergus，2013；Sermanet等，2014）表现最佳的参赛提交中使用的ConvNet配置有很大不同。本文在整个网络使用非常小的3×3感受野，与输入的每个像素（步长为1）进行卷积。很容易看到两个3×3卷积层堆叠（没有空间池化）有5×5的有效感受野；三个这样的层具有7×7的有效感受野。&lt;/p&gt;
&lt;p&gt;那么我们获得了什么？例如通过使用三个3×3卷积层的堆叠来替换单个7×7层。首先，结合了三个非线性修正层，而不是单一的，这使得决策函数更具判别性。其次，减少了参数的数量：假设三层3×3卷积堆叠的输入和输出有$C$个通道，堆叠卷积层的参数为$3(3^2C^2)=27C^2$个权重；同时，单个7×7卷积层将需要$7^2C^2=49C^2$个参数，即参数多81％。这可以看作是对7×7卷积滤波器进行正则化，迫使它们通过3×3滤波器（在它们之间注入非线性）进行分解。&lt;/p&gt;
&lt;h2 id=&#34;3-classification-framework&#34;&gt;3 CLASSIFICATION FRAMEWORK&lt;/h2&gt;
&lt;p&gt;在本节中，将介绍分类ConvNet训练和评估的细节。&lt;/p&gt;
&lt;h3 id=&#34;31-training&#34;&gt;3.1 TRAINING&lt;/h3&gt;
&lt;p&gt;ConvNet训练过程通常遵循Krizhevsky等人（2012）（除了从多尺度训练图像中对输入裁剪图像进行采样外，如下文所述）。也就是说，通过使用具有动量的小批量梯度下降（基于反向传播（LeCun等人，1989））优化多项式逻辑回归目标函数来进行训练。批量大小设为256，动量为0.9。训练通过权重衰减（L2惩罚乘子设定为$5\times10^{-4}$）进行正则化，前两个全连接层执行丢弃正则化（丢弃率设定为0.5）。学习率初始设定为$10^{-2}$，然后当验证集准确率停止改善时，减少10倍。学习率总共降低3次，学习在37万次迭代后停止（74个epochs）。经过推测，尽管与（Krizhevsky等，2012）相比本文网络参数更多，网络的深度更大，但网络需要更小的epoch就可以收敛，这是由于（a）由更大的深度和更小的卷积滤波器尺寸引起的隐式正则化，（b）某些层的预初始化。&lt;/p&gt;
&lt;p&gt;网络权重的初始化是重要的，因为由于深度网络中梯度的不稳定，不好的初始化可能会阻碍学习。为了规避这个问题，开始训练配置A（表1），其足够浅能够以随机初始化进行训练。然后，当训练更深的架构时，用网络A的层初始化前四个卷积层和最后三个全连接层（中间层被随机初始化）。没有减少预初始化层的学习率，允许他们在学习过程中改变。对于随机初始化（如果应用），选择从均值为0和方差为$10^{-2}$的正态分布中采样权重。偏置初始化为零。&lt;/p&gt;
&lt;p&gt;为了获得固定大小的224×224 ConvNet输入图像，它们从归一化的训练图像中被随机裁剪（每个图像每次SGD迭代进行一次裁剪）。为了进一步增强训练集，裁剪图像经过了随机水平翻转和随机RGB颜色偏移（Krizhevsky等，2012）。下面解释训练图像归一化。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;训练图像大小&lt;/strong&gt;。令$S$是等轴归一化的训练图像的最小边，ConvNet输入从$S$中裁剪（我们也将S称为训练尺度）。虽然裁剪尺寸固定为224×224，但原则上S可以是不小于224的任何值：对于$S=224$，裁剪图像将捕获整个图像的统计数据，完全扩展训练图像的最小边；对于$S»224$，裁剪图像将对应于图像的一小部分，包含小对象或对象的一部分。&lt;/p&gt;
&lt;p&gt;考虑两种方法来设置训练尺度$S$。第一种是修正对应单尺度训练的S（注意，采样裁剪图像中的图像内容仍然可以表示多尺度图像统计）。在本文的实验中评估了以两个固定尺度训练的模型：（已经在现有技术中广泛使用（Krizhevsky等人，2012；Zeiler＆Fergus，2013；Sermanet等，2014））和$S=384$。给定ConvNet配置，首先使用$S=256$来训练网络。为了加速$S=384$网络的训练，用$S=256$预训练的权重来进行初始化，使用较小的初始学习率$10^{-3}$。&lt;/p&gt;
&lt;p&gt;设置S的第二种方法是多尺度训练，其中每个训练图像通过从一定范围$S_{min}$，$S_{max}$（我们使用$S_{min}=256$和$S_{max}=512$）随机采样$S$来单独进行归一化。由于图像中的目标可能具有不同的大小，因此在训练期间考虑到这一点是有益的。这也可以看作是通过尺度抖动进行训练集增强，其中单个模型被训练在一定尺度范围内识别对象。为了速度，通过对具有相同配置的单尺度模型的所有层进行微调，训练了多尺度模型，并用固定的$S=384$进行预训练。&lt;/p&gt;
&lt;h3 id=&#34;32-testing&#34;&gt;3.2 TESTING&lt;/h3&gt;
&lt;p&gt;在测试时，给出训练的ConvNet和输入图像，它按以下方式分类。首先，将其等轴地归一化到预定义的最小图像边，表示为Q（我们也将其称为测试尺度）。我们注意到，Q不一定等于训练尺度S（正如我们在第4节中所示，每个S使用Q的几个值会导致性能改进）。然后，网络以类似于（Sermanet等人，2014）的方式密集地应用于归一化的测试图像上。即，全连接层首先被转换成卷积层（第一FC层转换到7×7卷积层，最后两个FC层转换到1×1卷积层）。然后将所得到的全卷积网络应用于整个（未裁剪）图像上。结果是类得分图的通道数等于类别的数量，以及取决于输入图像大小的可变空间分辨率。最后，为了获得图像的类别分数的固定大小的向量，类得分图在空间上平均（和池化）。我们还通过水平翻转图像来增强测试集；将原始图像和翻转图像的soft-max类后验进行平均，以获得图像的最终分数。&lt;/p&gt;
&lt;p&gt;由于全卷积网络被应用在整个图像上，所以不需要在测试时对采样多个裁剪图像（Krizhevsky等，2012），因为它需要网络重新计算每个裁剪图像，这样效率较低。同时，如Szegedy等人（2014）所做的那样，使用大量的裁剪图像可以提高准确度，因为与全卷积网络相比，它使输入图像的采样更精细。此外，由于不同的卷积边界条件，多裁剪图像评估是密集评估的补充：当将ConvNet应用于裁剪图像时，卷积特征图用零填充，而在密集评估的情况下，相同裁剪图像的填充自然会来自于图像的相邻部分（由于卷积和空间池化），这大大增加了整个网络的感受野，因此捕获了更多的上下文。虽然我们认为在实践中，多裁剪图像的计算时间增加并不足以证明准确性的潜在收益，但作为参考，我们还在每个尺度使用50个裁剪图像（5×5规则网格，2次翻转）评估了我们的网络，在3个尺度上总共150个裁剪图像，与Szegedy等人(2014)在4个尺度上使用的144个裁剪图像。&lt;/p&gt;
&lt;h3 id=&#34;33-implementation-details&#34;&gt;3.3 IMPLEMENTATION DETAILS&lt;/h3&gt;
&lt;p&gt;略（GPU上的实现细节，模型实现细节，已过时）&lt;/p&gt;
&lt;h2 id=&#34;4-classification-experiments&#34;&gt;4 CLASSIFICATION EXPERIMENTS&lt;/h2&gt;
&lt;p&gt;在本节中，介绍了描述的ConvNet架构（用于ILSVRC 2012-2014挑战）在ILSVRC-2012数据集上实现的图像分类结果。数据集包括1000个类别的图像，并分为三组：训练（130万张图像），验证（5万张图像）和测试（留有类标签的10万张图像）。使用两个措施评估分类性能：top-1和top-5错误率。前者是多类分类误差，即不正确分类图像的比例；后者是ILSVRC中使用的主要评估标准，并且计算为图像真实类别在前5个预测类别之外的图像比例。&lt;/p&gt;
&lt;h3 id=&#34;41-single-scale-evaluation&#34;&gt;4.1 SINGLE SCALE EVALUATION&lt;/h3&gt;
&lt;p&gt;首先评估单个ConvNet模型在单尺度上的性能，其层结构配置如2.2节中描述。测试图像大小设置如下：对于固定$S$的$Q=S$，对于抖动$S∈[S_{min},S_{max}]，Q=0.5(S_{min}+S_{max})$.结果如表3所示。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/ClassicPaperTranslation/VGG/Table_3.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;表3：在单测试尺度的ConvNet性能&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;首先注意到，使用局部响应归一化（A-LRN网络）在没有任何归一化层的情况下，对模型A没有改善。因此，在较深的架构（B-E）中不采用归一化。&lt;/p&gt;
&lt;p&gt;第二，可以观察到分类误差随着ConvNet深度的增加而减小：从A中的11层到E中的19层。值得注意的是，尽管深度相同，配置C（包含三个1×1卷积层）比在整个网络层中使用3×3卷积的配置D更差。这表明，虽然额外的非线性确实有帮助（C优于B），但也可以通过使用具有非平凡感受野（D比C好）的卷积滤波器来捕获空间上下文。当深度达到19层时，架构的错误率饱和，但更深的模型可能有益于较大的数据集。同时还将网络B与具有5×5卷积层的浅层网络进行了比较，浅层网络可以通过用单个5×5卷积层替换B中每对3×3卷积层得到（其具有相同的感受野如第2.3节所述）。测量的浅层网络top-1错误率比网络B的top-1错误率（在中心裁剪图像上）高7％，这证实了具有小滤波器的深层网络优于具有较大滤波器的浅层网络。&lt;/p&gt;
&lt;p&gt;最后，训练时的尺度抖动（$S∈[256;512]$）得到了与固定最小边（$S=256$或$S=384$）的图像训练相比更好的结果，即使在测试时使用单尺度。这证实了通过尺度抖动进行的训练集增强确实有助于捕获多尺度图像统计。&lt;/p&gt;</description>
    </item>
    <item>
      <title>正则表达式</title>
      <link>http://localhost:1313/posts/dailydev/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A__%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Wed, 26 Jun 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/dailydev/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A__%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</guid>
      <description>&lt;h2 id=&#34;第二章-匹配单个字符&#34;&gt;第二章. 匹配单个字符&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&amp;rsquo; . &amp;rsquo; 用来匹配任意单一字符, 元字符的一种&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&amp;rsquo; \ &amp;lsquo;为转义字符, 属于元字符的一种, 元字符: 有特殊含义的字符&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;正则表达式被称为模式(pattern)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;第三章-匹配一组字符&#34;&gt;第三章. 匹配一组字符&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&amp;rsquo; [ ] &amp;lsquo;为元字符, 表示一个字符集合, 必须匹配其中的一个或多个字符, 也可以全部匹配. &amp;rsquo; [ ] &amp;lsquo;可以用来匹配大小写, 如[Aa].*就匹配任意以A或a或Aa开头的字符串. 还有几种常见的用法, 如[a-z] [A-Z] [0-9], 这几种很常用, 还有一个用法[A-Za-z0-9] 这个字符集可以匹配以上三种用法的合集&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&amp;rsquo; - &amp;lsquo;表示连字符, 是一种较为特殊的元字符, 只有在&amp;rsquo; [ ] &amp;rsquo; 里才是元字符, 在其他地方就是一个普通的字符&amp;rsquo; - &amp;lsquo;, 也因此在这种情况下它不需要转义&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&amp;rsquo; ^ &amp;rsquo; 表示排除, 也是元字符. 在上面的几种用法中, 在集合的最前面加上&amp;rsquo; ^ &amp;lsquo;, 就表示匹配除了该集合以外的字符, 而且需要注意的是, &amp;rsquo; ^ &amp;lsquo;的作用域是整个字符集合, 而不是紧跟在其身后的单个字符什么的&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;第四章-使用元字符&#34;&gt;第四章. 使用元字符&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;如果要匹配元字符本身, 可以用 &amp;rsquo; \ . 如: 匹配[ ], 用\ [ \ ]&lt;/p&gt;</description>
    </item>
    <item>
      <title>KnowledgeGraph Abstract</title>
      <link>http://localhost:1313/posts/knowledgegraph/%E9%A2%86%E5%9F%9F%E7%BB%BC%E8%BF%B0/</link>
      <pubDate>Tue, 25 Jun 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/knowledgegraph/%E9%A2%86%E5%9F%9F%E7%BB%BC%E8%BF%B0/</guid>
      <description>KnowledgeGraph的领域综述，快速了解背景现状</description>
    </item>
    <item>
      <title>AlexNet</title>
      <link>http://localhost:1313/posts/classicpapertranslation/alexnet/</link>
      <pubDate>Mon, 24 Jun 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/classicpapertranslation/alexnet/</guid>
      <description>&lt;h1 id=&#34;alexnet&#34;&gt;AlexNet&lt;/h1&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;本文模型在2010的ImageNet LSVRC比赛数据集上取得了第一，top-1：37.5%，top-5：15.3%，远远超过第二名的top-5：26.2%。&lt;/p&gt;
&lt;p&gt;AlexNet由5个卷积模块（包含了池化）、3个全连接、1个1000-way Softmax组成，使用非饱和神经元并在GPU上训练，同时为了减少过拟合，还采用了一种当时刚出现的正则化方法dropout。&lt;/p&gt;
&lt;h2 id=&#34;1-introduction&#34;&gt;1 Introduction&lt;/h2&gt;
&lt;p&gt;当时的目标识别为提高性能，常采用增大数据集、更好的model、更好的正则化技术阻止过拟合。&lt;/p&gt;
&lt;p&gt;为了从ImageNet的数百万张高分辨的图像中学习到几千个对象，提出了CNNs（Convolutional nerual networks），其具有统计上的稳定性，并且对像素有局部性的依赖（卷积直接导致）。与相同层次的前馈相比，CNNs具有更少的连接和参数，更易于训练，但是理论最优性能稍差于前馈。&lt;/p&gt;
&lt;p&gt;论文几个贡献：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在ILSVRC-2010和ILSVRC-2012[2]的ImageNet子集上训练了到目前为止最大的神经网络之一，并取得了迄今为止在这些数据集上报道过的最好结果；&lt;/li&gt;
&lt;li&gt;编写了高度优化的2D卷积GPU实现以及训练卷积神经网络内部的所有其它操作；&lt;/li&gt;
&lt;li&gt;使用了一些有效的技术来防止过拟合；&lt;/li&gt;
&lt;li&gt;CNNs的深度很重要，移除任何卷积层（每个卷积层包含的参数不超过模型参数的1%）都会导致更差的性能。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;网络尺寸主要受限于目前GPU的内存容量和能忍受的训练时间。CNNs在两个GTX 580 3GB GPU上训练五六天。所有实验表明结果可以简单地通过等待更快的GPU和更大的可用数据集来提高。&lt;/p&gt;
&lt;h2 id=&#34;2-the-dataset&#34;&gt;2 The Dataset&lt;/h2&gt;
&lt;p&gt;ImageNet数据集有超过1500万的标注高分辨率图像，这些图像属于大约22000个类别。这些图像是从网上收集的，使用了Amazon&amp;rsquo;s Mechanical Turk的众包工具通过人工标注的。从2010年起，作为Pascal视觉对象挑战赛的一部分，每年都会举办ImageNet大规模视觉识别挑战赛（ILSVRC）。ILSVRC使用ImageNet的一个子集，1000个类别每个类别大约1000张图像。总计，大约120万训练图像，50000张验证图像和15万测试图像。&lt;/p&gt;
&lt;p&gt;ILSVRC-2010是ILSVRC竞赛中唯一可以获得测试集标签的版本，因此大多数实验都是在这个版本上运行的。由于模型参加了ILSVRC-2012竞赛，因此在之后包含模型在这个版本的数据集上的结果，这个版本的测试标签是不可获得的。在ImageNet上，按照惯例报告两个错误率：top-1和top-5，top-5错误率是指测试图像的正确标签不在模型认为的五个最可能的便签之中。&lt;/p&gt;
&lt;p&gt;mageNet包含各种分辨率的图像，而CNNs要求输入固定维度。因此将图像进行下采样到固定的&lt;code&gt;256×256&lt;/code&gt;分辨率。除了在训练集上对像素减去平均活跃度外，不对图像做任何其它的预处理。因此将在原始的RGB像素值上训练网络。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;下采样步骤：给定一个矩形图像，首先缩放图像短边长度为256，然后从结果图像中裁剪中心的&lt;code&gt;256×256&lt;/code&gt;大小的图像块。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;3-the-architecture&#34;&gt;3 The Architecture&lt;/h2&gt;
&lt;p&gt;下面内容是按照重要性排序的，3.1最重要。&lt;/p&gt;
&lt;h3 id=&#34;31-relu-nonlinearity&#34;&gt;3.1 ReLU Nonlinearity&lt;/h3&gt;
&lt;p&gt;下面的实验证明：使用饱和的激活函数（如Tanh）慢于非饱和的激活函数（如ReLU），且ReLU能较明显的加快训练速度。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;右饱和：
当x趋向于正无穷时，函数的导数趋近于0，此时称为右饱和。&lt;/p&gt;
&lt;p&gt;左饱和：
当x趋向于负无穷时，函数的导数趋近于0，此时称为左饱和。&lt;/p&gt;
&lt;p&gt;饱和函数和非饱和函数：
当一个函数既满足右饱和，又满足左饱和，则称为饱和函数，否则称为非饱和函数。&lt;/p&gt;
&lt;p&gt;常用的饱和激活函数和非饱和激活函数：
饱和激活函数有如Sigmoid和tanh，非饱和激活函数有ReLU；相较于饱和激活函数，非饱和激活函数可以解决“梯度消失”的问题，加快收敛。&lt;/p&gt;
&lt;p&gt;采用ReLU的深度卷积神经网络训练时间比等价的Tanh单元要快几倍，对于一个特定的四层卷积网络，在CIFAR-10数据集上达到25%的训练误差所需要的迭代次数可以证实这一点。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/ClassicPaperTranslation/AlexNet/Figure_1.png&#34; alt=&#34;图1&#34;  /&gt;
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;使用ReLU的四层卷积神经网络在CIFAR-10数据集上达到25%的训练误差比使用tanh神经元的等价网络（虚线）快六倍。为了使训练尽可能快，每个网络的学习率是单独选择的，且没有采用任何类型的正则化。这里展示的效果的大小随网络结构的变化而变化，但使用ReLU的网络都比等价的饱和神经元快几倍。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;32-training-on-multiple-gpus&#34;&gt;3.2 Training on Multiple GPUs&lt;/h3&gt;
&lt;p&gt;（该部分就是在说怎样用GPU训练的，略）&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/ClassicPaperTranslation/AlexNet/Figure_2.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;CNN架构图解，明确描述了两个GPU之间的责任。在图的顶部，一个GPU运行在部分层上，而在图的底部，另一个GPU运行在部分层上。GPU只在特定的层进行通信。网络的输入是150,528维，网络剩下层的神经元数目分别是253,440–186,624–64,896–64,896–43,264–4096–4096–1000（8层）。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;33-local-response-normalization&#34;&gt;3.3 Local Response Normalization&lt;/h3&gt;
&lt;p&gt;局部响应归一化有助于泛化。$a^i_{x,y}$表示激活的神经元，通过在$(x,y)$位置应用核$i$，然后应用ReLU计算。响应归一化激活$b^i_{x,y}$通过下式定义：
&lt;/p&gt;
$$
b^i_{x,y}=a^i_{x,y}/(k+α\sum_{j=max(0,i−n/2)}^{min(N−1,i+n/2)}(a^i_{x,y})^2)^β
$$&lt;p&gt;
求和运算在$n$个“毗邻的”核映射的同一位置上执行，$N$是本层的卷积核数目。核映射的顺序当然是任意的，在训练开始前确定。响应归一化的顺序实现了一种侧抑制形式，灵感来自于真实神经元中发现的类型，为使用不同核进行神经元输出计算的较大活动创造了竞争。常量$k$，$n$，$α$，$β$是超参数，它们的值通过验证集确定。在本文中，设$k=2$，$n=5$，$α=0.0001$，$β=0.75$。在特定的层使用的ReLU非线性之后应用了这种归一化。&lt;/p&gt;
&lt;p&gt;这个方案与Jarrett等人[11]的局部对比度归一化方案有一定的相似性，但更恰当的称其为“亮度归一化”，因此没有减去均值。响应归一化分别减少了top-1：1.4%，top-5：1.2%的错误率。之后在CIFAR-10数据集上验证了这个方案的有效性：一个四层CNN取得了13%的错误率，而使用归一化取得了11%的错误率。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Local Response Normalization(LRN)，局部响应归一化层。&lt;/p&gt;</description>
    </item>
    <item>
      <title>记一次博客搭建</title>
      <link>http://localhost:1313/posts/dailydev/%E8%AE%B0%E4%B8%80%E6%AC%A1%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/</link>
      <pubDate>Mon, 24 Jun 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/dailydev/%E8%AE%B0%E4%B8%80%E6%AC%A1%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/</guid>
      <description>&lt;h1 id=&#34;my-blog-construction&#34;&gt;My Blog Construction&lt;/h1&gt;
&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;这是第二次用 Hugo 搭建静态博客了，之前的那个博客不论是主题、工作流、文件结构都很不合理，用起来效率低下。遂决定在研一之前重新搞一次。&lt;/p&gt;
&lt;h2 id=&#34;完整过程&#34;&gt;完整过程&lt;/h2&gt;
&lt;h3 id=&#34;hugo-安装&#34;&gt;hugo 安装&lt;/h3&gt;
&lt;p&gt;在官方的 &lt;a href=&#34;https://github.com/gohugoio/hugo/releases&#34;&gt;Releases · gohugoio/hugo (github.com)&lt;/a&gt; 下载对应版本即可，然后设置环境变量。&lt;/p&gt;
&lt;h3 id=&#34;环境配置&#34;&gt;环境配置&lt;/h3&gt;
&lt;p&gt;网站选用 &lt;code&gt;Github Pages&lt;/code&gt; 搭建，因为静态网站可以满足我的所有写作需求。域名就是仓库名&lt;code&gt;705248010.github.io&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;将仓库拉取到本地后就要开始配置了。先用&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-1&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-1&#34;&gt;1&lt;/a&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;hugo new site &amp;lt;your site name&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;生成一个对应文件夹，然后我将选择的主题 &lt;a href=&#34;https://github.com/adityatelange/hugo-PaperMod&#34;&gt;adityatelange/hugo-PaperMod: A fast, clean, responsive Hugo theme. (github.com)&lt;/a&gt; 放到 &lt;code&gt;themes&lt;/code&gt; 文件夹内。&lt;/p&gt;
&lt;p&gt;可以通过&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-1-1&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-1-1&#34;&gt;1&lt;/a&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;hugo server
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;查看效果。&lt;/p&gt;
&lt;h3 id=&#34;写markdown&#34;&gt;写Markdown&lt;/h3&gt;
&lt;p&gt;根据官方文档配置完成后就可以本地写文章了，用以下命令生成&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-2-1&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-2-1&#34;&gt;1&lt;/a&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;hugo new --kind post ./xxxx/xxxx.md
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;katex&#34;&gt;KaTex&lt;/h3&gt;
&lt;p&gt;PaperMod 本身没有对数学公式的支持，但在 Hugo 官网能找到相关文档：&lt;a href=&#34;https://gohugo.io/content-management/mathematics/&#34;&gt;Mathematics in Markdown | Hugo (gohugo.io)&lt;/a&gt; 。&lt;/p&gt;
&lt;p&gt;这里选用 KaTex ，不用Mathjax的原因在于其对于内联公式符号 &lt;code&gt;$&lt;/code&gt; 的不支持。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
